{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import nltk.stem as ns\n",
    "ps = ns.PorterStemmer()\n",
    "lemma = ns.WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def remove_punctuation(x):\n",
    "    punctuation = string.punctuation\n",
    "    no_punct = \"\".join([word for word in x if word not in punctuation])\n",
    "    return no_punct\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    no_sw = [word for word in x if word not in stopwords]\n",
    "    return no_sw\n",
    "\n",
    "#function built to use either stemming or lematization\n",
    "def lemmatize(x):\n",
    "    lemmatized = [lemma.lemmatize(word) for word in x]\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "#all of those functions inside one function to keep code clean\n",
    "def clean_data(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z0-9]+\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    #root = lemmatize(no_sw)\n",
    "    cleaned = ' '.join(no_sw)\n",
    "    return cleaned\n",
    "\n",
    "def clean_tokenize(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    root = lemmatize(no_sw)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('English_Headlines_EngFeatures.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Rating</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaned tokenized</th>\n",
       "      <th>tokens</th>\n",
       "      <th>statement length</th>\n",
       "      <th>word count</th>\n",
       "      <th>sentence count</th>\n",
       "      <th>unique words</th>\n",
       "      <th>lexical richness</th>\n",
       "      <th>...</th>\n",
       "      <th>numerical%</th>\n",
       "      <th>sexual anatomy / sexual acts</th>\n",
       "      <th>bodily fluids / excrement</th>\n",
       "      <th>sexual orientation / gender</th>\n",
       "      <th>racial / ethnic slurs</th>\n",
       "      <th>animal references</th>\n",
       "      <th>internet slang</th>\n",
       "      <th>profanity_level</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing our clocks is a health hazard. Just a...</td>\n",
       "      <td>1</td>\n",
       "      <td>changing clocks health hazard ask sleep doctor</td>\n",
       "      <td>[changing, clock, health, hazard, ., ask, slee...</td>\n",
       "      <td>[Changing, our, clocks, is, a, health, hazard,...</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>40.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012298</td>\n",
       "      <td>[changing clocks, clocks health, health hazard...</td>\n",
       "      <td>[changing clocks health, clocks health hazard,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How the Alec Baldwin fatal film set shooting u...</td>\n",
       "      <td>1</td>\n",
       "      <td>alec baldwin fatal film set shooting unfolded</td>\n",
       "      <td>[alec, baldwin, fatal, film, set, shooting, un...</td>\n",
       "      <td>[How, the, Alec, Baldwin, fatal, film, set, sh...</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>[alec baldwin, baldwin fatal, fatal film, film...</td>\n",
       "      <td>[alec baldwin fatal, baldwin fatal film, fatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 90-year-old tortoise named Mr. Pickles just ...</td>\n",
       "      <td>1</td>\n",
       "      <td>90 year old tortoise named mr pickles became f...</td>\n",
       "      <td>[90-year-old, tortoise, named, mr., pickle, be...</td>\n",
       "      <td>[A, 90-year-old, tortoise, named, Mr., Pickles...</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>35.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>[90 year, year old, old tortoise, tortoise nam...</td>\n",
       "      <td>[90 year old, year old tortoise, old tortoise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama governor ousts a top education officia...</td>\n",
       "      <td>1</td>\n",
       "      <td>alabama governor ousts top education official ...</td>\n",
       "      <td>[alabama, governor, ousts, top, education, off...</td>\n",
       "      <td>[Alabama, governor, ousts, a, top, education, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>63.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>[alabama governor, governor ousts, ousts top, ...</td>\n",
       "      <td>[alabama governor ousts, governor ousts top, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 people are dead, 20 missing, as a migrant bo...</td>\n",
       "      <td>1</td>\n",
       "      <td>2 people dead 20 missing migrant boat sinks co...</td>\n",
       "      <td>[2, people, dead, ,, 20, missing, ,, migrant, ...</td>\n",
       "      <td>[2, people, are, dead, ,, 20, missing, ,, as, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065102</td>\n",
       "      <td>[2 people, people dead, dead 20, 20 missing, m...</td>\n",
       "      <td>[2 people dead, people dead 20, dead 20 missin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>Health Ranger Report: Gregory Mannarino dubs c...</td>\n",
       "      <td>0</td>\n",
       "      <td>health ranger report gregory mannarino dubs ce...</td>\n",
       "      <td>[health, ranger, report, :, gregory, mannarino...</td>\n",
       "      <td>[Health, Ranger, Report, :, Gregory, Mannarino...</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>71.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121624</td>\n",
       "      <td>[health ranger, ranger report, report gregory,...</td>\n",
       "      <td>[health ranger report, ranger report gregory, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>Trans Activist Threatens Women Who Try To Stop...</td>\n",
       "      <td>0</td>\n",
       "      <td>trans activist threatens women try stop using ...</td>\n",
       "      <td>[trans, activist, threatens, woman, try, stop,...</td>\n",
       "      <td>[Trans, Activist, Threatens, Women, Who, Try, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.120767</td>\n",
       "      <td>[trans activist, activist threatens, threatens...</td>\n",
       "      <td>[trans activist threatens, activist threatens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>Justin Trudeau Announces $5.5 Million To ‘Cens...</td>\n",
       "      <td>0</td>\n",
       "      <td>justin trudeau announces 5 5 million censor in...</td>\n",
       "      <td>[justin, trudeau, announces, $, 5.5, million, ...</td>\n",
       "      <td>[Justin, Trudeau, Announces, $, 5.5, Million, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.196001</td>\n",
       "      <td>[justin trudeau, trudeau announces, announces ...</td>\n",
       "      <td>[justin trudeau announces, trudeau announces 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>Rasmussen final Generic Congressional Ballot: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>rasmussen final generic congressional ballot 4...</td>\n",
       "      <td>[rasmussen, final, generic, congressional, bal...</td>\n",
       "      <td>[Rasmussen, final, Generic, Congressional, Bal...</td>\n",
       "      <td>19</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>33.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192476</td>\n",
       "      <td>[rasmussen final, final generic, generic congr...</td>\n",
       "      <td>[rasmussen final generic, final generic congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>Kevin McCarthy caves (as expected), appoints I...</td>\n",
       "      <td>0</td>\n",
       "      <td>kevin mccarthy caves expected appoints ilhan o...</td>\n",
       "      <td>[kevin, mccarthy, cave, (, expected, ), ,, app...</td>\n",
       "      <td>[Kevin, McCarthy, caves, (, as, expected, ), ,...</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>[kevin mccarthy, mccarthy caves, caves expecte...</td>\n",
       "      <td>[kevin mccarthy caves, mccarthy caves expected...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6548 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement  Rating  \\\n",
       "0     Changing our clocks is a health hazard. Just a...       1   \n",
       "1     How the Alec Baldwin fatal film set shooting u...       1   \n",
       "2     A 90-year-old tortoise named Mr. Pickles just ...       1   \n",
       "3     Alabama governor ousts a top education officia...       1   \n",
       "4     2 people are dead, 20 missing, as a migrant bo...       1   \n",
       "...                                                 ...     ...   \n",
       "6543  Health Ranger Report: Gregory Mannarino dubs c...       0   \n",
       "6544  Trans Activist Threatens Women Who Try To Stop...       0   \n",
       "6545  Justin Trudeau Announces $5.5 Million To ‘Cens...       0   \n",
       "6546  Rasmussen final Generic Congressional Ballot: ...       0   \n",
       "6547  Kevin McCarthy caves (as expected), appoints I...       0   \n",
       "\n",
       "                                                cleaned  \\\n",
       "0        changing clocks health hazard ask sleep doctor   \n",
       "1         alec baldwin fatal film set shooting unfolded   \n",
       "2     90 year old tortoise named mr pickles became f...   \n",
       "3     alabama governor ousts top education official ...   \n",
       "4     2 people dead 20 missing migrant boat sinks co...   \n",
       "...                                                 ...   \n",
       "6543  health ranger report gregory mannarino dubs ce...   \n",
       "6544  trans activist threatens women try stop using ...   \n",
       "6545  justin trudeau announces 5 5 million censor in...   \n",
       "6546  rasmussen final generic congressional ballot 4...   \n",
       "6547  kevin mccarthy caves expected appoints ilhan o...   \n",
       "\n",
       "                                      cleaned tokenized  \\\n",
       "0     [changing, clock, health, hazard, ., ask, slee...   \n",
       "1     [alec, baldwin, fatal, film, set, shooting, un...   \n",
       "2     [90-year-old, tortoise, named, mr., pickle, be...   \n",
       "3     [alabama, governor, ousts, top, education, off...   \n",
       "4     [2, people, dead, ,, 20, missing, ,, migrant, ...   \n",
       "...                                                 ...   \n",
       "6543  [health, ranger, report, :, gregory, mannarino...   \n",
       "6544  [trans, activist, threatens, woman, try, stop,...   \n",
       "6545  [justin, trudeau, announces, $, 5.5, million, ...   \n",
       "6546  [rasmussen, final, generic, congressional, bal...   \n",
       "6547  [kevin, mccarthy, cave, (, expected, ), ,, app...   \n",
       "\n",
       "                                                 tokens  statement length  \\\n",
       "0     [Changing, our, clocks, is, a, health, hazard,...                13   \n",
       "1     [How, the, Alec, Baldwin, fatal, film, set, sh...                 9   \n",
       "2     [A, 90-year-old, tortoise, named, Mr., Pickles...                19   \n",
       "3     [Alabama, governor, ousts, a, top, education, ...                17   \n",
       "4     [2, people, are, dead, ,, 20, missing, ,, as, ...                18   \n",
       "...                                                 ...               ...   \n",
       "6543  [Health, Ranger, Report, :, Gregory, Mannarino...                17   \n",
       "6544  [Trans, Activist, Threatens, Women, Who, Try, ...                14   \n",
       "6545  [Justin, Trudeau, Announces, $, 5.5, Million, ...                12   \n",
       "6546  [Rasmussen, final, Generic, Congressional, Bal...                19   \n",
       "6547  [Kevin, McCarthy, caves, (, as, expected, ), ,...                16   \n",
       "\n",
       "      word count  sentence count  unique words  lexical richness  ...  \\\n",
       "0             46               2            11             40.32  ...   \n",
       "1             45               1             9              9.00  ...   \n",
       "2             62               2            17             35.84  ...   \n",
       "3             69               1            14             63.00  ...   \n",
       "4             57               1            16             14.00  ...   \n",
       "...          ...             ...           ...               ...  ...   \n",
       "6543         108               1            15             71.68  ...   \n",
       "6544          55               1            14             12.00  ...   \n",
       "6545          61               1            12              8.00  ...   \n",
       "6546          84               1            14             33.88  ...   \n",
       "6547          81               1            16             13.00  ...   \n",
       "\n",
       "      numerical%  sexual anatomy / sexual acts  bodily fluids / excrement  \\\n",
       "0       0.000000                           0.0                        0.0   \n",
       "1       0.000000                           0.0                        0.0   \n",
       "2       0.052632                           0.0                        0.0   \n",
       "3       0.000000                           0.0                        0.0   \n",
       "4       0.111111                           0.0                        0.0   \n",
       "...          ...                           ...                        ...   \n",
       "6543    0.000000                           0.0                        0.0   \n",
       "6544    0.000000                           0.0                        0.0   \n",
       "6545    0.083333                           0.0                        0.0   \n",
       "6546    0.111111                           0.0                        0.0   \n",
       "6547    0.000000                           0.0                        0.0   \n",
       "\n",
       "      sexual orientation / gender  racial / ethnic slurs  animal references  \\\n",
       "0                             0.0                    0.0                0.0   \n",
       "1                             0.0                    0.0                0.0   \n",
       "2                             0.0                    0.0                0.0   \n",
       "3                             0.0                    0.0                0.0   \n",
       "4                             0.0                    0.0                0.0   \n",
       "...                           ...                    ...                ...   \n",
       "6543                          0.0                    0.0                0.0   \n",
       "6544                          0.0                    0.0                0.0   \n",
       "6545                          0.0                    0.0                0.0   \n",
       "6546                          0.0                    0.0                0.0   \n",
       "6547                          0.0                    0.0                0.0   \n",
       "\n",
       "      internet slang  profanity_level  \\\n",
       "0           0.000000         0.012298   \n",
       "1           0.000000         0.025994   \n",
       "2           0.000000         0.031957   \n",
       "3           0.000000         0.010403   \n",
       "4           0.000000         0.065102   \n",
       "...              ...              ...   \n",
       "6543        0.000000         0.121624   \n",
       "6544        0.071429         0.120767   \n",
       "6545        0.083333         0.196001   \n",
       "6546        0.000000         0.192476   \n",
       "6547        0.062500         0.008468   \n",
       "\n",
       "                                                bigrams  \\\n",
       "0     [changing clocks, clocks health, health hazard...   \n",
       "1     [alec baldwin, baldwin fatal, fatal film, film...   \n",
       "2     [90 year, year old, old tortoise, tortoise nam...   \n",
       "3     [alabama governor, governor ousts, ousts top, ...   \n",
       "4     [2 people, people dead, dead 20, 20 missing, m...   \n",
       "...                                                 ...   \n",
       "6543  [health ranger, ranger report, report gregory,...   \n",
       "6544  [trans activist, activist threatens, threatens...   \n",
       "6545  [justin trudeau, trudeau announces, announces ...   \n",
       "6546  [rasmussen final, final generic, generic congr...   \n",
       "6547  [kevin mccarthy, mccarthy caves, caves expecte...   \n",
       "\n",
       "                                               trigrams  \n",
       "0     [changing clocks health, clocks health hazard,...  \n",
       "1     [alec baldwin fatal, baldwin fatal film, fatal...  \n",
       "2     [90 year old, year old tortoise, old tortoise ...  \n",
       "3     [alabama governor ousts, governor ousts top, o...  \n",
       "4     [2 people dead, people dead 20, dead 20 missin...  \n",
       "...                                                 ...  \n",
       "6543  [health ranger report, ranger report gregory, ...  \n",
       "6544  [trans activist threatens, activist threatens ...  \n",
       "6545  [justin trudeau announces, trudeau announces 5...  \n",
       "6546  [rasmussen final generic, final generic congre...  \n",
       "6547  [kevin mccarthy caves, mccarthy caves expected...  \n",
       "\n",
       "[6548 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns.values if col != 'Rating' and col != 'bigrams' and \n",
    "        col != 'trigrams' and col != 'cleaned' \n",
    "        and col != 'cleaned tokenized' and col != 'tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = df[cols]\n",
    "y = df['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['Statement'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Changing our clocks is a health hazard. Just ask a sleep doctor',\n",
       "       'How the Alec Baldwin fatal film set shooting unfolded',\n",
       "       \"A 90-year-old tortoise named Mr. Pickles just became a father of 3. It's a big 'dill'\",\n",
       "       ...,\n",
       "       'Justin Trudeau Announces $5.5 Million To ‘Censor Independent Media’',\n",
       "       'Rasmussen final Generic Congressional Ballot: 48% GOP 43% DEM – GOP +13 with  independent voters',\n",
       "       'Kevin McCarthy caves (as expected), appoints Ilhan Omar to House Foreign Affairs Committee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=clean_tokenize)\n",
    "tfidf_vecs = vectorizer.fit_transform(sentences).toarray()\n",
    "#X = pd.concat([pd.DataFrame(tfidf_vecs), x_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([('standard_scaler', StandardScaler(), [col for col in x_df if col != 'Statement'])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_feat = ct.fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6548, 46)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6548, 9863)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.concatenate((tfidf_vecs, transformed_feat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6548, 9909)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "\n",
    "clfXGB = Pipeline(steps = [('XGBoost', XGBClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5238, 9909)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "clfSVM = Pipeline(steps = [('SVM', SVC())])\n",
    "#logistic regression\n",
    "clfLOGREG = Pipeline(steps = [('Logistic Regression', LogisticRegression())])\n",
    "#XGBoost\n",
    "clfXGB = Pipeline(steps = [('XGBoost', XGBClassifier())])\n",
    "#XGBoost with tuned params\n",
    "clfXGB_best =  Pipeline(steps = [('XGBoost_tuned', XGBClassifier(colsample_bytree= 0.5,\n",
    "                                                            gamma=0.3,\n",
    "                                                            learning_rate=0.1,\n",
    "                                                            max_depth=6,\n",
    "                                                            min_child_weight=1))])\n",
    "\n",
    "#Naive Bayes\n",
    "clfNB = Pipeline(steps = [('Naive Bayes', GaussianNB())])\n",
    "#Random forest\n",
    "clfRFC = Pipeline(steps = [('RFC', RandomForestClassifier())])\n",
    "#neural netTODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 done\n",
      "model 3 done\n",
      "model 4 done\n",
      "model 5 done\n",
      "model 6 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "models = [clfSVM, clfLOGREG, clfXGB, clfXGB_best, clfNB, clfRFC]\n",
    "\n",
    "model_scores={}\n",
    "model_rand_acc = {}\n",
    "\n",
    "\n",
    "    \n",
    "for idx, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    name = list(model.named_steps)[0]\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    model_scores[name] = score, mae, mse, f1\n",
    "\n",
    "\n",
    "    #joblib.dump(model, f'headline_classifiers_english/{name}Classifier.joblib')\n",
    "    print(f'model {idx+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': (0.8450381679389313,\n",
       "  0.1549618320610687,\n",
       "  0.1549618320610687,\n",
       "  0.8512820512820513),\n",
       " 'Logistic Regression': (0.8801526717557252,\n",
       "  0.11984732824427481,\n",
       "  0.11984732824427481,\n",
       "  0.8813303099017384),\n",
       " 'XGBoost': (0.8793893129770992,\n",
       "  0.12061068702290076,\n",
       "  0.12061068702290076,\n",
       "  0.8810240963855421),\n",
       " 'XGBoost_tuned': (0.8687022900763359,\n",
       "  0.13129770992366413,\n",
       "  0.13129770992366413,\n",
       "  0.8724035608308606),\n",
       " 'Naive Bayes': (0.7969465648854962,\n",
       "  0.20305343511450383,\n",
       "  0.20305343511450383,\n",
       "  0.8134642356241234),\n",
       " 'RFC': (0.8625954198473282,\n",
       "  0.13740458015267176,\n",
       "  0.13740458015267176,\n",
       "  0.8691860465116279)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding best params for LOGREG (it has the best performance out of all the tested ML models)   (ONLY TESTING THESE PARAMS AS THEY WERE DEEMED THE MOST IMPORTANT TO SAVE RESOURCE ALLOCATION)\n",
    "params={\n",
    " \"max_iter\" : [70, 90, 100, 500, 1000, 2000],\n",
    " \"C\"        : np.logspace(-4, 4, 50),\n",
    " \"penalty\"  : ['l1', 'l2', 'elasticnet']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clfLOGREG = LogisticRegression()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= new_clfLOGREG,\n",
    "    param_grid=params,\n",
    "    scoring = 'roc_auc',\n",
    "    verbose=True,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3000 fits failed out of a total of 4500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.87683036        nan        nan 0.87683036        nan\n",
      "        nan 0.87683036        nan        nan 0.87683036        nan\n",
      "        nan 0.87683036        nan        nan 0.87683036        nan\n",
      "        nan 0.87833102        nan        nan 0.87833102        nan\n",
      "        nan 0.87833102        nan        nan 0.87833102        nan\n",
      "        nan 0.87833102        nan        nan 0.87833102        nan\n",
      "        nan 0.87994899        nan        nan 0.87994899        nan\n",
      "        nan 0.87994899        nan        nan 0.87994899        nan\n",
      "        nan 0.87994899        nan        nan 0.87994899        nan\n",
      "        nan 0.88174703        nan        nan 0.88174703        nan\n",
      "        nan 0.88174703        nan        nan 0.88174703        nan\n",
      "        nan 0.88174703        nan        nan 0.88174703        nan\n",
      "        nan 0.88365155        nan        nan 0.88365155        nan\n",
      "        nan 0.88365155        nan        nan 0.88365155        nan\n",
      "        nan 0.88365155        nan        nan 0.88365155        nan\n",
      "        nan 0.88546128        nan        nan 0.88546128        nan\n",
      "        nan 0.88546128        nan        nan 0.88546128        nan\n",
      "        nan 0.88546128        nan        nan 0.88546128        nan\n",
      "        nan 0.88723093        nan        nan 0.88723093        nan\n",
      "        nan 0.88723093        nan        nan 0.88723093        nan\n",
      "        nan 0.88723093        nan        nan 0.88723093        nan\n",
      "        nan 0.88885851        nan        nan 0.88885851        nan\n",
      "        nan 0.88885851        nan        nan 0.88885851        nan\n",
      "        nan 0.88885851        nan        nan 0.88885851        nan\n",
      "        nan 0.89039205        nan        nan 0.89039205        nan\n",
      "        nan 0.89039205        nan        nan 0.89039205        nan\n",
      "        nan 0.89039205        nan        nan 0.89039205        nan\n",
      "        nan 0.89200501        nan        nan 0.89200501        nan\n",
      "        nan 0.89200501        nan        nan 0.89200501        nan\n",
      "        nan 0.89200501        nan        nan 0.89200501        nan\n",
      "        nan 0.89354154        nan        nan 0.89354154        nan\n",
      "        nan 0.89354154        nan        nan 0.89354154        nan\n",
      "        nan 0.89354154        nan        nan 0.89354154        nan\n",
      "        nan 0.89512758        nan        nan 0.89512758        nan\n",
      "        nan 0.89512758        nan        nan 0.89512758        nan\n",
      "        nan 0.89512758        nan        nan 0.89512758        nan\n",
      "        nan 0.89668678        nan        nan 0.89668678        nan\n",
      "        nan 0.89668678        nan        nan 0.89668678        nan\n",
      "        nan 0.89668678        nan        nan 0.89668678        nan\n",
      "        nan 0.89831888        nan        nan 0.89831888        nan\n",
      "        nan 0.89831888        nan        nan 0.89831888        nan\n",
      "        nan 0.89831888        nan        nan 0.89831888        nan\n",
      "        nan 0.90004283        nan        nan 0.90004283        nan\n",
      "        nan 0.90004283        nan        nan 0.90004283        nan\n",
      "        nan 0.90004283        nan        nan 0.90004283        nan\n",
      "        nan 0.90196658        nan        nan 0.90196658        nan\n",
      "        nan 0.90196658        nan        nan 0.90196658        nan\n",
      "        nan 0.90196658        nan        nan 0.90196658        nan\n",
      "        nan 0.90413306        nan        nan 0.90413306        nan\n",
      "        nan 0.90413306        nan        nan 0.90413306        nan\n",
      "        nan 0.90413306        nan        nan 0.90413306        nan\n",
      "        nan 0.90672601        nan        nan 0.90672601        nan\n",
      "        nan 0.90672601        nan        nan 0.90672601        nan\n",
      "        nan 0.90672601        nan        nan 0.90672601        nan\n",
      "        nan 0.90975265        nan        nan 0.90975265        nan\n",
      "        nan 0.90975265        nan        nan 0.90975265        nan\n",
      "        nan 0.90975265        nan        nan 0.90975265        nan\n",
      "        nan 0.91332677        nan        nan 0.91332677        nan\n",
      "        nan 0.91332677        nan        nan 0.91332677        nan\n",
      "        nan 0.91332677        nan        nan 0.91332677        nan\n",
      "        nan 0.91766562        nan        nan 0.91766562        nan\n",
      "        nan 0.91766562        nan        nan 0.91766562        nan\n",
      "        nan 0.91766562        nan        nan 0.91766562        nan\n",
      "        nan 0.92262397        nan        nan 0.9226247         nan\n",
      "        nan 0.9226247         nan        nan 0.9226247         nan\n",
      "        nan 0.9226247         nan        nan 0.9226247         nan\n",
      "        nan 0.92794241        nan        nan 0.92793512        nan\n",
      "        nan 0.92793512        nan        nan 0.92793512        nan\n",
      "        nan 0.92793512        nan        nan 0.92793512        nan\n",
      "        nan 0.9336093         nan        nan 0.93357793        nan\n",
      "        nan 0.93358231        nan        nan 0.9335845         nan\n",
      "        nan 0.9335845         nan        nan 0.9335845         nan\n",
      "        nan 0.93912746        nan        nan 0.9391442         nan\n",
      "        nan 0.93912306        nan        nan 0.93912891        nan\n",
      "        nan 0.93912891        nan        nan 0.93912891        nan\n",
      "        nan 0.94416741        nan        nan 0.94422208        nan\n",
      "        nan 0.94421404        nan        nan 0.94423591        nan\n",
      "        nan 0.94423591        nan        nan 0.94423591        nan\n",
      "        nan 0.94838905        nan        nan 0.94841131        nan\n",
      "        nan 0.94846957        nan        nan 0.9484769         nan\n",
      "        nan 0.9484769         nan        nan 0.9484769         nan\n",
      "        nan 0.95189137        nan        nan 0.95173813        nan\n",
      "        nan 0.95183363        nan        nan 0.9518409         nan\n",
      "        nan 0.9518409         nan        nan 0.9518409         nan\n",
      "        nan 0.95416323        nan        nan 0.95416548        nan\n",
      "        nan 0.95423389        nan        nan 0.95429079        nan\n",
      "        nan 0.95429079        nan        nan 0.95429079        nan\n",
      "        nan 0.95551021        nan        nan 0.95538689        nan\n",
      "        nan 0.95567288        nan        nan 0.95598625        nan\n",
      "        nan 0.95598625        nan        nan 0.95598625        nan\n",
      "        nan 0.95638238        nan        nan 0.95655756        nan\n",
      "        nan 0.95675073        nan        nan 0.95707228        nan\n",
      "        nan 0.95707228        nan        nan 0.95707228        nan\n",
      "        nan 0.95649924        nan        nan 0.95670396        nan\n",
      "        nan 0.95692356        nan        nan 0.95775143        nan\n",
      "        nan 0.95775143        nan        nan 0.95775143        nan\n",
      "        nan 0.95690547        nan        nan 0.95620155        nan\n",
      "        nan 0.95677576        nan        nan 0.95805673        nan\n",
      "        nan 0.95805673        nan        nan 0.95805673        nan\n",
      "        nan 0.95724491        nan        nan 0.95652729        nan\n",
      "        nan 0.95678248        nan        nan 0.95822285        nan\n",
      "        nan 0.95822285        nan        nan 0.95822285        nan\n",
      "        nan 0.95787506        nan        nan 0.95650946        nan\n",
      "        nan 0.95635452        nan        nan 0.95827011        nan\n",
      "        nan 0.95827011        nan        nan 0.95827011        nan\n",
      "        nan 0.9575465         nan        nan 0.95671169        nan\n",
      "        nan 0.95679471        nan        nan 0.95821611        nan\n",
      "        nan 0.95821611        nan        nan 0.95821611        nan\n",
      "        nan 0.9583634         nan        nan 0.95783474        nan\n",
      "        nan 0.95683687        nan        nan 0.95810671        nan\n",
      "        nan 0.95810671        nan        nan 0.95810671        nan\n",
      "        nan 0.95840904        nan        nan 0.95825154        nan\n",
      "        nan 0.95759479        nan        nan 0.95803667        nan\n",
      "        nan 0.95804177        nan        nan 0.95804177        nan\n",
      "        nan 0.95796843        nan        nan 0.95770335        nan\n",
      "        nan 0.95746892        nan        nan 0.95790103        nan\n",
      "        nan 0.95790468        nan        nan 0.95790468        nan\n",
      "        nan 0.95711703        nan        nan 0.95783986        nan\n",
      "        nan 0.95776847        nan        nan 0.95776106        nan\n",
      "        nan 0.95776326        nan        nan 0.95776326        nan\n",
      "        nan 0.95770339        nan        nan 0.95763662        nan\n",
      "        nan 0.95744513        nan        nan 0.95761814        nan\n",
      "        nan 0.95761522        nan        nan 0.95761522        nan\n",
      "        nan 0.95801801        nan        nan 0.9576517         nan\n",
      "        nan 0.95732329        nan        nan 0.95744389        nan\n",
      "        nan 0.95747812        nan        nan 0.95747812        nan\n",
      "        nan 0.95769301        nan        nan 0.95775947        nan\n",
      "        nan 0.95754117        nan        nan 0.95731477        nan\n",
      "        nan 0.95732353        nan        nan 0.95732353        nan\n",
      "        nan 0.9575955         nan        nan 0.95822954        nan\n",
      "        nan 0.95831684        nan        nan 0.95717478        nan\n",
      "        nan 0.95719082        nan        nan 0.95719082        nan\n",
      "        nan 0.95721058        nan        nan 0.95813837        nan\n",
      "        nan 0.95781475        nan        nan 0.95700341        nan\n",
      "        nan 0.95704865        nan        nan 0.95704865        nan\n",
      "        nan 0.95712375        nan        nan 0.95785745        nan\n",
      "        nan 0.95757376        nan        nan 0.95691738        nan\n",
      "        nan 0.95692249        nan        nan 0.95692249        nan\n",
      "        nan 0.9572412         nan        nan 0.9581655         nan\n",
      "        nan 0.95772143        nan        nan 0.95679126        nan\n",
      "        nan 0.9568175         nan        nan 0.9568175         nan\n",
      "        nan 0.95670054        nan        nan 0.95782096        nan\n",
      "        nan 0.95722761        nan        nan 0.95664107        nan\n",
      "        nan 0.95669283        nan        nan 0.95669283        nan\n",
      "        nan 0.95666961        nan        nan 0.95810203        nan\n",
      "        nan 0.95775245        nan        nan 0.95617615        nan\n",
      "        nan 0.9565995         nan        nan 0.9565995         nan\n",
      "        nan 0.95668764        nan        nan 0.95763357        nan\n",
      "        nan 0.95802813        nan        nan 0.95634278        nan\n",
      "        nan 0.95648577        nan        nan 0.95648577        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.87941328        nan        nan 0.87941328        nan\n",
      "        nan 0.87941328        nan        nan 0.87941328        nan\n",
      "        nan 0.87941328        nan        nan 0.87941328        nan\n",
      "        nan 0.88100197        nan        nan 0.88100197        nan\n",
      "        nan 0.88100197        nan        nan 0.88100197        nan\n",
      "        nan 0.88100197        nan        nan 0.88100197        nan\n",
      "        nan 0.88279626        nan        nan 0.88279626        nan\n",
      "        nan 0.88279626        nan        nan 0.88279626        nan\n",
      "        nan 0.88279626        nan        nan 0.88279626        nan\n",
      "        nan 0.88468099        nan        nan 0.88468099        nan\n",
      "        nan 0.88468099        nan        nan 0.88468099        nan\n",
      "        nan 0.88468099        nan        nan 0.88468099        nan\n",
      "        nan 0.88663725        nan        nan 0.88663725        nan\n",
      "        nan 0.88663725        nan        nan 0.88663725        nan\n",
      "        nan 0.88663725        nan        nan 0.88663725        nan\n",
      "        nan 0.88858125        nan        nan 0.88858125        nan\n",
      "        nan 0.88858125        nan        nan 0.88858125        nan\n",
      "        nan 0.88858125        nan        nan 0.88858125        nan\n",
      "        nan 0.89051204        nan        nan 0.89051204        nan\n",
      "        nan 0.89051204        nan        nan 0.89051204        nan\n",
      "        nan 0.89051204        nan        nan 0.89051204        nan\n",
      "        nan 0.89241439        nan        nan 0.89241439        nan\n",
      "        nan 0.89241439        nan        nan 0.89241439        nan\n",
      "        nan 0.89241439        nan        nan 0.89241439        nan\n",
      "        nan 0.89429419        nan        nan 0.89429419        nan\n",
      "        nan 0.89429419        nan        nan 0.89429419        nan\n",
      "        nan 0.89429419        nan        nan 0.89429419        nan\n",
      "        nan 0.89612051        nan        nan 0.89612051        nan\n",
      "        nan 0.89612051        nan        nan 0.89612051        nan\n",
      "        nan 0.89612051        nan        nan 0.89612051        nan\n",
      "        nan 0.89793876        nan        nan 0.89793876        nan\n",
      "        nan 0.89793876        nan        nan 0.89793876        nan\n",
      "        nan 0.89793876        nan        nan 0.89793876        nan\n",
      "        nan 0.89981109        nan        nan 0.89981109        nan\n",
      "        nan 0.89981109        nan        nan 0.89981109        nan\n",
      "        nan 0.89981109        nan        nan 0.89981109        nan\n",
      "        nan 0.90175946        nan        nan 0.90175946        nan\n",
      "        nan 0.90175946        nan        nan 0.90175946        nan\n",
      "        nan 0.90175946        nan        nan 0.90175946        nan\n",
      "        nan 0.90385881        nan        nan 0.90385881        nan\n",
      "        nan 0.90385881        nan        nan 0.90385881        nan\n",
      "        nan 0.90385881        nan        nan 0.90385881        nan\n",
      "        nan 0.90613889        nan        nan 0.90613889        nan\n",
      "        nan 0.90613889        nan        nan 0.90613889        nan\n",
      "        nan 0.90613889        nan        nan 0.90613889        nan\n",
      "        nan 0.90874486        nan        nan 0.90874486        nan\n",
      "        nan 0.90874486        nan        nan 0.90874486        nan\n",
      "        nan 0.90874486        nan        nan 0.90874486        nan\n",
      "        nan 0.9118072         nan        nan 0.9118072         nan\n",
      "        nan 0.9118072         nan        nan 0.9118072         nan\n",
      "        nan 0.9118072         nan        nan 0.9118072         nan\n",
      "        nan 0.91550686        nan        nan 0.91550686        nan\n",
      "        nan 0.91550686        nan        nan 0.91550686        nan\n",
      "        nan 0.91550686        nan        nan 0.91550686        nan\n",
      "        nan 0.92004755        nan        nan 0.92004755        nan\n",
      "        nan 0.92004755        nan        nan 0.92004755        nan\n",
      "        nan 0.92004755        nan        nan 0.92004755        nan\n",
      "        nan 0.92568787        nan        nan 0.92568787        nan\n",
      "        nan 0.92568787        nan        nan 0.92568787        nan\n",
      "        nan 0.92568787        nan        nan 0.92568787        nan\n",
      "        nan 0.93263232        nan        nan 0.93263232        nan\n",
      "        nan 0.93263232        nan        nan 0.93263232        nan\n",
      "        nan 0.93263232        nan        nan 0.93263232        nan\n",
      "        nan 0.94095695        nan        nan 0.94095741        nan\n",
      "        nan 0.94095741        nan        nan 0.94095741        nan\n",
      "        nan 0.94095741        nan        nan 0.94095741        nan\n",
      "        nan 0.95041888        nan        nan 0.95042016        nan\n",
      "        nan 0.95042016        nan        nan 0.95042016        nan\n",
      "        nan 0.95042016        nan        nan 0.95042016        nan\n",
      "        nan 0.96057327        nan        nan 0.96056303        nan\n",
      "        nan 0.96055993        nan        nan 0.96056043        nan\n",
      "        nan 0.96056043        nan        nan 0.96056043        nan\n",
      "        nan 0.97064539        nan        nan 0.97064162        nan\n",
      "        nan 0.97064248        nan        nan 0.97064471        nan\n",
      "        nan 0.97064471        nan        nan 0.97064471        nan\n",
      "        nan 0.97979137        nan        nan 0.97999938        nan\n",
      "        nan 0.97997757        nan        nan 0.97996834        nan\n",
      "        nan 0.97996834        nan        nan 0.97996834        nan\n",
      "        nan 0.98744856        nan        nan 0.9876162         nan\n",
      "        nan 0.98766595        nan        nan 0.98770858        nan\n",
      "        nan 0.98770858        nan        nan 0.98770858        nan\n",
      "        nan 0.9928919         nan        nan 0.99315514        nan\n",
      "        nan 0.99332283        nan        nan 0.99346812        nan\n",
      "        nan 0.99346812        nan        nan 0.99346812        nan\n",
      "        nan 0.99685097        nan        nan 0.99702795        nan\n",
      "        nan 0.99708185        nan        nan 0.99718191        nan\n",
      "        nan 0.99718191        nan        nan 0.99718191        nan\n",
      "        nan 0.9989008         nan        nan 0.99905038        nan\n",
      "        nan 0.99903317        nan        nan 0.99910448        nan\n",
      "        nan 0.99910448        nan        nan 0.99910448        nan\n",
      "        nan 0.99955797        nan        nan 0.99981233        nan\n",
      "        nan 0.99983767        nan        nan 0.99981708        nan\n",
      "        nan 0.99981708        nan        nan 0.99981708        nan\n",
      "        nan 0.99981888        nan        nan 0.99998574        nan\n",
      "        nan 0.99998447        nan        nan 0.99997891        nan\n",
      "        nan 0.99997891        nan        nan 0.99997891        nan\n",
      "        nan 0.99994168        nan        nan 0.99999636        nan\n",
      "        nan 0.99999836        nan        nan 0.9999985         nan\n",
      "        nan 0.9999985         nan        nan 0.9999985         nan\n",
      "        nan 0.99997262        nan        nan 0.99999795        nan\n",
      "        nan 0.99999909        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999371        nan        nan 0.99999863        nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999371        nan        nan 0.99999991        nan\n",
      "        nan 0.99999895        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999166        nan        nan 0.99999995        nan\n",
      "        nan 0.99999982        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999904        nan        nan 0.99999982        nan\n",
      "        nan 0.99999995        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999986        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999936        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999918        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999991        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999613        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999718        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999932        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999813        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999945        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999891        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 0.99999945        nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan\n",
      "        nan 1.                nan        nan 1.                nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('XGBoost',\n",
       "                 GridSearchCV(estimator=LogisticRegression(),\n",
       "                              param_grid={'C': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n",
       "       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n",
       "       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n",
       "       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n",
       "       4.09491506e-02, 5...\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                                          'max_iter': [70, 90, 100, 500, 1000,\n",
       "                                                       2000],\n",
       "                                          'penalty': ['l1', 'l2',\n",
       "                                                      'elasticnet']},\n",
       "                              return_train_score=True, scoring='roc_auc',\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfLOGREG_gs = Pipeline(steps = [('XGBoost', grid_search)])\n",
    "clfLOGREG_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 109.85411419875572, 'max_iter': 70, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584090402030064"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8839694656488549 0.11603053435114503 0.11603053435114503 0.8836140888208269\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(score, mae, mse, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['headline_classifiers_english/LOGREG_GSCV_Classifier.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, f'headline_classifiers_english/LOGREG_GSCV_Classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.34360852, 0.27653027, 0.28933311, ..., 0.3265409 , 0.31184034,\n",
       "        0.29962072]),\n",
       " 'std_fit_time': array([0.04929935, 0.04565802, 0.04590715, ..., 0.00223934, 0.00393109,\n",
       "        0.00331537]),\n",
       " 'mean_score_time': array([0.00959654, 0.00849128, 0.00592194, ..., 0.00777917, 0.00777907,\n",
       "        0.00777454]),\n",
       " 'std_score_time': array([0.00723767, 0.00602896, 0.00112284, ..., 0.00039854, 0.00116315,\n",
       "        0.00039753]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.3, 0.3, 0.3, ..., 0.11, 0.11, 0.11],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0, 0.0, 0.0, ..., 0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, ..., 0.25, 0.25, 0.25],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, ..., 12, 12, 12],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 3, 5, ..., 7, 9, 11],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'learning_rate': 0.25,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 12,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 7},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 9},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 1},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 3},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 5},\n",
       "  {'colsample_bytree': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'learning_rate': 0.15,\n",
       "   'max_depth': 9,\n",
       "   'min_child_weight': 7},\n",
       "  ...],\n",
       " 'split0_test_score': array([0.86732951, 0.86722025, 0.86725667, ..., 0.88706911, 0.88695985,\n",
       "        0.88714559]),\n",
       " 'split1_test_score': array([0.88998816, 0.89005736, 0.88989347, ..., 0.91515979, 0.91517436,\n",
       "        0.91461714]),\n",
       " 'split2_test_score': array([0.88493672, 0.88453246, 0.88443413, ..., 0.90420468, 0.90098152,\n",
       "        0.9002859 ]),\n",
       " 'split3_test_score': array([0.88614387, 0.88614752, 0.88593223, ..., 0.91211157, 0.91103878,\n",
       "        0.90795542]),\n",
       " 'split4_test_score': array([0.88826026, 0.8882858 , 0.88807051, ..., 0.90988389, 0.91256221,\n",
       "        0.90955366]),\n",
       " 'mean_test_score': array([0.8833317 , 0.88324868, 0.8831174 , ..., 0.90568581, 0.90534334,\n",
       "        0.90391154]),\n",
       " 'std_test_score': array([0.00818723, 0.00823034, 0.00814455, ..., 0.00997443, 0.01037475,\n",
       "        0.00956074]),\n",
       " 'rank_test_score': array([7489, 7495, 7504, ..., 5849, 5924, 6195]),\n",
       " 'split0_train_score': array([0.89946551, 0.89933666, 0.8987273 , ..., 0.97697627, 0.97070243,\n",
       "        0.96441902]),\n",
       " 'split1_train_score': array([0.89322527, 0.89306806, 0.89270944, ..., 0.97306743, 0.96744122,\n",
       "        0.96231285]),\n",
       " 'split2_train_score': array([0.89651963, 0.89602954, 0.8958598 , ..., 0.9756049 , 0.9682103 ,\n",
       "        0.96478448]),\n",
       " 'split3_train_score': array([0.89656995, 0.89626274, 0.89608705, ..., 0.9723153 , 0.96801912,\n",
       "        0.96252939]),\n",
       " 'split4_train_score': array([0.89402424, 0.89377943, 0.89361603, ..., 0.97593341, 0.97003467,\n",
       "        0.96495349]),\n",
       " 'mean_train_score': array([0.89596092, 0.89569529, 0.89539992, ..., 0.97477946, 0.96888155,\n",
       "        0.96379985]),\n",
       " 'std_train_score': array([0.00219999, 0.00220301, 0.00210599, ..., 0.00178   , 0.00125811,\n",
       "        0.00114096])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x432 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_search_results(grid):\n",
    "    \"\"\"\n",
    "    Params: \n",
    "        grid: A trained GridSearchCV object.\n",
    "    \"\"\"\n",
    "    ## Results from grid search\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    means_train = results['mean_train_score']\n",
    "    stds_train = results['std_train_score']\n",
    "\n",
    "    ## Getting indexes of values per hyper-parameter\n",
    "    masks=[]\n",
    "    masks_names= list(grid.best_params_.keys())\n",
    "    for p_k, p_v in grid.best_params_.items():\n",
    "        masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "    params=grid.param_grid\n",
    "\n",
    "    ## Ploting results\n",
    "    fig, ax = plt.subplots(1,len(params),sharex='none', sharey='none',figsize=(30,6))\n",
    "    fig.suptitle('Score per parameter')\n",
    "    fig.text(0.04, 0.5, 'MEAN SCORE', va='center', rotation='vertical')\n",
    "    pram_preformace_in_best = {}\n",
    "    for i, p in enumerate(masks_names):\n",
    "        m = np.stack(masks[:i] + masks[i+1:])\n",
    "        pram_preformace_in_best\n",
    "        best_parms_mask = m.all(axis=0)\n",
    "        best_index = np.where(best_parms_mask)[0]\n",
    "        x = np.array(params[p])\n",
    "        y_1 = np.array(means_test[best_index])\n",
    "        e_1 = np.array(stds_test[best_index])\n",
    "        y_2 = np.array(means_train[best_index])\n",
    "        e_2 = np.array(stds_train[best_index])\n",
    "        ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
    "        ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "        ax[i].set_xlabel(p.upper())\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_search_results(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=45)\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5238, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    'glove/glove.6B.100d.txt',\n",
    "    tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1377000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,442,429\n",
      "Trainable params: 1,442,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                116210    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,221\n",
      "Trainable params: 116,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "               optimizer='adam', \n",
    "               metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cvaal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 3s 7ms/step - loss: 0.6250 - accuracy: 0.7289 - val_loss: 0.5273 - val_accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.3986 - accuracy: 0.8921 - val_loss: 0.4124 - val_accuracy: 0.8321\n",
      "Epoch 3/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.2470 - accuracy: 0.9414 - val_loss: 0.3695 - val_accuracy: 0.8405\n",
      "Epoch 4/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.1617 - accuracy: 0.9704 - val_loss: 0.3560 - val_accuracy: 0.8420\n",
      "Epoch 5/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.1108 - accuracy: 0.9845 - val_loss: 0.3569 - val_accuracy: 0.8382\n",
      "Epoch 6/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.0782 - accuracy: 0.9914 - val_loss: 0.3625 - val_accuracy: 0.8359\n",
      "Epoch 7/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.0568 - accuracy: 0.9952 - val_loss: 0.3713 - val_accuracy: 0.8351\n",
      "Epoch 8/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0423 - accuracy: 0.9973 - val_loss: 0.3884 - val_accuracy: 0.8328\n",
      "Epoch 9/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9983 - val_loss: 0.3983 - val_accuracy: 0.8351\n",
      "Epoch 10/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9987 - val_loss: 0.4116 - val_accuracy: 0.8321\n",
      "Epoch 11/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9990 - val_loss: 0.4240 - val_accuracy: 0.8313\n",
      "Epoch 12/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9992 - val_loss: 0.4371 - val_accuracy: 0.8305\n",
      "Epoch 13/100\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.4500 - val_accuracy: 0.8275\n",
      "Epoch 14/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.4607 - val_accuracy: 0.8282\n",
      "Epoch 15/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9996 - val_loss: 0.4745 - val_accuracy: 0.8290\n",
      "Epoch 16/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.4867 - val_accuracy: 0.8305\n",
      "Epoch 17/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.4976 - val_accuracy: 0.8298\n",
      "Epoch 18/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.5100 - val_accuracy: 0.8313\n",
      "Epoch 19/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.5219 - val_accuracy: 0.8305\n",
      "Epoch 20/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.5316 - val_accuracy: 0.8313\n",
      "Epoch 21/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.5433 - val_accuracy: 0.8313\n",
      "Epoch 22/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.5528 - val_accuracy: 0.8321\n",
      "Epoch 23/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.5638 - val_accuracy: 0.8321\n",
      "Epoch 24/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.5729 - val_accuracy: 0.8305\n",
      "Epoch 25/100\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.5832 - val_accuracy: 0.8290\n",
      "Epoch 26/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.5946 - val_accuracy: 0.8282\n",
      "Epoch 27/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.6032 - val_accuracy: 0.8290\n",
      "Epoch 28/100\n",
      "164/164 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.6147 - val_accuracy: 0.8290\n",
      "Epoch 29/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.6229 - val_accuracy: 0.8267\n",
      "Epoch 30/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.6331 - val_accuracy: 0.8275\n",
      "Epoch 31/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.6404 - val_accuracy: 0.8267\n",
      "Epoch 32/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.6498 - val_accuracy: 0.8275\n",
      "Epoch 33/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.6582 - val_accuracy: 0.8267\n",
      "Epoch 34/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 9.5795e-04 - accuracy: 0.9998 - val_loss: 0.6687 - val_accuracy: 0.8252\n",
      "Epoch 35/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 8.7437e-04 - accuracy: 0.9998 - val_loss: 0.6782 - val_accuracy: 0.8244\n",
      "Epoch 36/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 8.0888e-04 - accuracy: 0.9998 - val_loss: 0.6864 - val_accuracy: 0.8244\n",
      "Epoch 37/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 7.5833e-04 - accuracy: 0.9998 - val_loss: 0.6950 - val_accuracy: 0.8229\n",
      "Epoch 38/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 7.1061e-04 - accuracy: 0.9998 - val_loss: 0.7052 - val_accuracy: 0.8214\n",
      "Epoch 39/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 6.7175e-04 - accuracy: 0.9998 - val_loss: 0.7136 - val_accuracy: 0.8229\n",
      "Epoch 40/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.4940e-04 - accuracy: 0.9996 - val_loss: 0.7198 - val_accuracy: 0.8229\n",
      "Epoch 41/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.0274e-04 - accuracy: 0.9998 - val_loss: 0.7308 - val_accuracy: 0.8221\n",
      "Epoch 42/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 5.6274e-04 - accuracy: 0.9998 - val_loss: 0.7424 - val_accuracy: 0.8198\n",
      "Epoch 43/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 5.3280e-04 - accuracy: 0.9998 - val_loss: 0.7492 - val_accuracy: 0.8221\n",
      "Epoch 44/100\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 5.0640e-04 - accuracy: 0.9998 - val_loss: 0.7563 - val_accuracy: 0.8221\n",
      "Epoch 45/100\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 4.9094e-04 - accuracy: 0.9998 - val_loss: 0.7637 - val_accuracy: 0.8221\n",
      "Epoch 46/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 4.6936e-04 - accuracy: 0.9998 - val_loss: 0.7730 - val_accuracy: 0.8221\n",
      "Epoch 47/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 4.4858e-04 - accuracy: 0.9998 - val_loss: 0.7831 - val_accuracy: 0.8191\n",
      "Epoch 48/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 4.3105e-04 - accuracy: 0.9998 - val_loss: 0.7894 - val_accuracy: 0.8214\n",
      "Epoch 49/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 4.1519e-04 - accuracy: 0.9998 - val_loss: 0.7995 - val_accuracy: 0.8198\n",
      "Epoch 50/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 4.1381e-04 - accuracy: 0.9996 - val_loss: 0.8061 - val_accuracy: 0.8198\n",
      "Epoch 51/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.9189e-04 - accuracy: 0.9998 - val_loss: 0.8167 - val_accuracy: 0.8183\n",
      "Epoch 52/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.7875e-04 - accuracy: 0.9998 - val_loss: 0.8270 - val_accuracy: 0.8191\n",
      "Epoch 53/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.6723e-04 - accuracy: 0.9998 - val_loss: 0.8341 - val_accuracy: 0.8183\n",
      "Epoch 54/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 3.5680e-04 - accuracy: 0.9998 - val_loss: 0.8425 - val_accuracy: 0.8176\n",
      "Epoch 55/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.4815e-04 - accuracy: 0.9998 - val_loss: 0.8518 - val_accuracy: 0.8191\n",
      "Epoch 56/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 3.4103e-04 - accuracy: 0.9998 - val_loss: 0.8572 - val_accuracy: 0.8183\n",
      "Epoch 57/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.3753e-04 - accuracy: 0.9998 - val_loss: 0.8652 - val_accuracy: 0.8160\n",
      "Epoch 58/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.3294e-04 - accuracy: 0.9998 - val_loss: 0.8727 - val_accuracy: 0.8160\n",
      "Epoch 59/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.2480e-04 - accuracy: 0.9998 - val_loss: 0.8834 - val_accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.2205e-04 - accuracy: 0.9998 - val_loss: 0.8899 - val_accuracy: 0.8153\n",
      "Epoch 61/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.1525e-04 - accuracy: 0.9998 - val_loss: 0.8996 - val_accuracy: 0.8160\n",
      "Epoch 62/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.0993e-04 - accuracy: 0.9998 - val_loss: 0.9082 - val_accuracy: 0.8153\n",
      "Epoch 63/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.0814e-04 - accuracy: 0.9998 - val_loss: 0.9153 - val_accuracy: 0.8153\n",
      "Epoch 64/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.0299e-04 - accuracy: 0.9998 - val_loss: 0.9242 - val_accuracy: 0.8145\n",
      "Epoch 65/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.9940e-04 - accuracy: 0.9998 - val_loss: 0.9335 - val_accuracy: 0.8145\n",
      "Epoch 66/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 2.9522e-04 - accuracy: 0.9998 - val_loss: 0.9418 - val_accuracy: 0.8145\n",
      "Epoch 67/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.9508e-04 - accuracy: 0.9998 - val_loss: 0.9498 - val_accuracy: 0.8145\n",
      "Epoch 68/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.9467e-04 - accuracy: 0.9998 - val_loss: 0.9557 - val_accuracy: 0.8145\n",
      "Epoch 69/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.9060e-04 - accuracy: 0.9998 - val_loss: 0.9648 - val_accuracy: 0.8145\n",
      "Epoch 70/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.8770e-04 - accuracy: 0.9998 - val_loss: 0.9741 - val_accuracy: 0.8145\n",
      "Epoch 71/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.8648e-04 - accuracy: 0.9998 - val_loss: 0.9839 - val_accuracy: 0.8145\n",
      "Epoch 72/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.8362e-04 - accuracy: 0.9998 - val_loss: 0.9924 - val_accuracy: 0.8145\n",
      "Epoch 73/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.8183e-04 - accuracy: 0.9998 - val_loss: 1.0010 - val_accuracy: 0.8145\n",
      "Epoch 74/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.8104e-04 - accuracy: 0.9998 - val_loss: 1.0104 - val_accuracy: 0.8153\n",
      "Epoch 75/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7932e-04 - accuracy: 0.9998 - val_loss: 1.0196 - val_accuracy: 0.8153\n",
      "Epoch 76/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7808e-04 - accuracy: 0.9998 - val_loss: 1.0268 - val_accuracy: 0.8153\n",
      "Epoch 77/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7658e-04 - accuracy: 0.9998 - val_loss: 1.0347 - val_accuracy: 0.8153\n",
      "Epoch 78/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7597e-04 - accuracy: 0.9998 - val_loss: 1.0435 - val_accuracy: 0.8153\n",
      "Epoch 79/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7489e-04 - accuracy: 0.9998 - val_loss: 1.0528 - val_accuracy: 0.8145\n",
      "Epoch 80/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7423e-04 - accuracy: 0.9998 - val_loss: 1.0594 - val_accuracy: 0.8153\n",
      "Epoch 81/100\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 2.7333e-04 - accuracy: 0.9998 - val_loss: 1.0689 - val_accuracy: 0.8145\n",
      "Epoch 82/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7282e-04 - accuracy: 0.9998 - val_loss: 1.0759 - val_accuracy: 0.8145\n",
      "Epoch 83/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7248e-04 - accuracy: 0.9998 - val_loss: 1.0837 - val_accuracy: 0.8145\n",
      "Epoch 84/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7146e-04 - accuracy: 0.9998 - val_loss: 1.0918 - val_accuracy: 0.8137\n",
      "Epoch 85/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7207e-04 - accuracy: 0.9998 - val_loss: 1.0993 - val_accuracy: 0.8122\n",
      "Epoch 86/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 2.7183e-04 - accuracy: 0.9998 - val_loss: 1.1111 - val_accuracy: 0.8153\n",
      "Epoch 87/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7063e-04 - accuracy: 0.9998 - val_loss: 1.1187 - val_accuracy: 0.8145\n",
      "Epoch 88/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7240e-04 - accuracy: 0.9998 - val_loss: 1.1252 - val_accuracy: 0.8137\n",
      "Epoch 89/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.7000e-04 - accuracy: 0.9998 - val_loss: 1.1336 - val_accuracy: 0.8130\n",
      "Epoch 90/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6894e-04 - accuracy: 0.9998 - val_loss: 1.1427 - val_accuracy: 0.8130\n",
      "Epoch 91/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6919e-04 - accuracy: 0.9998 - val_loss: 1.1506 - val_accuracy: 0.8122\n",
      "Epoch 92/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6950e-04 - accuracy: 0.9998 - val_loss: 1.1561 - val_accuracy: 0.8122\n",
      "Epoch 93/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6874e-04 - accuracy: 0.9998 - val_loss: 1.1658 - val_accuracy: 0.8122\n",
      "Epoch 94/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 2.6853e-04 - accuracy: 0.9998 - val_loss: 1.1746 - val_accuracy: 0.8122\n",
      "Epoch 95/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6825e-04 - accuracy: 0.9998 - val_loss: 1.1842 - val_accuracy: 0.8130\n",
      "Epoch 96/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6740e-04 - accuracy: 0.9998 - val_loss: 1.1922 - val_accuracy: 0.8137\n",
      "Epoch 97/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6779e-04 - accuracy: 0.9998 - val_loss: 1.2000 - val_accuracy: 0.8130\n",
      "Epoch 98/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6762e-04 - accuracy: 0.9998 - val_loss: 1.2094 - val_accuracy: 0.8130\n",
      "Epoch 99/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 2.6741e-04 - accuracy: 0.9998 - val_loss: 1.2163 - val_accuracy: 0.8122\n",
      "Epoch 100/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 2.6703e-04 - accuracy: 0.9998 - val_loss: 1.2250 - val_accuracy: 0.8122\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9998090863227844\n",
      "Testing Accuracy:  0.8122137188911438\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(f\"Training Accuracy: {accuracy}\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f\"Testing Accuracy:  {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Church of England Declares ‘Jesus Is Non-Binary’\n"
     ]
    }
   ],
   "source": [
    "print(sentences_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[484, 4, 932, 506, 10, 1112]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           688500    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 50)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                510       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 689,021\n",
      "Trainable params: 689,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "524/524 [==============================] - 5s 8ms/step - loss: 0.6134 - accuracy: 0.7003 - val_loss: 0.4681 - val_accuracy: 0.8023\n",
      "Epoch 2/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.3042 - accuracy: 0.8881 - val_loss: 0.3346 - val_accuracy: 0.8534\n",
      "Epoch 3/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.1335 - accuracy: 0.9586 - val_loss: 0.3388 - val_accuracy: 0.8603\n",
      "Epoch 4/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0532 - accuracy: 0.9878 - val_loss: 0.3775 - val_accuracy: 0.8466\n",
      "Epoch 5/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0196 - accuracy: 0.9981 - val_loss: 0.4128 - val_accuracy: 0.8389\n",
      "Epoch 6/20\n",
      "524/524 [==============================] - 4s 9ms/step - loss: 0.0085 - accuracy: 0.9994 - val_loss: 0.4433 - val_accuracy: 0.8389\n",
      "Epoch 7/20\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.4853 - val_accuracy: 0.8435\n",
      "Epoch 8/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.5122 - val_accuracy: 0.8389\n",
      "Epoch 9/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.5397 - val_accuracy: 0.8382\n",
      "Epoch 10/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.5548 - val_accuracy: 0.8389\n",
      "Epoch 11/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.5714 - val_accuracy: 0.8397\n",
      "Epoch 12/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.5880 - val_accuracy: 0.8366\n",
      "Epoch 13/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 8.8158e-04 - accuracy: 0.9998 - val_loss: 0.6066 - val_accuracy: 0.8389\n",
      "Epoch 14/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 8.5662e-04 - accuracy: 0.9998 - val_loss: 0.6380 - val_accuracy: 0.8328\n",
      "Epoch 15/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.6332 - val_accuracy: 0.8374\n",
      "Epoch 16/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.6384 - val_accuracy: 0.8382\n",
      "Epoch 17/20\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 7.2638e-04 - accuracy: 0.9998 - val_loss: 0.6564 - val_accuracy: 0.8366\n",
      "Epoch 18/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.6866 - val_accuracy: 0.8305\n",
      "Epoch 19/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.6705 - val_accuracy: 0.8389\n",
      "Epoch 20/20\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 6.9663e-04 - accuracy: 0.9998 - val_loss: 0.6790 - val_accuracy: 0.8374\n",
      "Training Accuracy: 0.9998\n",
      "Testing Accuracy:  0.8374\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1377000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 100)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,021\n",
      "Trainable params: 1,378,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=maxlen, \n",
    "                           trainable=True))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "524/524 [==============================] - 4s 6ms/step - loss: 0.6752 - accuracy: 0.5836 - val_loss: 0.6106 - val_accuracy: 0.7252\n",
      "Epoch 2/50\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5121 - accuracy: 0.7591 - val_loss: 0.4503 - val_accuracy: 0.7863\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.3502 - accuracy: 0.8511 - val_loss: 0.4069 - val_accuracy: 0.8038\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.2377 - accuracy: 0.9049 - val_loss: 0.3776 - val_accuracy: 0.8252\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.1546 - accuracy: 0.9488 - val_loss: 0.3853 - val_accuracy: 0.8313\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0933 - accuracy: 0.9727 - val_loss: 0.4012 - val_accuracy: 0.8382\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 0.4263 - val_accuracy: 0.8382\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0301 - accuracy: 0.9939 - val_loss: 0.4756 - val_accuracy: 0.8298\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0164 - accuracy: 0.9979 - val_loss: 0.4876 - val_accuracy: 0.8305\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.5246 - val_accuracy: 0.8275\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.5452 - val_accuracy: 0.8351\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.5720 - val_accuracy: 0.8359\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5945 - val_accuracy: 0.8374\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.6481 - val_accuracy: 0.8275\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.6582 - val_accuracy: 0.8412\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.6661 - val_accuracy: 0.8298\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.6759 - val_accuracy: 0.8351\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 8.0044e-04 - accuracy: 0.9998 - val_loss: 0.7006 - val_accuracy: 0.8420\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.7172 - val_accuracy: 0.8397\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 8.4509e-04 - accuracy: 0.9998 - val_loss: 0.7411 - val_accuracy: 0.8313\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 8.2911e-04 - accuracy: 0.9998 - val_loss: 0.7580 - val_accuracy: 0.8298\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 8.6121e-04 - accuracy: 0.9998 - val_loss: 0.7708 - val_accuracy: 0.8267\n",
      "Epoch 23/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.7789 - val_accuracy: 0.8298\n",
      "Epoch 24/50\n",
      "524/524 [==============================] - 5s 10ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.7854 - val_accuracy: 0.8344\n",
      "Epoch 25/50\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 7.0640e-04 - accuracy: 0.9998 - val_loss: 0.7904 - val_accuracy: 0.8344\n",
      "Epoch 26/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.8041 - val_accuracy: 0.8366\n",
      "Epoch 27/50\n",
      "524/524 [==============================] - 6s 11ms/step - loss: 7.6467e-04 - accuracy: 0.9998 - val_loss: 0.8171 - val_accuracy: 0.8344\n",
      "Epoch 28/50\n",
      "524/524 [==============================] - 8s 16ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.8316 - val_accuracy: 0.8359\n",
      "Epoch 29/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 7.4102e-04 - accuracy: 0.9998 - val_loss: 0.8295 - val_accuracy: 0.8328\n",
      "Epoch 30/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8633 - val_accuracy: 0.8405\n",
      "Epoch 31/50\n",
      "524/524 [==============================] - 6s 12ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.8414 - val_accuracy: 0.8420\n",
      "Epoch 32/50\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.8582 - val_accuracy: 0.8412\n",
      "Epoch 33/50\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 7.4515e-04 - accuracy: 0.9998 - val_loss: 0.8791 - val_accuracy: 0.8359\n",
      "Epoch 34/50\n",
      "524/524 [==============================] - 5s 9ms/step - loss: 7.4653e-04 - accuracy: 0.9998 - val_loss: 0.8589 - val_accuracy: 0.8443\n",
      "Epoch 35/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8703 - val_accuracy: 0.8374\n",
      "Epoch 36/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 9.3836e-04 - accuracy: 0.9994 - val_loss: 1.0329 - val_accuracy: 0.8244\n",
      "Epoch 37/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.8863 - val_accuracy: 0.8382\n",
      "Epoch 38/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 6.7394e-04 - accuracy: 0.9998 - val_loss: 0.9952 - val_accuracy: 0.8244\n",
      "Epoch 39/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 8.7004e-04 - accuracy: 0.9998 - val_loss: 1.0313 - val_accuracy: 0.8260\n",
      "Epoch 40/50\n",
      "524/524 [==============================] - 6s 11ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.9006 - val_accuracy: 0.8389\n",
      "Epoch 41/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 7.5371e-04 - accuracy: 0.9998 - val_loss: 0.9083 - val_accuracy: 0.8351\n",
      "Epoch 42/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 6.4848e-04 - accuracy: 0.9998 - val_loss: 0.9270 - val_accuracy: 0.8374\n",
      "Epoch 43/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 8.4693e-04 - accuracy: 0.9998 - val_loss: 1.1729 - val_accuracy: 0.8115\n",
      "Epoch 44/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.1971 - val_accuracy: 0.8107\n",
      "Epoch 45/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 7.6540e-04 - accuracy: 0.9998 - val_loss: 0.9586 - val_accuracy: 0.8313\n",
      "Epoch 46/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.9954 - val_accuracy: 0.8305\n",
      "Epoch 47/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 7.1456e-04 - accuracy: 0.9998 - val_loss: 1.0483 - val_accuracy: 0.8282\n",
      "Epoch 48/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.9754 - val_accuracy: 0.8359\n",
      "Epoch 49/50\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 6.7121e-04 - accuracy: 0.9998 - val_loss: 1.0040 - val_accuracy: 0.8313\n",
      "Epoch 50/50\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.0982 - val_accuracy: 0.8206\n",
      "Training Accuracy: 0.9998\n",
      "Testing Accuracy:  0.8206\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
