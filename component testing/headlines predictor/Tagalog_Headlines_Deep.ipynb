{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Rating</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaned tokenized</th>\n",
       "      <th>period%</th>\n",
       "      <th>comma%</th>\n",
       "      <th>colon%</th>\n",
       "      <th>semicolon%</th>\n",
       "      <th>question mark%</th>\n",
       "      <th>exclamation mark%</th>\n",
       "      <th>dash%</th>\n",
       "      <th>apostrophe%</th>\n",
       "      <th>close parenthesis%</th>\n",
       "      <th>capitalized%</th>\n",
       "      <th>slang words%</th>\n",
       "      <th>curse words%</th>\n",
       "      <th>with numericals%</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lalaki patay sa pamamaril sa Tondo, Maynila</td>\n",
       "      <td>Real</td>\n",
       "      <td>lalaki patay pamamaril tondo maynila</td>\n",
       "      <td>[lalaki, patay, pamamaril, tondo, ,, maynila]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[lalaki patay, patay pamamaril, pamamaril tond...</td>\n",
       "      <td>[lalaki patay pamamaril, patay pamamaril tondo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50 Pinoy na naipit sa kaguluhan sa Sudan, nail...</td>\n",
       "      <td>Real</td>\n",
       "      <td>50 pinoy naipit kaguluhan sudan nailikas</td>\n",
       "      <td>[50, pinoy, naipit, kaguluhan, sudan, ,, naili...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>[50 pinoy, pinoy naipit, naipit kaguluhan, kag...</td>\n",
       "      <td>[50 pinoy naipit, pinoy naipit kaguluhan, naip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#BoyingResign: Netizens galit kay DOJ Chief Re...</td>\n",
       "      <td>Real</td>\n",
       "      <td>boyingresign netizens galit kay doj chief remu...</td>\n",
       "      <td>[#, boyingresign, :, netizens, galit, kay, doj...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[boyingresign netizens, netizens galit, galit ...</td>\n",
       "      <td>[boyingresign netizens galit, netizens galit k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘Backdoor entry’ ng Grab sa motorcycle taxi pi...</td>\n",
       "      <td>Real</td>\n",
       "      <td>backdoor entry grab motorcycle taxi pilot pina...</td>\n",
       "      <td>[‘, backdoor, entry, ’, grab, motorcycle, taxi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[backdoor entry, entry grab, grab motorcycle, ...</td>\n",
       "      <td>[backdoor entry grab, entry grab motorcycle, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doktor nangangamba na na-mild stroke si De Lima</td>\n",
       "      <td>Real</td>\n",
       "      <td>doktor nangangamba mild stroke de</td>\n",
       "      <td>[doktor, nangangamba, na-mild, stroke, de]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[doktor nangangamba, nangangamba mild, mild st...</td>\n",
       "      <td>[doktor nangangamba mild, nangangamba mild str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>Remembering Marky Cielo, Proud Igorot and Star...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>remembering marky cielo proud igorot and stars...</td>\n",
       "      <td>[remembering, marky, cielo, ,, proud, igorot, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[remembering marky, marky cielo, cielo proud, ...</td>\n",
       "      <td>[remembering marky cielo, marky cielo proud, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>Netizen, inilabas ang sekretong galit dahil la...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>netizen inilabas sekretong galit lang my day k...</td>\n",
       "      <td>[netizen, ,, inilabas, sekretong, galit, lang,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[netizen inilabas, inilabas sekretong, sekreto...</td>\n",
       "      <td>[netizen inilabas sekretong, inilabas sekreton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>Pinoy Vlogger na tumulong kay Nas Daily noon, ...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>pinoy vlogger tumulong kay nas daily nagsalita...</td>\n",
       "      <td>[pinoy, vlogger, tumulong, kay, nas, daily, ,,...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[pinoy vlogger, vlogger tumulong, tumulong kay...</td>\n",
       "      <td>[pinoy vlogger tumulong, vlogger tumulong kay,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>GRABE! UNANG GABI NG LAMAY SA BUROL NI KRIS AQ...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>grabe unang gabi lamay burol kris aquino dinag...</td>\n",
       "      <td>[grabe, !, unang, gabi, lamay, burol, kris, aq...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[grabe unang, unang gabi, gabi lamay, lamay bu...</td>\n",
       "      <td>[grabe unang gabi, unang gabi lamay, gabi lama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>Isang tattoo artist may walong asawa at magka...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>tattoo artist walong asawa magkakasamang nanin...</td>\n",
       "      <td>[tattoo, artist, walong, asawa, magkakasamang,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[tattoo artist, artist walong, walong asawa, a...</td>\n",
       "      <td>[tattoo artist walong, artist walong asawa, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3452 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement Rating  \\\n",
       "0           Lalaki patay sa pamamaril sa Tondo, Maynila   Real   \n",
       "1     50 Pinoy na naipit sa kaguluhan sa Sudan, nail...   Real   \n",
       "2     #BoyingResign: Netizens galit kay DOJ Chief Re...   Real   \n",
       "3     ‘Backdoor entry’ ng Grab sa motorcycle taxi pi...   Real   \n",
       "4       Doktor nangangamba na na-mild stroke si De Lima   Real   \n",
       "...                                                 ...    ...   \n",
       "3447  Remembering Marky Cielo, Proud Igorot and Star...   Fake   \n",
       "3448  Netizen, inilabas ang sekretong galit dahil la...   Fake   \n",
       "3449  Pinoy Vlogger na tumulong kay Nas Daily noon, ...   Fake   \n",
       "3450  GRABE! UNANG GABI NG LAMAY SA BUROL NI KRIS AQ...   Fake   \n",
       "3451   Isang tattoo artist may walong asawa at magka...   Fake   \n",
       "\n",
       "                                                cleaned  \\\n",
       "0                  lalaki patay pamamaril tondo maynila   \n",
       "1              50 pinoy naipit kaguluhan sudan nailikas   \n",
       "2     boyingresign netizens galit kay doj chief remu...   \n",
       "3     backdoor entry grab motorcycle taxi pilot pina...   \n",
       "4                     doktor nangangamba mild stroke de   \n",
       "...                                                 ...   \n",
       "3447  remembering marky cielo proud igorot and stars...   \n",
       "3448  netizen inilabas sekretong galit lang my day k...   \n",
       "3449  pinoy vlogger tumulong kay nas daily nagsalita...   \n",
       "3450  grabe unang gabi lamay burol kris aquino dinag...   \n",
       "3451  tattoo artist walong asawa magkakasamang nanin...   \n",
       "\n",
       "                                      cleaned tokenized   period%    comma%  \\\n",
       "0         [lalaki, patay, pamamaril, tondo, ,, maynila]  0.000000  0.125000   \n",
       "1     [50, pinoy, naipit, kaguluhan, sudan, ,, naili...  0.000000  0.090909   \n",
       "2     [#, boyingresign, :, netizens, galit, kay, doj...  0.000000  0.000000   \n",
       "3     [‘, backdoor, entry, ’, grab, motorcycle, taxi...  0.000000  0.000000   \n",
       "4            [doktor, nangangamba, na-mild, stroke, de]  0.000000  0.000000   \n",
       "...                                                 ...       ...       ...   \n",
       "3447  [remembering, marky, cielo, ,, proud, igorot, ...  0.000000  0.083333   \n",
       "3448  [netizen, ,, inilabas, sekretong, galit, lang,...  0.000000  0.055556   \n",
       "3449  [pinoy, vlogger, tumulong, kay, nas, daily, ,,...  0.041667  0.083333   \n",
       "3450  [grabe, !, unang, gabi, lamay, burol, kris, aq...  0.050000  0.050000   \n",
       "3451  [tattoo, artist, walong, asawa, magkakasamang,...  0.000000  0.000000   \n",
       "\n",
       "        colon%  semicolon%  question mark%  exclamation mark%     dash%  \\\n",
       "0     0.000000    0.000000             0.0           0.000000  0.000000   \n",
       "1     0.000000    0.000000             0.0           0.000000  0.000000   \n",
       "2     0.055556    0.000000             0.0           0.000000  0.055556   \n",
       "3     0.000000    0.000000             0.0           0.000000  0.000000   \n",
       "4     0.000000    0.000000             0.0           0.000000  0.125000   \n",
       "...        ...         ...             ...                ...       ...   \n",
       "3447  0.000000    0.000000             0.0           0.083333  0.000000   \n",
       "3448  0.000000    0.055556             0.0           0.000000  0.000000   \n",
       "3449  0.041667    0.000000             0.0           0.000000  0.000000   \n",
       "3450  0.000000    0.000000             0.0           0.050000  0.050000   \n",
       "3451  0.000000    0.000000             0.0           0.000000  0.000000   \n",
       "\n",
       "      apostrophe%  close parenthesis%  capitalized%  slang words%  \\\n",
       "0             0.0                 0.0      0.000000           0.0   \n",
       "1             0.0                 0.0      0.000000           0.0   \n",
       "2             0.0                 0.0      0.055556           0.0   \n",
       "3             0.0                 0.0      0.000000           0.0   \n",
       "4             0.0                 0.0      0.000000           0.0   \n",
       "...           ...                 ...           ...           ...   \n",
       "3447          0.0                 0.0      0.000000           0.0   \n",
       "3448          0.0                 0.0      0.000000           0.0   \n",
       "3449          0.0                 0.0      0.000000           0.0   \n",
       "3450          0.0                 0.0      0.850000           0.0   \n",
       "3451          0.0                 0.0      0.000000           0.0   \n",
       "\n",
       "      curse words%  with numericals%  \\\n",
       "0              0.0          0.000000   \n",
       "1              0.0          0.090909   \n",
       "2              0.0          0.000000   \n",
       "3              0.0          0.000000   \n",
       "4              0.0          0.000000   \n",
       "...            ...               ...   \n",
       "3447           0.0          0.000000   \n",
       "3448           0.0          0.000000   \n",
       "3449           0.0          0.000000   \n",
       "3450           0.0          0.000000   \n",
       "3451           0.0          0.000000   \n",
       "\n",
       "                                                bigrams  \\\n",
       "0     [lalaki patay, patay pamamaril, pamamaril tond...   \n",
       "1     [50 pinoy, pinoy naipit, naipit kaguluhan, kag...   \n",
       "2     [boyingresign netizens, netizens galit, galit ...   \n",
       "3     [backdoor entry, entry grab, grab motorcycle, ...   \n",
       "4     [doktor nangangamba, nangangamba mild, mild st...   \n",
       "...                                                 ...   \n",
       "3447  [remembering marky, marky cielo, cielo proud, ...   \n",
       "3448  [netizen inilabas, inilabas sekretong, sekreto...   \n",
       "3449  [pinoy vlogger, vlogger tumulong, tumulong kay...   \n",
       "3450  [grabe unang, unang gabi, gabi lamay, lamay bu...   \n",
       "3451  [tattoo artist, artist walong, walong asawa, a...   \n",
       "\n",
       "                                               trigrams  \n",
       "0     [lalaki patay pamamaril, patay pamamaril tondo...  \n",
       "1     [50 pinoy naipit, pinoy naipit kaguluhan, naip...  \n",
       "2     [boyingresign netizens galit, netizens galit k...  \n",
       "3     [backdoor entry grab, entry grab motorcycle, g...  \n",
       "4     [doktor nangangamba mild, nangangamba mild str...  \n",
       "...                                                 ...  \n",
       "3447  [remembering marky cielo, marky cielo proud, c...  \n",
       "3448  [netizen inilabas sekretong, inilabas sekreton...  \n",
       "3449  [pinoy vlogger tumulong, vlogger tumulong kay,...  \n",
       "3450  [grabe unang gabi, unang gabi lamay, gabi lama...  \n",
       "3451  [tattoo artist walong, artist walong asawa, wa...  \n",
       "\n",
       "[3452 rows x 19 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('Tagalog_Headlines_EngFeatures')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Rating'] = le.fit_transform(df.Rating.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['Statement'].values\n",
    "y = df['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lalaki patay sa pamamaril sa Tondo, Maynila',\n",
       "       '50 Pinoy na naipit sa kaguluhan sa Sudan, nailikas na',\n",
       "       '#BoyingResign: Netizens galit kay DOJ Chief Remulla matapos mahulihan ng ‘high-grade’ marijuana ang anak',\n",
       "       ...,\n",
       "       'Pinoy Vlogger na tumulong kay Nas Daily noon, nagsalita na: Parang ginamit lang ako, naabuso. Hindi ko na sya kilala',\n",
       "       'GRABE! UNANG GABI NG LAMAY SA BUROL NI KRIS AQUINO DINAGSA NG MGA TAO, KAIBIGAN AT KAMAG-ANAK .',\n",
       "       ' Isang tattoo artist may walong asawa at magkakasamang naninirahan sa iisang bubong'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=49, stratify=y)\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 572, 3, 33, 445, 2, 3835, 66, 13, 1, 2, 121, 345],\n",
       " [795, 24, 565, 2, 2238, 3229, 415, 566, 1698, 1],\n",
       " [3179, 3180, 4015, 4, 26, 161, 9, 3725, 4, 2214, 2, 15, 84],\n",
       " [150, 1347, 747, 1, 77, 2, 7, 67, 1, 3237, 152],\n",
       " [634, 3272, 3, 1, 3, 270, 2, 50, 3083],\n",
       " [7, 845, 1, 1287, 4284, 30, 2, 78, 9, 4046],\n",
       " [4885,\n",
       "  415,\n",
       "  4886,\n",
       "  211,\n",
       "  2,\n",
       "  517,\n",
       "  30,\n",
       "  525,\n",
       "  1,\n",
       "  3043,\n",
       "  3044,\n",
       "  1,\n",
       "  2007,\n",
       "  4887,\n",
       "  628,\n",
       "  106],\n",
       " [92, 1695, 4, 2167, 2, 1696, 2, 39, 3223, 331, 55],\n",
       " [1752, 796, 482, 744, 636, 1362, 2, 2, 301, 11, 3274, 2, 226],\n",
       " [27, 1557, 1, 2471, 8, 989, 2472, 3631],\n",
       " [2915, 916, 1, 254, 636, 3046, 3, 5, 1826, 2852],\n",
       " [586,\n",
       "  220,\n",
       "  677,\n",
       "  4,\n",
       "  12,\n",
       "  3,\n",
       "  16,\n",
       "  631,\n",
       "  602,\n",
       "  1343,\n",
       "  95,\n",
       "  18,\n",
       "  1007,\n",
       "  465,\n",
       "  91,\n",
       "  58,\n",
       "  1078],\n",
       " [2070, 2503, 1, 5, 3, 2480, 1, 192, 263, 1242, 1, 212],\n",
       " [1, 955, 2, 357, 4, 568, 357, 163, 3, 1135, 3, 2344, 2, 2138],\n",
       " [212, 3, 4, 1355, 365, 2008, 314, 19, 1239, 98],\n",
       " [7, 583, 403, 11, 3738, 2, 1272, 1, 664, 2, 1943, 4013],\n",
       " [243, 227, 1090, 1, 5, 1089, 3, 45, 1113, 952, 1359, 1],\n",
       " [674, 3, 3403, 2, 1577, 1470, 13, 2956, 4, 2, 800],\n",
       " [842, 9, 19, 110, 316, 2, 135, 1436, 6, 215, 16, 110, 1923],\n",
       " [4, 2, 853, 519, 2976, 1064, 6, 3750, 1, 1, 139, 128],\n",
       " [1039, 3709, 2366, 167, 3, 1, 140, 3],\n",
       " [7, 61, 1010, 2, 32, 1, 4044, 2, 4235, 13, 1, 248, 399],\n",
       " [3497, 1, 74, 648, 2409, 1320, 3, 3498, 2413],\n",
       " [7, 583, 1505, 4, 15, 5, 4036, 1173, 23, 1, 135, 9, 1, 667, 1440, 1, 57, 133],\n",
       " [162, 4, 314, 3, 1937, 1, 4371, 93, 11, 204, 13, 1, 545, 2],\n",
       " [1537, 822, 542, 3, 88, 423],\n",
       " [442, 18, 315, 27, 210, 184, 1, 1142, 571, 258, 2326, 3],\n",
       " [1882, 1467, 1188, 783, 8, 669, 868, 1, 7, 3044, 1, 15, 1127],\n",
       " [42, 54, 1, 591, 1, 792, 152],\n",
       " [688, 86, 1, 780, 65, 1, 1929, 438, 3, 346, 2, 387, 1395, 4, 15, 5, 66, 284],\n",
       " [595, 489, 1108, 2, 252, 4, 825, 3132, 950, 3132, 950],\n",
       " [51, 133, 1, 280, 6, 690, 1309, 1, 349, 198, 40, 13, 1, 186, 172],\n",
       " [4, 197, 3, 2752, 235, 986, 3, 16, 3813, 6, 4, 15, 14, 3, 469],\n",
       " [4376, 1487, 3, 1392, 4, 2596, 1363, 324, 504, 23, 19, 965, 1127],\n",
       " [65, 18, 4138, 79, 1454, 175, 1151, 4, 196, 247, 627],\n",
       " [68, 54, 111, 351, 1, 591, 1, 715, 80],\n",
       " [243, 227, 219, 3, 1, 599, 1338, 4, 3, 393, 339],\n",
       " [977,\n",
       "  101,\n",
       "  41,\n",
       "  24,\n",
       "  233,\n",
       "  2,\n",
       "  761,\n",
       "  347,\n",
       "  25,\n",
       "  736,\n",
       "  2,\n",
       "  3531,\n",
       "  713,\n",
       "  1935,\n",
       "  90,\n",
       "  3604,\n",
       "  17,\n",
       "  18],\n",
       " [12, 2, 439, 3, 2517, 6, 1174, 2, 5, 65, 1226, 4, 61, 337, 2, 843, 2, 77],\n",
       " [40, 351, 1, 2387, 3, 1, 632],\n",
       " [1, 7, 122, 395, 1821, 804, 11, 2, 5],\n",
       " [92, 3410, 3, 2459, 4, 3546, 2, 1738, 2, 37, 6, 3, 23, 1, 1396],\n",
       " [3771, 10, 718, 1, 2342, 3, 396, 4, 12, 347, 3, 85, 457, 457],\n",
       " [16, 14, 3, 6, 1009, 3, 101, 4, 15, 32, 43],\n",
       " [147,\n",
       "  3,\n",
       "  97,\n",
       "  64,\n",
       "  4,\n",
       "  66,\n",
       "  32,\n",
       "  2,\n",
       "  33,\n",
       "  998,\n",
       "  3,\n",
       "  16,\n",
       "  756,\n",
       "  6,\n",
       "  2,\n",
       "  125,\n",
       "  247,\n",
       "  447,\n",
       "  3,\n",
       "  102,\n",
       "  2,\n",
       "  1955],\n",
       " [2782,\n",
       "  508,\n",
       "  1102,\n",
       "  3938,\n",
       "  500,\n",
       "  58,\n",
       "  139,\n",
       "  128,\n",
       "  232,\n",
       "  22,\n",
       "  540,\n",
       "  253,\n",
       "  2782,\n",
       "  435,\n",
       "  2639,\n",
       "  1979,\n",
       "  253,\n",
       "  2955,\n",
       "  4063,\n",
       "  548,\n",
       "  2782,\n",
       "  255,\n",
       "  1725,\n",
       "  170,\n",
       "  154],\n",
       " [48, 24, 4402, 4402, 1203, 2, 3947, 13, 1, 248, 873, 325, 2, 7, 1079],\n",
       " [4053, 322, 3903, 109, 93, 403, 4, 1450, 1, 120, 668, 2, 3737, 1, 1924],\n",
       " [42, 348, 209, 3, 4006, 4, 662, 1, 15, 2625],\n",
       " [1164, 246, 767, 854, 4, 4113, 4113, 1234, 67, 1, 1488],\n",
       " [1559, 2, 3012, 10, 3403, 97, 64, 1, 1671],\n",
       " [618, 2291, 1, 80, 1689, 534, 1698, 2, 692, 313, 3, 1, 193],\n",
       " [25, 125, 874, 20, 1, 659, 4, 7, 984, 601, 681],\n",
       " [4, 8, 82, 2, 1, 2236, 2, 885, 8, 4214, 4215, 3, 16, 1499, 756],\n",
       " [42, 1, 114, 106, 11, 204, 4, 150, 3, 1042, 166, 140],\n",
       " [95, 1183, 2, 7, 94, 3, 1, 142],\n",
       " [227, 1, 599, 185, 393, 339, 799, 1, 377, 297, 2, 37],\n",
       " [2767, 320, 3, 16, 3600, 3601, 987, 2739, 66, 1091],\n",
       " [293,\n",
       "  70,\n",
       "  1966,\n",
       "  81,\n",
       "  1581,\n",
       "  1967,\n",
       "  4105,\n",
       "  21,\n",
       "  283,\n",
       "  1424,\n",
       "  49,\n",
       "  1199,\n",
       "  511,\n",
       "  1750,\n",
       "  2445,\n",
       "  3119,\n",
       "  283,\n",
       "  22,\n",
       "  2566,\n",
       "  928,\n",
       "  253,\n",
       "  666,\n",
       "  2413,\n",
       "  49,\n",
       "  1018,\n",
       "  1424,\n",
       "  666,\n",
       "  335,\n",
       "  3877,\n",
       "  91,\n",
       "  4105,\n",
       "  49,\n",
       "  441,\n",
       "  319,\n",
       "  1424,\n",
       "  2142],\n",
       " [36, 101, 4, 5, 203, 41, 123, 112, 503, 4201, 2, 67, 4, 25, 125],\n",
       " [239, 2, 408, 2, 179, 266],\n",
       " [60, 2677, 2, 1836, 1, 7, 100, 472, 7, 2802, 6, 2562, 4, 478],\n",
       " [430, 3167, 411, 2274, 2108, 922, 3225, 2102, 193, 306, 2, 3226, 55, 497],\n",
       " [7, 462, 4109, 2, 4110, 6, 1661, 578, 1, 15],\n",
       " [4, 119, 6, 9, 1, 26, 2713, 43, 1, 834, 207],\n",
       " [147,\n",
       "  97,\n",
       "  64,\n",
       "  4,\n",
       "  295,\n",
       "  3,\n",
       "  177,\n",
       "  19,\n",
       "  1598,\n",
       "  1667,\n",
       "  358,\n",
       "  217,\n",
       "  4,\n",
       "  366,\n",
       "  177,\n",
       "  1,\n",
       "  32,\n",
       "  8,\n",
       "  362,\n",
       "  989],\n",
       " [1825, 915, 2, 62, 665, 1, 39, 1430, 2, 486],\n",
       " [498, 2, 299, 2, 648, 1, 355, 80],\n",
       " [506, 3, 2570, 2, 60, 345, 1, 15, 167, 3, 655, 501, 870, 1, 5, 34],\n",
       " [1709, 500, 8, 241, 918, 3, 3498, 24, 314, 2, 40, 554, 1937, 29, 215],\n",
       " [7, 464, 271, 272, 625, 1, 2753, 146, 2, 1298, 14, 2680, 3463, 18],\n",
       " [214, 6, 217, 41, 1277, 4, 5, 66, 76, 1, 32, 8, 2774],\n",
       " [89, 4819, 4820, 4821, 929, 4822, 1, 296, 2050, 8, 92],\n",
       " [28, 129, 341, 3, 94, 1172, 3, 769, 4, 3836, 23, 17, 527, 173],\n",
       " [286, 31, 3, 65, 325, 11, 1165, 4, 369, 3, 1, 26, 149, 100, 969],\n",
       " [3968, 8, 1333, 2701, 101, 2, 7, 36, 10, 5, 261, 3, 957, 4, 117, 273],\n",
       " [857, 66, 582, 11, 204, 1913, 2, 7, 205, 116, 2, 15, 131],\n",
       " [2, 1585, 2, 455, 1, 388, 543],\n",
       " [5, 371, 1, 142, 2239, 203, 2, 384, 1, 39],\n",
       " [323, 2, 1300, 6, 10, 1482, 1, 245, 231, 19, 721, 1928, 3, 483, 81, 58],\n",
       " [383, 1354, 411, 1047, 1690, 1373, 1, 911, 116, 2],\n",
       " [413, 250, 5, 1152, 1, 45, 45],\n",
       " [993, 3813, 6, 631, 2558, 30, 2, 5, 36, 1, 5, 12, 8, 195, 3, 1145, 2559, 6],\n",
       " [440, 124, 1463, 16, 110, 1183, 2, 7, 36, 9, 1, 120, 674, 3, 507, 2, 84],\n",
       " [893, 1, 801, 2, 222, 265, 14, 3, 1377, 470, 4, 2063],\n",
       " [33, 866, 2812, 1, 654, 2, 2320, 1014, 287, 278, 1, 4380, 834, 207],\n",
       " [3880,\n",
       "  31,\n",
       "  3,\n",
       "  110,\n",
       "  854,\n",
       "  4,\n",
       "  1420,\n",
       "  2,\n",
       "  387,\n",
       "  1846,\n",
       "  3881,\n",
       "  3882,\n",
       "  1903,\n",
       "  996,\n",
       "  70,\n",
       "  608],\n",
       " [181, 3706, 328, 2, 192, 263, 1, 223, 3],\n",
       " [1467,\n",
       "  3935,\n",
       "  3936,\n",
       "  4352,\n",
       "  1,\n",
       "  1342,\n",
       "  13,\n",
       "  1,\n",
       "  3996,\n",
       "  3,\n",
       "  4411,\n",
       "  1,\n",
       "  132,\n",
       "  17,\n",
       "  4,\n",
       "  4360,\n",
       "  117,\n",
       "  18,\n",
       "  4,\n",
       "  1249,\n",
       "  117],\n",
       " [208,\n",
       "  2,\n",
       "  52,\n",
       "  1773,\n",
       "  6,\n",
       "  2803,\n",
       "  1,\n",
       "  73,\n",
       "  191,\n",
       "  963,\n",
       "  3,\n",
       "  14,\n",
       "  1246,\n",
       "  64,\n",
       "  1957,\n",
       "  4,\n",
       "  208,\n",
       "  95],\n",
       " [123, 229, 117, 4299, 2, 7, 3230, 205, 4, 203],\n",
       " [27, 733, 3, 3060, 821, 4918, 4919, 1224, 41, 4920, 4921, 548, 522],\n",
       " [2193, 3722, 519, 3723, 6, 3724, 1, 2, 834, 768],\n",
       " [4984, 8, 3042, 2148, 1, 5, 447, 3023, 519, 1333, 635],\n",
       " [2578, 3, 8, 33, 1598, 1667, 358, 6, 240, 16, 1154, 1, 245],\n",
       " [442,\n",
       "  18,\n",
       "  941,\n",
       "  92,\n",
       "  6,\n",
       "  1479,\n",
       "  3788,\n",
       "  4,\n",
       "  251,\n",
       "  495,\n",
       "  257,\n",
       "  410,\n",
       "  8,\n",
       "  1578,\n",
       "  343,\n",
       "  2,\n",
       "  1755],\n",
       " [583, 1, 1107, 3, 33, 2530, 6, 103, 3, 88, 3998],\n",
       " [42, 4, 2, 39, 1, 389, 381],\n",
       " [604, 8, 847, 3832, 8, 10, 269, 3370, 2004, 7, 45, 11, 81],\n",
       " [2111, 2112, 3, 684, 30, 1, 384, 8, 720, 549, 54, 1, 1035, 80],\n",
       " [25, 125, 2732, 2, 34, 11, 3814, 2, 1143, 6, 4, 3, 2659, 1, 849],\n",
       " [635, 404, 3, 677, 4, 26, 1253, 8, 669, 868, 1, 5, 3478, 2],\n",
       " [36, 514, 862, 1, 7, 2745, 370, 86, 3, 2299, 6, 2746, 2, 267, 1, 15, 579],\n",
       " [36, 352, 1, 676, 11, 2250, 4, 402, 14, 175, 2, 390, 159],\n",
       " [4675, 4676, 2931, 2039, 103, 20, 1585, 85, 4677],\n",
       " [3677, 913, 79, 1, 1072, 80],\n",
       " [320,\n",
       "  3,\n",
       "  16,\n",
       "  1500,\n",
       "  1501,\n",
       "  24,\n",
       "  1,\n",
       "  1138,\n",
       "  2,\n",
       "  701,\n",
       "  2,\n",
       "  557,\n",
       "  29,\n",
       "  3536,\n",
       "  3,\n",
       "  16,\n",
       "  773,\n",
       "  774],\n",
       " [2491, 2492, 14, 16, 254, 178, 350, 98],\n",
       " [2052, 2, 1589, 1, 715, 80, 100, 3, 46],\n",
       " [186, 1685, 909, 56, 2825, 108, 164, 1427, 737, 1, 37],\n",
       " [1211, 3, 127, 2, 9, 1, 2205, 3, 294, 1010, 2, 32, 11, 4122],\n",
       " [7, 400, 23, 1, 33, 662, 3, 2107, 159, 2, 14, 1302, 4],\n",
       " [60, 24, 1282, 2, 1960, 1, 662, 1, 141, 11, 18, 4, 89, 182],\n",
       " [76, 1, 618, 10, 2626, 3905, 2, 131, 6, 1490, 3, 322, 1914, 2407, 1, 5, 34],\n",
       " [857, 855, 2, 14, 264, 3, 5, 1, 1287],\n",
       " [70, 1081, 736, 578, 21, 81, 283, 1007, 1001, 2518, 3875, 511, 1196, 667],\n",
       " [590,\n",
       "  97,\n",
       "  64,\n",
       "  16,\n",
       "  4214,\n",
       "  4215,\n",
       "  6,\n",
       "  123,\n",
       "  32,\n",
       "  17,\n",
       "  46,\n",
       "  75,\n",
       "  1,\n",
       "  2598,\n",
       "  2,\n",
       "  245,\n",
       "  90,\n",
       "  2481,\n",
       "  159,\n",
       "  3,\n",
       "  11,\n",
       "  167],\n",
       " [442, 18, 1, 1503, 1479, 1930, 3, 571, 258, 556, 1656, 2690, 1118, 3, 184],\n",
       " [257, 31, 3, 76, 1, 3603, 549, 54, 6, 10, 5, 130, 28, 48, 76, 46],\n",
       " [2882, 4579],\n",
       " [186, 172, 103, 20, 227],\n",
       " [96, 6, 4, 176, 323, 18, 2, 1565, 2727, 18],\n",
       " [4043, 1862, 951, 3890, 2, 649, 1, 849, 99, 2, 1565, 69, 1, 5, 808],\n",
       " [5,\n",
       "  1539,\n",
       "  1,\n",
       "  1540,\n",
       "  1245,\n",
       "  606,\n",
       "  2,\n",
       "  267,\n",
       "  4525,\n",
       "  607,\n",
       "  2013,\n",
       "  1246,\n",
       "  3,\n",
       "  124,\n",
       "  4526,\n",
       "  3,\n",
       "  18,\n",
       "  124],\n",
       " [796,\n",
       "  482,\n",
       "  4790,\n",
       "  4791,\n",
       "  337,\n",
       "  2,\n",
       "  927,\n",
       "  1297,\n",
       "  1,\n",
       "  4792,\n",
       "  1298,\n",
       "  1612,\n",
       "  2,\n",
       "  464,\n",
       "  271,\n",
       "  272,\n",
       "  625],\n",
       " [1622, 4, 2, 160, 3, 5, 1576, 1, 228, 138, 35, 2322, 1, 22, 1125, 650],\n",
       " [2403, 2404, 19, 3727, 81, 2504, 3728, 602, 206, 2505],\n",
       " [1607, 163, 1806, 352, 2475, 10, 1065, 199, 1, 525, 3, 600, 89, 449, 302],\n",
       " [12, 2, 7, 943, 6, 277, 346, 35, 464, 271, 272],\n",
       " [12, 2, 1912, 1829, 4, 15, 172, 1504, 75, 2, 26, 161],\n",
       " [52, 10, 3, 1, 529, 1200, 4, 116, 2, 2630, 4, 3422, 125],\n",
       " [25, 172, 582, 2751, 1, 292, 1972, 2, 69, 2, 7, 36],\n",
       " [113,\n",
       "  3,\n",
       "  2290,\n",
       "  2,\n",
       "  131,\n",
       "  1,\n",
       "  5,\n",
       "  651,\n",
       "  113,\n",
       "  652,\n",
       "  2,\n",
       "  237,\n",
       "  1,\n",
       "  568,\n",
       "  2962,\n",
       "  1,\n",
       "  632,\n",
       "  80,\n",
       "  695],\n",
       " [3817, 275, 62, 3, 2, 828, 1, 262],\n",
       " [277, 2217, 35, 169, 2, 827, 4298, 4, 7, 1966],\n",
       " [635, 404, 1747, 16, 586, 35, 208, 581, 4, 6, 1, 659, 721, 1, 1156],\n",
       " [362, 112, 2, 5, 4, 112, 970, 3, 1553, 3, 3341],\n",
       " [249, 193, 306, 1, 2294, 55, 1360, 3271, 2, 430, 1060],\n",
       " [1491, 4, 757, 758, 370, 3, 3114, 1, 2499, 1, 805, 3957],\n",
       " [195,\n",
       "  1460,\n",
       "  1,\n",
       "  1513,\n",
       "  8,\n",
       "  884,\n",
       "  3,\n",
       "  896,\n",
       "  2,\n",
       "  242,\n",
       "  4,\n",
       "  84,\n",
       "  6,\n",
       "  85,\n",
       "  1462,\n",
       "  2778,\n",
       "  588,\n",
       "  108],\n",
       " [33, 4071, 991, 8, 669, 868, 3, 16, 47, 3, 102, 4, 15, 32, 43],\n",
       " [28, 304, 1763, 2, 600, 2866, 211, 2, 925, 517, 205, 3, 977, 2, 130, 106, 46],\n",
       " [631, 2676, 4, 4241, 231, 1, 1600, 1234, 1140, 1, 172, 16, 586, 220],\n",
       " [3193, 3194, 2, 160, 1370, 3, 113, 1, 535, 536],\n",
       " [2161, 3, 396, 3, 449, 449, 4, 2675, 856, 545, 3, 1496, 10, 340],\n",
       " [2900, 255, 309],\n",
       " [25, 240, 1, 956, 99, 3508, 2, 50, 67, 1, 5, 808, 73, 1, 139, 128],\n",
       " [181, 920, 3, 4, 2155, 1, 5, 371, 3, 185, 1815, 1, 1093, 3, 279],\n",
       " [52, 2010, 2, 65, 6, 1678, 2, 1, 3404, 1, 2358, 3405, 106],\n",
       " [51, 498, 2, 221, 1, 251, 3, 3578, 4, 489, 1469, 2, 5, 1447],\n",
       " [76, 2228, 1, 640, 13, 1, 248, 354, 2, 6, 26, 2, 1976, 1609],\n",
       " [996,\n",
       "  58,\n",
       "  710,\n",
       "  10,\n",
       "  314,\n",
       "  3,\n",
       "  19,\n",
       "  1442,\n",
       "  3,\n",
       "  229,\n",
       "  1262,\n",
       "  4,\n",
       "  402,\n",
       "  1756,\n",
       "  126,\n",
       "  23,\n",
       "  1,\n",
       "  707],\n",
       " [447, 2608, 1, 15, 1385, 11, 1724, 4, 402, 3761, 107, 82],\n",
       " [12, 2, 1912, 6, 2531, 372, 2, 1488, 1407],\n",
       " [176, 2, 537, 9, 1319, 2, 4372, 2765, 2, 131, 2, 1110],\n",
       " [241, 490, 399, 3, 30, 1, 964, 3, 1, 3390, 2, 327],\n",
       " [2137, 3440, 2, 357],\n",
       " [2, 327, 1, 2, 37, 3, 4, 200, 418, 812, 38, 3160, 44, 2235],\n",
       " [397, 1030, 225, 839, 134, 1425, 2179, 778, 2547, 2729, 3, 268, 23, 1, 7, 53],\n",
       " [3, 24, 565, 2, 322, 1151, 90, 1772, 17, 2, 353, 2, 51, 182],\n",
       " [2271, 733, 2, 456, 1, 15, 296, 3247],\n",
       " [28, 1, 111, 448, 3235, 2278, 3, 2, 210],\n",
       " [53, 4131, 1376, 1, 7, 1, 392, 7, 45, 144, 4, 121, 649],\n",
       " [2710,\n",
       "  2711,\n",
       "  10,\n",
       "  1253,\n",
       "  19,\n",
       "  515,\n",
       "  38,\n",
       "  1,\n",
       "  3450,\n",
       "  4,\n",
       "  5,\n",
       "  12,\n",
       "  117,\n",
       "  108,\n",
       "  17,\n",
       "  987,\n",
       "  987,\n",
       "  1876],\n",
       " [169, 145, 2241, 2],\n",
       " [9, 1, 610, 28, 72, 1674, 1, 571, 2318, 3402, 3],\n",
       " [51, 1, 2304, 1, 5, 845],\n",
       " [349, 198, 40, 799, 17, 46, 1, 297, 2, 280, 902, 2008, 1243, 1, 51, 1032],\n",
       " [259, 2, 25, 401, 587, 1, 1927, 2, 292, 4, 142, 2, 5, 34],\n",
       " [4307, 18, 102, 2577, 28, 129, 6, 4, 4312, 366, 1475],\n",
       " [4625, 1, 5, 56, 2907, 1, 532, 1261, 251, 2908, 2, 4626],\n",
       " [27, 2043, 2, 2893, 4605, 4606, 3, 4607, 1, 702],\n",
       " [523, 3, 2563, 9, 1, 649, 2, 7, 3819, 224, 173, 467, 1, 568, 45, 2, 109],\n",
       " [3, 2077, 2, 813, 1, 1735, 2, 1287, 221, 2, 69, 99, 1771, 3, 1, 15, 37],\n",
       " [2046, 4614, 4, 705, 2898, 2, 5, 168, 1, 331, 4615],\n",
       " [120, 42, 1918, 6, 2292, 4, 15, 1214, 3622, 1, 594, 2, 1049, 1159],\n",
       " [405, 2, 201, 928, 1, 736, 613, 3, 8, 143, 27],\n",
       " [52, 1, 7, 391, 378, 4, 392, 59],\n",
       " [13, 274, 8, 977, 3, 4, 761, 59],\n",
       " [954,\n",
       "  29,\n",
       "  605,\n",
       "  814,\n",
       "  2639,\n",
       "  650,\n",
       "  238,\n",
       "  608,\n",
       "  1919,\n",
       "  293,\n",
       "  174,\n",
       "  666,\n",
       "  3925,\n",
       "  148,\n",
       "  3926,\n",
       "  22,\n",
       "  2318,\n",
       "  608,\n",
       "  2467,\n",
       "  508,\n",
       "  134,\n",
       "  285,\n",
       "  1489,\n",
       "  72,\n",
       "  63,\n",
       "  253,\n",
       "  666,\n",
       "  335,\n",
       "  511,\n",
       "  2432,\n",
       "  730,\n",
       "  49,\n",
       "  335,\n",
       "  2640,\n",
       "  508,\n",
       "  134,\n",
       "  285,\n",
       "  2640,\n",
       "  425,\n",
       "  148,\n",
       "  134,\n",
       "  29,\n",
       "  3927,\n",
       "  157,\n",
       "  879,\n",
       "  29,\n",
       "  879,\n",
       "  745,\n",
       "  756,\n",
       "  2568,\n",
       "  1713,\n",
       "  87,\n",
       "  183,\n",
       "  151,\n",
       "  348,\n",
       "  497,\n",
       "  44,\n",
       "  257,\n",
       "  104],\n",
       " [583, 1, 716, 101, 4, 1495, 41, 123, 56, 986, 4, 15],\n",
       " [363,\n",
       "  4102,\n",
       "  375,\n",
       "  162,\n",
       "  3,\n",
       "  10,\n",
       "  3,\n",
       "  4,\n",
       "  32,\n",
       "  24,\n",
       "  565,\n",
       "  2,\n",
       "  875,\n",
       "  1,\n",
       "  15,\n",
       "  338,\n",
       "  2696,\n",
       "  1,\n",
       "  984],\n",
       " [825, 1028, 3, 38, 3512, 1, 262, 3030, 3],\n",
       " [1533, 353, 2920, 4659, 6, 1577, 2921, 3, 9, 4660, 5, 328, 8, 4661],\n",
       " [997, 2537, 6, 1867, 99, 1771, 1, 1032, 2539, 2, 273, 562],\n",
       " [3170, 3272, 3, 1, 5, 1126, 1, 1069, 1070, 3273, 155, 1, 87],\n",
       " [2783,\n",
       "  174,\n",
       "  881,\n",
       "  58,\n",
       "  22,\n",
       "  1846,\n",
       "  29,\n",
       "  33,\n",
       "  4272,\n",
       "  70,\n",
       "  1211,\n",
       "  1327,\n",
       "  253,\n",
       "  4273,\n",
       "  209,\n",
       "  1841,\n",
       "  1393],\n",
       " [468, 169, 2, 3458, 122, 141, 17, 54, 1, 1229, 1, 2388, 3459],\n",
       " [183, 2293, 3661, 127, 2, 1111, 278, 1, 114, 2086, 40, 2035, 2367],\n",
       " [819, 1595, 1289, 3, 2, 210, 9, 806, 4, 83, 269, 118, 2, 188, 1, 254, 178],\n",
       " [3195, 23, 2324, 3, 88, 3248],\n",
       " [1590, 959, 10, 697, 9, 3702, 4, 5, 1086],\n",
       " [3757, 3758, 578, 21, 1853, 1178, 1260, 81, 22, 2524, 21, 174],\n",
       " [5,\n",
       "  153,\n",
       "  2,\n",
       "  7,\n",
       "  129,\n",
       "  341,\n",
       "  3,\n",
       "  94,\n",
       "  2,\n",
       "  81,\n",
       "  1282,\n",
       "  4,\n",
       "  59,\n",
       "  1,\n",
       "  150,\n",
       "  318,\n",
       "  6,\n",
       "  103,\n",
       "  56,\n",
       "  1385],\n",
       " [710, 1, 5, 133, 3, 2164, 1, 3059, 4917, 3, 546, 1, 459, 433],\n",
       " [3, 1406, 108, 3920, 3, 125, 6, 61, 4, 366, 404, 1, 748, 2, 3704],\n",
       " [893, 801, 2, 222, 265, 412, 1025, 17, 46],\n",
       " [1862,\n",
       "  951,\n",
       "  11,\n",
       "  4,\n",
       "  26,\n",
       "  4212,\n",
       "  6,\n",
       "  26,\n",
       "  2,\n",
       "  3192,\n",
       "  1,\n",
       "  1954,\n",
       "  1823,\n",
       "  3,\n",
       "  46,\n",
       "  4,\n",
       "  3468,\n",
       "  2914,\n",
       "  1,\n",
       "  688],\n",
       " [60,\n",
       "  2,\n",
       "  584,\n",
       "  180,\n",
       "  761,\n",
       "  3681,\n",
       "  2,\n",
       "  3992,\n",
       "  2477,\n",
       "  743,\n",
       "  2,\n",
       "  180,\n",
       "  761,\n",
       "  3,\n",
       "  2724,\n",
       "  35,\n",
       "  144,\n",
       "  47,\n",
       "  3965,\n",
       "  32],\n",
       " [225, 494, 1, 19, 3514, 35, 1652, 2, 181],\n",
       " [2176, 3072, 358, 50, 74, 163],\n",
       " [138, 1121, 733, 746, 2125, 1691],\n",
       " [889,\n",
       "  2,\n",
       "  4507,\n",
       "  6,\n",
       "  4508,\n",
       "  2005,\n",
       "  2845,\n",
       "  4509,\n",
       "  4510,\n",
       "  3,\n",
       "  4511,\n",
       "  2,\n",
       "  2846,\n",
       "  2,\n",
       "  2006,\n",
       "  1,\n",
       "  37],\n",
       " [3307, 1, 2309, 14, 1, 1254, 11, 2, 5, 113, 106, 1, 520, 504],\n",
       " [4, 1495, 8, 2495, 1961, 217, 4, 366, 177, 1, 15, 32],\n",
       " [431, 160, 1757, 3, 4, 2322, 1, 450, 6, 1076, 2085],\n",
       " [597, 281, 3099, 4, 3412, 2, 5, 3413, 688],\n",
       " [3048, 2122, 55, 1, 2157, 104, 62, 274, 2158, 115, 1, 72, 63],\n",
       " [454, 3, 139, 3622, 1, 808, 3, 2204, 10, 697],\n",
       " [1698, 2, 223, 192, 263, 185, 1383, 2, 331, 1305],\n",
       " [1801, 2, 2195, 365, 3610, 1, 3611],\n",
       " [89, 3985, 3, 3977, 8, 2661, 2662, 235, 939, 177, 97, 64],\n",
       " [1127, 3609, 1052, 1, 936, 2395, 2268],\n",
       " [7, 120, 4, 5, 1512, 1, 568, 469, 325, 2, 5, 34],\n",
       " [290, 438, 103, 20, 1082, 3, 4093, 1202],\n",
       " [42, 54, 20, 3279, 2, 1323, 1, 716],\n",
       " [520, 3, 10, 2870, 3, 44, 1320],\n",
       " [68, 831, 2, 925, 3024, 3, 3586, 525, 1, 389],\n",
       " [28, 1038, 1, 553, 80, 6, 805, 1, 3653, 193, 306, 1, 3226, 55, 497],\n",
       " [180, 359, 163, 1569, 411, 1047, 167, 3, 1, 140, 915],\n",
       " [1083, 521, 264, 4, 3486, 2, 189, 9, 1, 1125, 650],\n",
       " [1227, 899, 2, 1532, 3, 3, 806, 4, 384, 2, 2501, 16, 1664],\n",
       " [61, 2, 130, 1, 1547, 1794, 54, 11, 1232, 1, 2424],\n",
       " [61,\n",
       "  10,\n",
       "  56,\n",
       "  1462,\n",
       "  19,\n",
       "  198,\n",
       "  28,\n",
       "  1,\n",
       "  365,\n",
       "  108,\n",
       "  342,\n",
       "  3827,\n",
       "  2,\n",
       "  769,\n",
       "  9,\n",
       "  1,\n",
       "  135,\n",
       "  12],\n",
       " [136, 1, 4160, 2596, 4161, 2, 7, 50, 392, 13, 1, 4162],\n",
       " [376, 4, 1, 181, 11, 3117, 35],\n",
       " [14, 2937, 222, 2068, 919, 83, 4689, 2069, 17, 46],\n",
       " [2914, 1, 355, 80, 4644, 2, 321, 86, 13, 146, 1, 1048],\n",
       " [308, 3, 4218, 2, 3, 10, 14, 2, 12, 13, 14, 270, 4219],\n",
       " [1156, 1790, 1112, 27, 2, 431, 312, 4, 1054, 155],\n",
       " [7, 96, 2655, 4, 3366, 231, 1, 688, 86, 3, 107],\n",
       " [1314, 2144, 198, 2145, 1315, 4870, 2, 322, 3036, 1316],\n",
       " [11, 4, 958, 209, 2643, 4037, 3, 97, 64, 1, 1948, 1949],\n",
       " [590, 97, 64, 16, 4244, 1, 366, 32, 6, 147, 4, 3, 1210, 2, 3860, 197, 3, 320],\n",
       " [805, 1259, 80, 169, 3623, 50, 228, 138, 2210, 368],\n",
       " [1, 45, 2, 15, 421, 207, 4066, 677, 4, 1832, 81, 1904],\n",
       " [52, 6, 3615, 1, 955, 2, 54, 1, 591, 1, 715],\n",
       " [644, 745, 1304, 2032, 701, 3, 806, 4, 384, 1, 1344, 246, 13, 30, 1, 619],\n",
       " [1111, 31, 3, 53, 994, 1019, 99, 3827, 2, 4094, 6, 770, 2, 12, 3, 3, 1023],\n",
       " [86, 24, 1660, 2, 353, 424, 35, 1801, 11, 1416, 1, 4380, 834, 207],\n",
       " [719, 3, 596, 35, 2],\n",
       " [50, 294, 1, 80, 311, 2, 5, 4150, 211, 2, 5, 2078, 6, 1120, 35, 400],\n",
       " [3425, 2, 5, 50, 704, 1362, 3, 2, 209, 44, 357],\n",
       " [3, 4, 1, 205, 136, 1, 1397, 435, 4154, 941, 4, 580, 20, 53, 347],\n",
       " [256, 2457, 24, 602, 19, 332, 333, 1419, 861, 38, 4, 73, 657],\n",
       " [3473, 2466, 1, 2419, 3, 4, 26, 3651, 1, 1836, 2, 2858],\n",
       " [326, 2, 715, 80, 1751, 1250, 1421, 3, 1, 171],\n",
       " [60, 1476, 1, 121, 568, 294, 4090, 97, 64, 2, 1804, 344, 662],\n",
       " [447, 437, 718, 1, 2916, 3, 1167, 2, 149, 1448],\n",
       " [1939, 31, 3, 137, 219, 3, 1019, 1, 1484, 2, 1943, 9, 1, 15, 84],\n",
       " [1481, 6, 3856, 140, 2081, 6, 2229, 4062, 1, 100, 33],\n",
       " [463, 3863, 1736, 147, 97, 64, 4, 6, 123, 229, 864],\n",
       " [1412, 2, 4127, 277, 66, 1452, 1, 69, 2, 25, 125],\n",
       " [172, 2731, 4, 77, 1, 1218, 4158, 2, 12, 116, 2, 446, 20, 474, 4, 509],\n",
       " [7, 760, 31, 3, 230, 23, 1, 1752, 305, 2, 55, 416, 1, 190],\n",
       " [12, 3, 14, 4, 1490, 6, 1932, 2, 61, 1, 15, 660, 603, 2, 5, 880],\n",
       " [181, 2055, 2, 160, 40, 1272, 3, 118, 2, 2915, 235, 1573],\n",
       " [202, 953, 1, 382, 6, 622, 11, 4, 89, 170, 3, 226],\n",
       " [2644, 3, 1002, 2, 7, 162, 11, 2, 109, 93, 4, 15, 314],\n",
       " [30, 54, 11, 1, 5, 1826, 1, 2453],\n",
       " [76, 3264, 1, 7, 532, 1, 563, 68, 94, 1236, 1, 55, 3, 544],\n",
       " [5, 3261, 406, 1, 751, 1691, 2, 210],\n",
       " [109, 93, 17, 46, 1, 1807, 2, 797, 704, 79, 47, 1, 1561, 2, 7, 859, 1],\n",
       " [48, 4020, 5, 1207, 1, 15, 852, 3, 5, 153],\n",
       " [28, 168, 316, 8, 1675, 1112, 2, 3164, 1, 535],\n",
       " [42, 1894, 4, 390, 119, 9, 127, 2, 837, 4, 240, 369, 1, 1034],\n",
       " [47, 3, 102, 4, 32, 8, 43, 4, 33, 197, 3, 877, 3, 507, 4, 26, 4404],\n",
       " [4350, 729, 3, 4351, 4352, 11, 483, 4353, 4354, 4, 15, 7, 12],\n",
       " [551, 31, 3, 2175, 617, 739, 2641, 9, 3928, 2021],\n",
       " [1833, 3144, 2, 3, 406, 1, 1121, 1, 296, 7, 2, 1347],\n",
       " [1276, 206, 1352, 197, 85, 97, 108, 141, 4, 1, 117],\n",
       " [36, 101, 4, 1905, 3, 585, 2, 48, 582, 26, 105, 66, 2555, 95, 116, 2, 1825],\n",
       " [3718, 2, 423, 379, 1, 5, 1033, 3268, 3598, 1537],\n",
       " [50,\n",
       "  144,\n",
       "  3420,\n",
       "  1928,\n",
       "  3,\n",
       "  79,\n",
       "  1496,\n",
       "  3952,\n",
       "  661,\n",
       "  3953,\n",
       "  78,\n",
       "  380,\n",
       "  206,\n",
       "  988,\n",
       "  894,\n",
       "  502,\n",
       "  91,\n",
       "  49,\n",
       "  851,\n",
       "  91,\n",
       "  3805,\n",
       "  894,\n",
       "  502,\n",
       "  2623,\n",
       "  2650,\n",
       "  3954,\n",
       "  386,\n",
       "  1868,\n",
       "  2371,\n",
       "  3955,\n",
       "  425,\n",
       "  1001,\n",
       "  335,\n",
       "  22,\n",
       "  650,\n",
       "  21,\n",
       "  3373,\n",
       "  3954,\n",
       "  1180,\n",
       "  148,\n",
       "  148,\n",
       "  2650,\n",
       "  2639,\n",
       "  881,\n",
       "  148,\n",
       "  894,\n",
       "  502,\n",
       "  124,\n",
       "  3956,\n",
       "  894,\n",
       "  502,\n",
       "  3956],\n",
       " [98, 1, 210],\n",
       " [104, 78, 1539, 1, 3280, 91, 3281, 1, 553],\n",
       " [74,\n",
       "  24,\n",
       "  1525,\n",
       "  1273,\n",
       "  179,\n",
       "  3186,\n",
       "  3,\n",
       "  113,\n",
       "  9,\n",
       "  81,\n",
       "  4,\n",
       "  5,\n",
       "  532,\n",
       "  6,\n",
       "  5,\n",
       "  133,\n",
       "  3,\n",
       "  328,\n",
       "  2,\n",
       "  1760,\n",
       "  1,\n",
       "  1107],\n",
       " [155, 896, 2, 5, 1662, 4, 4, 3348, 1, 3240],\n",
       " [1111,\n",
       "  3,\n",
       "  133,\n",
       "  3,\n",
       "  328,\n",
       "  2,\n",
       "  192,\n",
       "  263,\n",
       "  1105,\n",
       "  2,\n",
       "  179,\n",
       "  3159,\n",
       "  193,\n",
       "  3,\n",
       "  69,\n",
       "  23,\n",
       "  1,\n",
       "  826,\n",
       "  6,\n",
       "  3036,\n",
       "  2846],\n",
       " [4, 1833, 871, 2, 197, 3, 320, 82, 3, 16, 3267, 3, 2, 15, 53],\n",
       " [7, 28, 31, 3, 94, 54, 11, 4, 1, 653, 2562],\n",
       " [1537, 10, 353, 354, 1, 5, 2853, 2854, 3, 284, 1, 1033],\n",
       " [4286,\n",
       "  3,\n",
       "  4286,\n",
       "  3,\n",
       "  259,\n",
       "  30,\n",
       "  8,\n",
       "  1472,\n",
       "  2473,\n",
       "  242,\n",
       "  4,\n",
       "  651,\n",
       "  42,\n",
       "  1638,\n",
       "  3,\n",
       "  1638,\n",
       "  1,\n",
       "  139,\n",
       "  128],\n",
       " [12, 2228, 1, 640, 11, 2, 1475, 5, 153, 291],\n",
       " [2974,\n",
       "  4757,\n",
       "  2975,\n",
       "  3,\n",
       "  4,\n",
       "  1600,\n",
       "  126,\n",
       "  8,\n",
       "  2976,\n",
       "  1064,\n",
       "  4758,\n",
       "  386,\n",
       "  363,\n",
       "  1601,\n",
       "  49,\n",
       "  363,\n",
       "  4759,\n",
       "  605,\n",
       "  6,\n",
       "  4760],\n",
       " [94, 994, 3864, 2, 162, 3, 3865, 2, 3866, 1, 3867, 2, 45],\n",
       " [105,\n",
       "  1,\n",
       "  4300,\n",
       "  1477,\n",
       "  847,\n",
       "  1,\n",
       "  646,\n",
       "  46,\n",
       "  174,\n",
       "  881,\n",
       "  1580,\n",
       "  134,\n",
       "  70,\n",
       "  58,\n",
       "  397,\n",
       "  1734,\n",
       "  148,\n",
       "  1877,\n",
       "  335,\n",
       "  22,\n",
       "  954,\n",
       "  429,\n",
       "  81,\n",
       "  2772,\n",
       "  881,\n",
       "  81,\n",
       "  283,\n",
       "  2041,\n",
       "  21,\n",
       "  1044,\n",
       "  1178,\n",
       "  22,\n",
       "  29,\n",
       "  397,\n",
       "  887,\n",
       "  425,\n",
       "  16,\n",
       "  945,\n",
       "  883,\n",
       "  1877,\n",
       "  1,\n",
       "  3696,\n",
       "  107,\n",
       "  1,\n",
       "  2402,\n",
       "  49,\n",
       "  21,\n",
       "  22,\n",
       "  887,\n",
       "  88,\n",
       "  850,\n",
       "  63],\n",
       " [183, 3515, 2, 51, 394, 1, 1658, 9, 1, 380],\n",
       " [2038, 4, 792, 3450, 4, 539, 1776, 28, 300, 2359, 19, 169, 723, 4, 117, 3],\n",
       " [110, 3, 215, 93, 1, 394, 2, 119, 645, 2, 69],\n",
       " [61, 8, 288, 16, 4239, 3, 2630, 4, 12, 95, 3778, 2441],\n",
       " [2954, 6, 2089, 2090, 1, 5, 1235, 722, 1, 236, 37, 4726, 3],\n",
       " [3691, 2129, 1, 3064, 690, 9, 1, 1801, 2, 2500],\n",
       " [521, 3145, 1, 1619, 3146, 687],\n",
       " [38, 852, 372, 3, 4176, 271, 272, 1, 1058],\n",
       " [160, 1114, 1, 907, 1241, 2, 2900, 299],\n",
       " [7, 84, 396, 3, 4039, 4, 5, 1793, 985, 49, 451, 4040, 3, 953, 1, 659, 1, 731],\n",
       " [176, 14, 313, 1, 660, 11, 3755, 2, 375, 2, 5, 3756, 9, 1852, 17, 46],\n",
       " [3656, 106, 11, 2, 452, 4, 2, 130],\n",
       " [136, 337, 2, 843, 2, 77, 1, 5, 129, 14, 4392, 25, 2, 4274],\n",
       " [321, 86, 24, 2, 2795, 2925, 1, 15, 284, 510, 2, 880],\n",
       " [522, 959, 14, 742, 2, 3258, 9, 3259, 2, 37, 4, 821, 1278, 2966],\n",
       " [194, 8, 234, 237, 1, 3342, 24, 242, 4, 2314, 18, 146, 2],\n",
       " [104, 78, 2879, 1908, 2, 7, 61, 1, 12, 2637, 2, 34],\n",
       " [1861, 2, 1622, 4, 1454, 3, 627, 3, 1049, 2, 3773, 3773, 3, 131],\n",
       " [7, 2586, 2600, 439, 112, 1895, 393, 1896, 1, 236, 37, 605, 363, 3868],\n",
       " [33, 197, 3, 2572, 8, 965, 1127, 3, 16, 147, 3, 282, 4, 32, 43],\n",
       " [217, 4, 5, 4168, 2, 1736, 3, 371, 3],\n",
       " [7, 593, 841, 1446, 4, 4172, 3, 7, 136, 3, 2, 78, 476, 276, 6, 267],\n",
       " [4056, 1034, 2, 439, 2, 1, 630, 967, 2, 34],\n",
       " [583, 1464, 1, 5, 3948, 4, 347, 1, 15, 12],\n",
       " [7, 162, 4, 6, 2, 3996, 4, 7, 681, 2, 2334, 3997],\n",
       " [1345, 2200, 2, 5, 618, 2201, 23, 639, 55, 156, 257],\n",
       " [1491, 4, 4266, 560, 67, 8, 4220, 1215, 1515, 24, 18, 1, 39],\n",
       " [7, 137, 671, 20, 1906, 2, 783, 783, 4, 402, 3889, 23, 1, 298, 572],\n",
       " [249, 803, 4474, 4475, 1, 4476, 2, 4477, 4478],\n",
       " [178, 223, 896, 4487, 2, 2842],\n",
       " [181, 376, 1, 245, 3, 2129, 20, 10, 4, 5, 1126, 1, 5, 705, 3, 1434, 2, 69],\n",
       " [915, 129, 341, 3, 137, 323, 2, 1048, 1, 7, 592, 93, 1006, 2, 15],\n",
       " [4008,\n",
       "  162,\n",
       "  47,\n",
       "  4,\n",
       "  310,\n",
       "  101,\n",
       "  2,\n",
       "  7,\n",
       "  1453,\n",
       "  903,\n",
       "  1,\n",
       "  1541,\n",
       "  11,\n",
       "  1453,\n",
       "  855,\n",
       "  4,\n",
       "  7,\n",
       "  162],\n",
       " [25,\n",
       "  240,\n",
       "  1912,\n",
       "  3,\n",
       "  28,\n",
       "  1497,\n",
       "  2,\n",
       "  14,\n",
       "  2364,\n",
       "  325,\n",
       "  2,\n",
       "  273,\n",
       "  562,\n",
       "  90,\n",
       "  1788,\n",
       "  743,\n",
       "  3,\n",
       "  18,\n",
       "  4,\n",
       "  513,\n",
       "  2,\n",
       "  2702],\n",
       " [1604,\n",
       "  2103,\n",
       "  2343,\n",
       "  3628,\n",
       "  1349,\n",
       "  4,\n",
       "  3621,\n",
       "  2,\n",
       "  757,\n",
       "  758,\n",
       "  3629,\n",
       "  202,\n",
       "  3594,\n",
       "  1,\n",
       "  434,\n",
       "  280],\n",
       " [24,\n",
       "  1175,\n",
       "  643,\n",
       "  1,\n",
       "  310,\n",
       "  529,\n",
       "  3,\n",
       "  40,\n",
       "  18,\n",
       "  4,\n",
       "  31,\n",
       "  3,\n",
       "  137,\n",
       "  4,\n",
       "  1011,\n",
       "  3,\n",
       "  588,\n",
       "  561,\n",
       "  169,\n",
       "  6,\n",
       "  141,\n",
       "  17],\n",
       " [5, 3, 2137, 5, 875, 102, 2, 5, 2828, 3, 10, 1482, 1],\n",
       " [230, 1, 1929, 100, 2572, 1, 780, 2742, 2, 1324, 3, 67, 6, 5, 1914],\n",
       " [13, 23, 1, 3891, 2437, 7, 9, 19, 1198, 4, 1062, 2, 2910, 6, 587, 84],\n",
       " [155, 281, 932, 4, 1, 2251, 1, 830],\n",
       " [4985, 3084, 1, 703, 3085, 620, 8, 169, 2037, 612, 941, 1099, 4986, 2, 4987],\n",
       " [2073, 1590, 213, 27, 85, 2941, 2942, 3, 1, 2943, 57, 4700, 4701],\n",
       " [25, 240, 1, 2525, 2, 2120, 6, 2631, 156, 1, 1108, 2, 135, 67],\n",
       " [422, 1384, 1131, 40, 278, 40, 83, 262, 3],\n",
       " [308, 1, 703, 2897, 2, 4612, 204, 135, 12],\n",
       " [1862, 951, 2, 1060, 9, 4, 5, 6, 2528, 4, 26, 1458, 2],\n",
       " [876, 2, 1897, 1898, 1898, 4, 121, 40, 129, 341, 3, 12, 79, 1148, 32],\n",
       " [4817, 2, 39, 1, 4818, 2122, 2123, 312, 3],\n",
       " [3263, 822, 953, 1, 5, 1235, 23, 1, 1021],\n",
       " [4814, 3, 1585, 191, 9, 1, 222, 265, 24, 73],\n",
       " [1820, 72, 63, 2, 39, 281, 313, 1, 803],\n",
       " [439, 1, 73, 604, 191, 24, 602, 3],\n",
       " [691, 1762, 35, 50],\n",
       " [61, 3, 740, 38, 1941, 3, 119, 6, 67],\n",
       " [212, 376, 4, 360, 1, 892, 410, 2, 555],\n",
       " [136, 1, 1129, 1879, 2532, 11, 6, 4, 4054, 1, 566],\n",
       " [4744, 8, 723, 4745, 2965, 905, 4746, 463, 14, 105, 66, 4747],\n",
       " [124, 2536, 722, 1, 2651, 699, 1, 4073, 3, 4074, 2],\n",
       " [73, 604, 191, 2, 7, 96, 1636, 2, 251],\n",
       " [1253, 8, 213, 1, 5, 2874, 14, 105, 4557, 3, 4558, 905, 4559],\n",
       " [48,\n",
       "  1926,\n",
       "  3995,\n",
       "  18,\n",
       "  4,\n",
       "  2719,\n",
       "  3839,\n",
       "  4,\n",
       "  142,\n",
       "  2,\n",
       "  5,\n",
       "  36,\n",
       "  721,\n",
       "  2087,\n",
       "  663,\n",
       "  1,\n",
       "  5,\n",
       "  153,\n",
       "  477],\n",
       " [644, 10, 489, 25, 1065, 199, 1, 526, 2, 600, 89, 449, 525, 3, 302],\n",
       " [3232, 2, 3233, 1699, 1376],\n",
       " [1953,\n",
       "  1003,\n",
       "  2475,\n",
       "  14,\n",
       "  75,\n",
       "  295,\n",
       "  3,\n",
       "  12,\n",
       "  8,\n",
       "  1472,\n",
       "  1003,\n",
       "  14,\n",
       "  124,\n",
       "  105,\n",
       "  1088,\n",
       "  2,\n",
       "  208,\n",
       "  95],\n",
       " [72, 63, 488, 816, 28, 1045, 1, 1025, 3, 133, 228, 138, 83, 488, 816, 40],\n",
       " [848, 2, 1, 116, 2, 3356, 3, 4, 116, 3, 1566],\n",
       " [4447, 4448, 1, 2826, 2827, 800, 2, 37, 281, 408],\n",
       " [762,\n",
       "  175,\n",
       "  3824,\n",
       "  2,\n",
       "  2838,\n",
       "  108,\n",
       "  706,\n",
       "  175,\n",
       "  124,\n",
       "  581,\n",
       "  1,\n",
       "  189,\n",
       "  675,\n",
       "  1876,\n",
       "  175,\n",
       "  950,\n",
       "  2315,\n",
       "  706,\n",
       "  124,\n",
       "  2567,\n",
       "  3825,\n",
       "  3,\n",
       "  4,\n",
       "  189,\n",
       "  124,\n",
       "  71,\n",
       "  14,\n",
       "  2315,\n",
       "  6,\n",
       "  663,\n",
       "  18,\n",
       "  13,\n",
       "  14,\n",
       "  124,\n",
       "  935,\n",
       "  785,\n",
       "  1377,\n",
       "  953,\n",
       "  108,\n",
       "  706,\n",
       "  124,\n",
       "  950,\n",
       "  25,\n",
       "  1643,\n",
       "  2,\n",
       "  676,\n",
       "  13,\n",
       "  14,\n",
       "  18,\n",
       "  175,\n",
       "  663,\n",
       "  4,\n",
       "  157,\n",
       "  91,\n",
       "  22,\n",
       "  44,\n",
       "  528,\n",
       "  1146,\n",
       "  1643,\n",
       "  32,\n",
       "  301,\n",
       "  1612,\n",
       "  2568,\n",
       "  104,\n",
       "  87],\n",
       " [176, 1000, 116, 2, 119, 1, 26, 161, 372, 2, 464, 271, 272, 1, 872, 1067],\n",
       " [560, 4293, 76, 3, 1458, 1, 2817, 1, 2500],\n",
       " [275, 45, 2, 693, 3432, 154, 66, 978],\n",
       " [1978, 24, 642, 1, 292, 51, 1539, 1, 4390, 3, 4383, 642],\n",
       " [3161, 85, 64, 1, 3162, 3163, 47, 41, 2, 1055, 1674],\n",
       " [81, 666, 1572, 319, 149, 13, 2360, 175, 4, 2, 252, 44, 723],\n",
       " [352, 1, 2691, 3, 3039, 30, 1, 3251, 3, 2692],\n",
       " [254, 976, 641, 1421, 3, 1, 1055, 2075, 1, 212],\n",
       " [33, 4911, 1642, 1052, 2, 4912, 1324, 1, 700, 190, 55, 933],\n",
       " [4124,\n",
       "  175,\n",
       "  1,\n",
       "  345,\n",
       "  205,\n",
       "  136,\n",
       "  2,\n",
       "  121,\n",
       "  2421,\n",
       "  2,\n",
       "  2906,\n",
       "  149,\n",
       "  2,\n",
       "  160,\n",
       "  2303,\n",
       "  78,\n",
       "  476,\n",
       "  276],\n",
       " [375, 1020, 1007, 4132, 4243],\n",
       " [3170, 3, 1, 1365, 1, 3171, 1366, 2, 1679, 4, 1329, 1367],\n",
       " [4173, 1164, 246, 603, 2, 880, 6, 4174, 11, 4, 402, 747, 1, 1214, 2698],\n",
       " [7, 76, 396, 3, 11, 81, 657, 4, 542, 1, 15, 649],\n",
       " [4289, 3, 4289, 3, 391, 2787, 4, 20, 4, 3847, 2, 15, 345],\n",
       " [2, 2341, 13, 1, 2813, 2758, 2],\n",
       " [1163, 3, 560, 2, 262, 106, 1, 1035],\n",
       " [3189, 14, 17, 46, 4, 797, 891, 1, 1024],\n",
       " [451, 484, 603, 2, 880, 13, 1, 219, 3, 119, 1, 4325, 2, 1676, 6, 493],\n",
       " [217, 4752, 244, 4753, 1, 4754],\n",
       " [298, 2, 5, 33, 456, 44, 1712],\n",
       " [3470, 2397, 1799, 2, 4, 36, 3, 1, 659, 2, 15, 12, 3, 25, 172],\n",
       " [1464, 9, 1, 15, 1467, 2619, 25, 2, 620, 115, 1, 240, 205],\n",
       " [25, 12, 1010, 2, 32, 11, 2305, 20, 4, 616, 3, 491, 3747],\n",
       " [2254, 2, 42, 1, 25, 240, 289, 458, 818, 385, 629, 1, 2243],\n",
       " [454, 3195, 1, 466, 3196, 1688, 8, 612],\n",
       " [435,\n",
       "  4,\n",
       "  991,\n",
       "  2,\n",
       "  87,\n",
       "  3,\n",
       "  16,\n",
       "  2609,\n",
       "  13,\n",
       "  1,\n",
       "  342,\n",
       "  503,\n",
       "  2325,\n",
       "  59,\n",
       "  231,\n",
       "  1,\n",
       "  1008,\n",
       "  2,\n",
       "  125],\n",
       " [752, 2, 2136, 78, 13, 1, 664, 2, 6, 3876, 1, 77, 127, 2, 972, 45],\n",
       " [521, 221, 19, 98, 3, 1599, 4, 5, 2227, 3, 24, 1, 132, 1, 188, 19, 300, 145],\n",
       " [202, 929, 2356, 2, 416, 1053, 1, 622],\n",
       " [593, 3, 2, 9, 1, 2833],\n",
       " [694, 1538, 2011, 1, 4523, 4524, 2, 2012, 2857],\n",
       " [7, 172, 10, 371, 461, 2, 69, 11, 1938, 2, 15, 5, 12],\n",
       " [151, 21, 711, 214, 17, 5, 42, 1, 32, 8, 4220, 1215, 1515],\n",
       " [824, 1957, 270, 4, 3, 8, 468, 672],\n",
       " [1731, 219, 3, 4, 252, 2237],\n",
       " [367, 2, 1163, 1, 5, 743, 2997, 552],\n",
       " [3451, 3540, 929, 3541, 2, 1656],\n",
       " [326, 1, 340, 2, 5, 230, 3, 18, 2, 456, 4, 1438],\n",
       " [22,\n",
       "  4423,\n",
       "  2449,\n",
       "  134,\n",
       "  1776,\n",
       "  29,\n",
       "  2819,\n",
       "  2321,\n",
       "  206,\n",
       "  4424,\n",
       "  55,\n",
       "  70,\n",
       "  364,\n",
       "  794,\n",
       "  373,\n",
       "  2272,\n",
       "  1178,\n",
       "  22,\n",
       "  1134,\n",
       "  22,\n",
       "  4423,\n",
       "  2449,\n",
       "  2762,\n",
       "  304,\n",
       "  58,\n",
       "  319,\n",
       "  2819,\n",
       "  1739,\n",
       "  931,\n",
       "  49,\n",
       "  936,\n",
       "  931,\n",
       "  22,\n",
       "  206,\n",
       "  22,\n",
       "  931,\n",
       "  29,\n",
       "  22,\n",
       "  388,\n",
       "  22,\n",
       "  187,\n",
       "  794,\n",
       "  373,\n",
       "  2451,\n",
       "  2819,\n",
       "  4343,\n",
       "  49,\n",
       "  1519,\n",
       "  314,\n",
       "  49,\n",
       "  58,\n",
       "  70,\n",
       "  2600,\n",
       "  49,\n",
       "  1186,\n",
       "  157,\n",
       "  187,\n",
       "  4425,\n",
       "  29,\n",
       "  726,\n",
       "  343,\n",
       "  1700,\n",
       "  726,\n",
       "  4425,\n",
       "  3100,\n",
       "  3569,\n",
       "  879,\n",
       "  1170,\n",
       "  206,\n",
       "  4424,\n",
       "  286,\n",
       "  154,\n",
       "  735,\n",
       "  286,\n",
       "  154],\n",
       " [4156, 101, 4, 15, 5, 1512, 1, 7, 667, 1440, 1, 539],\n",
       " [36, 3962, 20, 14, 30, 2, 7, 859, 4, 50, 1114, 13, 18, 1],\n",
       " [3971, 93, 507, 4, 314, 3, 99, 1463, 4, 7, 512],\n",
       " [882, 3, 7, 4, 3833, 3, 24, 2, 4219, 3, 354, 9, 1, 15, 572],\n",
       " [7, 234, 14, 2636, 79, 2, 191, 4, 5, 338, 3924, 2, 15, 125],\n",
       " [1015, 3, 322, 2, 248, 108, 3961, 18, 3, 1977, 199, 14, 615, 1445],\n",
       " [1697, 502, 2791, 4301, 1020, 70, 225, 3828, 2445, 441, 21, 4087, 49, 2640],\n",
       " [232,\n",
       "  283,\n",
       "  70,\n",
       "  851,\n",
       "  128,\n",
       "  174,\n",
       "  386,\n",
       "  2622,\n",
       "  386,\n",
       "  605,\n",
       "  851,\n",
       "  97,\n",
       "  105,\n",
       "  987,\n",
       "  863,\n",
       "  97,\n",
       "  105,\n",
       "  1,\n",
       "  987,\n",
       "  174,\n",
       "  1431,\n",
       "  363,\n",
       "  3938,\n",
       "  465,\n",
       "  29,\n",
       "  282,\n",
       "  95,\n",
       "  3,\n",
       "  863,\n",
       "  661,\n",
       "  117,\n",
       "  232,\n",
       "  283,\n",
       "  70,\n",
       "  730,\n",
       "  851,\n",
       "  128,\n",
       "  293,\n",
       "  2645,\n",
       "  21,\n",
       "  293,\n",
       "  2645,\n",
       "  21,\n",
       "  2297,\n",
       "  293,\n",
       "  2645,\n",
       "  21,\n",
       "  2400,\n",
       "  157,\n",
       "  307,\n",
       "  29,\n",
       "  22,\n",
       "  309,\n",
       "  3939,\n",
       "  29,\n",
       "  307,\n",
       "  368,\n",
       "  1259,\n",
       "  1411,\n",
       "  1444,\n",
       "  2646,\n",
       "  879,\n",
       "  1170,\n",
       "  1451,\n",
       "  89,\n",
       "  87],\n",
       " [4709, 4710, 538, 4711, 4712, 8, 4713],\n",
       " [3243, 9, 1, 911, 764, 2482, 900, 14, 1, 667, 1440],\n",
       " [123,\n",
       "  663,\n",
       "  729,\n",
       "  2480,\n",
       "  1832,\n",
       "  8,\n",
       "  166,\n",
       "  680,\n",
       "  1,\n",
       "  524,\n",
       "  1297,\n",
       "  1,\n",
       "  3483,\n",
       "  2,\n",
       "  327,\n",
       "  1,\n",
       "  206],\n",
       " [62, 418, 3428, 2264, 8, 92, 1, 610, 2363, 2027, 2, 45, 2],\n",
       " [3066,\n",
       "  725,\n",
       "  4929,\n",
       "  3,\n",
       "  4930,\n",
       "  2,\n",
       "  4931,\n",
       "  6,\n",
       "  4932,\n",
       "  1326,\n",
       "  4933,\n",
       "  1,\n",
       "  5,\n",
       "  129,\n",
       "  4934,\n",
       "  2,\n",
       "  619],\n",
       " [333,\n",
       "  2942,\n",
       "  11,\n",
       "  2,\n",
       "  28,\n",
       "  394,\n",
       "  634,\n",
       "  14,\n",
       "  270,\n",
       "  1,\n",
       "  1658,\n",
       "  723,\n",
       "  1659,\n",
       "  20,\n",
       "  38,\n",
       "  201,\n",
       "  928],\n",
       " [27, 765, 4, 2, 2, 448, 3548, 1998, 1, 37],\n",
       " [2, 5, 637, 4],\n",
       " [4797, 1, 74, 4798, 2, 2995, 1, 817, 426, 330, 1614, 1, 710],\n",
       " [480, 23, 1, 2948, 3820, 204, 782, 11, 1, 2184],\n",
       " [2, 1115, 1, 280, 1383, 1, 2169, 3],\n",
       " [33, 38, 164, 6, 668, 127, 2, 3951, 2469, 6, 3, 43],\n",
       " [3713, 8, 143, 213, 27, 164, 3, 950, 2022],\n",
       " [10, 2689, 1, 3872, 8, 1639, 35, 1091, 1136, 1333, 6, 1198],\n",
       " [92, 1479, 1930, 3, 258, 1, 1142, 2260, 91, 3693, 210],\n",
       " [1861,\n",
       "  3,\n",
       "  858,\n",
       "  127,\n",
       "  2,\n",
       "  3658,\n",
       "  4152,\n",
       "  4,\n",
       "  1487,\n",
       "  6,\n",
       "  3285,\n",
       "  369,\n",
       "  108,\n",
       "  607,\n",
       "  68,\n",
       "  416,\n",
       "  47],\n",
       " [234,\n",
       "  665,\n",
       "  2,\n",
       "  2470,\n",
       "  1,\n",
       "  574,\n",
       "  209,\n",
       "  3,\n",
       "  1626,\n",
       "  126,\n",
       "  8,\n",
       "  194,\n",
       "  11,\n",
       "  14,\n",
       "  75,\n",
       "  4,\n",
       "  61,\n",
       "  2,\n",
       "  57,\n",
       "  390,\n",
       "  12],\n",
       " [60, 1, 4405, 2709, 2, 4405, 590, 282, 4, 4364],\n",
       " [7, 76, 4, 66, 506, 11, 247, 2350, 2, 9, 1, 121, 267],\n",
       " [475, 2, 1211, 4224, 11, 2, 3517, 1, 1399, 463, 1445, 4, 1103, 3, 4290],\n",
       " [1, 140, 2, 947, 480, 2742, 2, 135, 67, 6, 789, 4267, 1, 5, 153, 35, 862],\n",
       " [901, 2, 1353, 2, 5, 113, 2218, 8, 1667, 19, 50, 74, 163, 1354],\n",
       " [60, 30, 4, 15, 5, 1004, 772, 305, 16, 856, 323, 2, 602],\n",
       " [68, 2327, 1, 2957, 3, 530, 2, 222, 2068],\n",
       " [68, 1306, 2, 716, 311, 2, 380, 23, 19, 413, 250],\n",
       " [138, 1223, 378, 2894, 1262, 4, 201, 928, 4813],\n",
       " [110, 1, 1924, 11, 14, 2077, 1, 67, 4, 240, 1149, 2, 541],\n",
       " [1201, 1982, 34, 2278, 1216, 1, 162, 13, 1, 531, 59, 1, 681, 3, 2, 354, 126],\n",
       " [974,\n",
       "  844,\n",
       "  3,\n",
       "  369,\n",
       "  4076,\n",
       "  2,\n",
       "  2627,\n",
       "  4,\n",
       "  4077,\n",
       "  904,\n",
       "  1272,\n",
       "  82,\n",
       "  1,\n",
       "  2702,\n",
       "  4078,\n",
       "  6,\n",
       "  83,\n",
       "  904,\n",
       "  111,\n",
       "  554,\n",
       "  673,\n",
       "  3],\n",
       " [4282, 2095, 1, 11, 204, 2, 717, 12],\n",
       " [39, 3, 2445, 1121, 6],\n",
       " [3646, 2, 1, 103],\n",
       " [149, 1, 295, 3, 32, 1052, 35, 1, 324, 1061],\n",
       " [468, 672, 677, 4, 736, 578, 1, 132, 2, 7, 96],\n",
       " [1390, 1, 78, 3349, 971, 3350, 1, 1541, 80, 1, 1138, 2, 1718, 1719],\n",
       " [4, 165, 2, 2088, 2, 2, 7, 3],\n",
       " [104, 31, 3, 48, 2287, 1, 3265, 703, 406, 1714, 4, 40, 45, 1, 152],\n",
       " [1, 4006, 126, 4, 2239, 9, 1, 4007, 23, 1, 5, 233, 102, 883],\n",
       " [68, 23, 1101, 1230, 1, 72, 63, 260, 1, 181],\n",
       " [4183, 726, 3878, 3, 510, 2, 620, 2663, 800, 2, 5, 62],\n",
       " [968, 3, 8, 27, 1, 520, 3304, 2, 431],\n",
       " [855, 786, 1197, 915, 224, 173, 1900, 2560, 58, 961, 373, 319, 241, 1341],\n",
       " [199, 2248, 1616, 1617, 4, 2, 705, 537],\n",
       " [433, 224, 173, 3, 205, 1145, 641, 6, 3703, 1, 89],\n",
       " [2247, 222, 500, 265, 1, 2206, 44, 241, 490],\n",
       " [62, 1, 3203, 3204, 2264, 1, 2],\n",
       " [1083, 521, 1747, 16, 350, 1310, 98, 3, 1149, 3],\n",
       " [818, 3, 45, 45, 2, 110, 1, 903, 4267, 2, 445, 1, 512],\n",
       " [3772, 2, 2606, 39, 3, 4287, 4288, 2, 2516, 1, 51, 5, 34],\n",
       " [120, 10, 473, 3, 1050, 2, 2793, 645, 2, 69, 11, 81, 4386, 2, 162, 4, 314],\n",
       " [1677, 10, 848, 1, 245, 229, 3386, 1233, 4, 5, 1085],\n",
       " [47, 4, 8, 468, 672, 1, 7, 2363, 129, 341, 3, 137, 3, 346, 2, 466, 962],\n",
       " [1277, 1, 50, 1, 1332, 178],\n",
       " [193, 211, 2, 69, 1, 5, 2, 192, 263, 1, 223, 3],\n",
       " [286, 78, 1255, 2, 1553, 2876, 2877, 3, 1, 37],\n",
       " [92, 954, 3109, 1, 2471, 8, 989, 2472, 3631, 1],\n",
       " [1106, 1712, 4, 812, 811, 1294, 1295, 2, 74, 1, 792, 200, 1284],\n",
       " [1556, 2, 3564, 1, 1560, 1228, 17, 548],\n",
       " [2066, 314, 115, 1, 28, 374, 2, 3105, 3, 2, 216, 329],\n",
       " [4339, 4, 15, 298, 48, 53, 1, 140, 3, 574, 159, 341],\n",
       " [33, 858, 3, 43, 1, 100, 2, 4089, 78, 266, 182],\n",
       " [52, 1969, 6, 4, 60, 782, 90, 10, 510, 2, 1956],\n",
       " [1422,\n",
       "  1808,\n",
       "  471,\n",
       "  3,\n",
       "  2196,\n",
       "  1,\n",
       "  5,\n",
       "  4159,\n",
       "  4411,\n",
       "  1,\n",
       "  132,\n",
       "  81,\n",
       "  1864,\n",
       "  81,\n",
       "  2772,\n",
       "  4363,\n",
       "  148],\n",
       " [1, 26, 487, 2, 628, 2199, 1, 5, 118, 2],\n",
       " [120, 42, 1, 1060, 4, 4028, 1, 15, 1795, 1686, 13, 1438, 270, 47],\n",
       " [33, 741, 169, 167, 3],\n",
       " [740, 1184, 4, 402, 4419, 2, 512, 2764, 1, 99],\n",
       " [251, 3527, 4, 5, 1316, 3, 2, 630, 13, 1, 910],\n",
       " [36, 1, 370, 86, 3, 2746, 2, 1456, 344, 267, 4363, 1928, 4261],\n",
       " [181, 638, 1657, 2, 3, 50, 118, 2, 422, 2198],\n",
       " [2, 29, 1094],\n",
       " [275, 339, 2386, 3, 1, 364, 29],\n",
       " [522, 2, 555, 1, 737, 2, 693, 1],\n",
       " [4432, 34, 446, 19, 210, 163, 184, 11, 1517, 2, 2821, 4433, 1518, 4, 12],\n",
       " [32, 2, 1893, 3921, 2, 3, 16, 47, 102, 4, 1210, 2, 320, 82],\n",
       " [249, 617, 67, 1, 1551],\n",
       " [1222, 1281, 2, 1060],\n",
       " [508, 134, 4087, 2263, 43, 1, 499, 4088, 1397, 2707, 3440, 1684],\n",
       " [951, 861, 3699, 82, 20, 1855, 3721, 4],\n",
       " [118, 2, 72, 63, 1, 39, 4544, 3, 1, 249, 4545, 78],\n",
       " [3912,\n",
       "  3913,\n",
       "  281,\n",
       "  1827,\n",
       "  3,\n",
       "  23,\n",
       "  82,\n",
       "  71,\n",
       "  38,\n",
       "  3799,\n",
       "  3,\n",
       "  2627,\n",
       "  4,\n",
       "  150,\n",
       "  12,\n",
       "  107,\n",
       "  19,\n",
       "  1422],\n",
       " [1449, 6, 2556, 2, 7, 53, 1898, 4, 10, 4280, 12, 156, 372, 2, 387],\n",
       " [237, 2, 973, 215, 732, 376, 1, 2, 524],\n",
       " [111, 106, 11, 2334, 2335, 30, 2, 846, 224, 173, 3, 76],\n",
       " [1083, 521, 455, 4858, 4, 526, 2, 3029, 329, 19, 350, 1310, 98],\n",
       " [3243, 133, 2, 5, 50, 934, 1702, 229],\n",
       " [1288, 923, 488, 185, 2, 243, 1, 459],\n",
       " [7, 2635, 277, 2, 5, 1296, 2, 5, 4040, 11, 2694, 4, 15, 1901],\n",
       " [466,\n",
       "  829,\n",
       "  3,\n",
       "  321,\n",
       "  86,\n",
       "  101,\n",
       "  4,\n",
       "  1461,\n",
       "  3,\n",
       "  165,\n",
       "  2,\n",
       "  15,\n",
       "  32,\n",
       "  905,\n",
       "  25,\n",
       "  103,\n",
       "  6,\n",
       "  1476],\n",
       " [2, 3830, 1, 7, 120, 1888, 2, 135, 84],\n",
       " [13, 1, 2, 3253, 196, 4, 569, 1366, 2, 6, 671, 20, 1265, 2],\n",
       " [1097, 313, 1, 1694, 2, 171, 1, 1544, 1729],\n",
       " [7, 751, 670, 403, 13, 1, 2465, 3746, 1, 32, 1, 654, 2, 5, 3],\n",
       " [50, 72, 63, 422, 3147, 3, 83, 262, 3, 846, 1230],\n",
       " [3337, 1740, 738, 17, 46],\n",
       " [241, 220, 1226, 1, 5, 3478, 4, 719, 3, 26, 3479, 1, 1781, 2, 2402],\n",
       " [1310, 98, 3, 3625, 2, 1284, 1, 15, 67, 3, 2936, 75],\n",
       " [1869, 352, 1, 579, 3, 2466, 2, 95, 1452, 772, 2542, 652, 2, 15, 838],\n",
       " [655, 391, 4, 3528, 1, 871, 2, 15, 345, 6, 3864, 127, 1, 59],\n",
       " [7,\n",
       "  4293,\n",
       "  4294,\n",
       "  4294,\n",
       "  385,\n",
       "  1,\n",
       "  4295,\n",
       "  313,\n",
       "  2,\n",
       "  3134,\n",
       "  4116,\n",
       "  4296,\n",
       "  2,\n",
       "  972,\n",
       "  394,\n",
       "  144,\n",
       "  23,\n",
       "  1,\n",
       "  948],\n",
       " [35, 2, 5, 2937, 9, 1, 87, 1077, 313, 3, 1],\n",
       " [42, 237, 1, 2875, 2, 1042, 166, 140, 1, 114],\n",
       " [734, 14, 328, 2, 2874],\n",
       " [7, 1147, 2996, 488, 3216, 3, 46, 1, 74],\n",
       " [74, 3194, 2, 1111, 78, 3, 5, 1296, 1, 310, 37, 9, 1, 423, 379],\n",
       " [147, 97, 64, 4, 1, 77, 2, 7, 7, 165, 23, 1, 33],\n",
       " [3232, 62, 112, 20, 1, 26, 1562, 976],\n",
       " [268, 8, 1457, 35, 208, 1, 912, 12, 1, 3],\n",
       " [147, 97, 4186, 177, 19, 11, 247, 565, 4, 529, 2, 577],\n",
       " [1018,\n",
       "  22,\n",
       "  936,\n",
       "  667,\n",
       "  4399,\n",
       "  70,\n",
       "  4400,\n",
       "  2507,\n",
       "  22,\n",
       "  2482,\n",
       "  900,\n",
       "  29,\n",
       "  22,\n",
       "  309,\n",
       "  293,\n",
       "  70,\n",
       "  726,\n",
       "  1414,\n",
       "  1389,\n",
       "  2761,\n",
       "  22,\n",
       "  1776,\n",
       "  232,\n",
       "  386,\n",
       "  2792,\n",
       "  58,\n",
       "  22,\n",
       "  309,\n",
       "  134,\n",
       "  253,\n",
       "  22,\n",
       "  2141,\n",
       "  1760,\n",
       "  134,\n",
       "  285,\n",
       "  70,\n",
       "  1414,\n",
       "  1389,\n",
       "  2650,\n",
       "  58,\n",
       "  3068,\n",
       "  22,\n",
       "  2576,\n",
       "  1389,\n",
       "  22,\n",
       "  936,\n",
       "  667,\n",
       "  1020,\n",
       "  4399,\n",
       "  70,\n",
       "  4400,\n",
       "  4332,\n",
       "  49,\n",
       "  1018,\n",
       "  1774,\n",
       "  253,\n",
       "  1219,\n",
       "  386,\n",
       "  70,\n",
       "  1414,\n",
       "  299,\n",
       "  157,\n",
       "  1878,\n",
       "  336,\n",
       "  89,\n",
       "  343,\n",
       "  886,\n",
       "  781,\n",
       "  2493,\n",
       "  293,\n",
       "  557,\n",
       "  238,\n",
       "  244,\n",
       "  2141,\n",
       "  1760,\n",
       "  1878,\n",
       "  1983,\n",
       "  492,\n",
       "  87,\n",
       "  183,\n",
       "  151,\n",
       "  40,\n",
       "  21,\n",
       "  40],\n",
       " [466, 829, 305, 2, 193, 1, 190, 55, 1374],\n",
       " [114, 540, 1133, 1381, 2, 51, 1078, 1133, 556, 100, 969, 13, 1, 453, 725],\n",
       " [1201,\n",
       "  1982,\n",
       "  1204,\n",
       "  522,\n",
       "  2,\n",
       "  1086,\n",
       "  3,\n",
       "  2613,\n",
       "  2,\n",
       "  4172,\n",
       "  882,\n",
       "  3,\n",
       "  1,\n",
       "  377,\n",
       "  211,\n",
       "  71,\n",
       "  1446,\n",
       "  47,\n",
       "  1,\n",
       "  10,\n",
       "  398],\n",
       " [52,\n",
       "  103,\n",
       "  1,\n",
       "  2484,\n",
       "  1057,\n",
       "  1,\n",
       "  188,\n",
       "  1,\n",
       "  7,\n",
       "  94,\n",
       "  6,\n",
       "  1642,\n",
       "  237,\n",
       "  11,\n",
       "  4,\n",
       "  160,\n",
       "  947,\n",
       "  159],\n",
       " [447, 3863, 4, 2728, 5, 770, 102, 4, 2, 153, 1, 5, 12],\n",
       " [90, 3, 219, 3, 1185, 1514, 16, 775, 776, 81, 4303, 81, 435, 2810, 91, 1853],\n",
       " [75, 102, 4, 509, 8, 669, 868, 6, 103, 1, 2511, 2, 15, 4179],\n",
       " [1893, 2, 1386, 168, 3, 16, 404, 1005, 102, 4, 295, 3, 177, 1, 15, 32],\n",
       " [26, 2174, 2, 7, 1883, 6, 31, 3, 137, 603, 2, 236, 1002],\n",
       " [439, 3, 1174, 2, 176, 4234, 344, 2727, 337, 2, 843, 2, 77],\n",
       " [1341, 1616, 1617, 4, 483, 3717, 745],\n",
       " [1315, 3216, 1, 254, 178, 714, 2, 5, 118, 2, 188],\n",
       " [3856, 53, 1285, 2, 9, 1, 12, 99, 2598, 2, 57, 584, 61],\n",
       " [1182, 788, 2, 7, 205, 3350, 18, 30, 8, 3897, 1, 45, 4034, 2, 57, 294],\n",
       " [1, 4209, 3, 127, 13, 1],\n",
       " [92, 376, 1, 245, 3, 3334, 4, 15, 3335, 3, 4, 2320, 1, 37],\n",
       " [1309, 3, 1],\n",
       " [897, 288, 17, 2091, 41, 4727, 3, 4, 72, 63, 35, 540, 225, 1593],\n",
       " [694, 634, 1649, 2178, 4953, 3, 4954, 4955, 134, 4956, 2179, 4957],\n",
       " [3589, 2, 1984, 2, 5, 109, 985, 13, 1, 3, 4326, 1, 659],\n",
       " [845, 1, 956, 20, 474, 4, 641, 11, 2364, 1, 2365, 976],\n",
       " [36, 461, 2, 69, 9, 1, 7, 120, 1943, 1786, 277],\n",
       " [3772, 2, 1859, 39, 10, 231, 1, 334, 2, 1860, 4, 366, 305],\n",
       " [4652, 2, 1575, 461, 2, 69, 9, 1, 5, 2057, 2, 186, 711],\n",
       " [28,\n",
       "  74,\n",
       "  6,\n",
       "  170,\n",
       "  141,\n",
       "  17,\n",
       "  1813,\n",
       "  29,\n",
       "  2,\n",
       "  644,\n",
       "  13,\n",
       "  1,\n",
       "  1065,\n",
       "  199,\n",
       "  1,\n",
       "  200,\n",
       "  238,\n",
       "  8,\n",
       "  695,\n",
       "  459],\n",
       " [52, 1, 73, 191, 8, 3677, 913, 471, 3, 14, 105, 2, 1300],\n",
       " [239, 2, 2763, 6, 141, 56, 5, 354, 1, 7, 197, 3, 1735, 2, 5, 34],\n",
       " [788, 14, 2604, 2, 1211, 1, 294, 3791, 116, 2, 6, 24, 3280, 465],\n",
       " [92, 2, 9, 1815, 4, 1305, 3, 1955, 8, 9, 1, 5, 168],\n",
       " [248, 405, 2, 267, 66, 1, 2, 111, 31, 3, 94],\n",
       " [2049, 3213, 3576, 3, 4, 3057, 1, 1080, 3, 1558, 115, 19, 258],\n",
       " [12, 2488, 4, 5, 268, 2, 121, 53, 1, 1046, 61],\n",
       " [10, 1851, 231, 1, 3752, 2, 240, 16, 4, 125, 3753],\n",
       " [2193, 3313, 2356, 2, 375],\n",
       " [33, 3900, 6, 1193, 1193, 277, 43, 71, 10, 67, 6, 2469, 1, 32],\n",
       " [103, 1, 5, 2, 22, 1088, 4, 1, 107, 2, 449, 449, 213],\n",
       " [249, 1, 104, 78, 50, 119, 2862, 9, 1, 5, 430, 715, 80],\n",
       " [1, 140, 3, 1122, 31, 7, 583, 1, 2990, 2, 15, 1945, 3, 12],\n",
       " [698, 4534, 2, 1248, 1, 1036, 68, 11, 2020, 4, 7, 284],\n",
       " [1122, 224, 173, 3, 42, 2706, 4, 269, 224, 173, 3, 76, 5, 153, 2, 76, 316, 2],\n",
       " [278, 3, 113, 3, 1027, 684, 1, 384, 8, 1551, 80, 169, 558, 3375, 3376],\n",
       " [7, 1326, 1389, 1, 741, 2106, 71, 353, 1031, 6, 354, 9, 1, 5, 1434],\n",
       " [52, 2780, 2, 1, 77, 2, 286, 209, 625, 3, 2, 387],\n",
       " [1079,\n",
       "  2417,\n",
       "  13,\n",
       "  164,\n",
       "  204,\n",
       "  1490,\n",
       "  3,\n",
       "  1412,\n",
       "  4,\n",
       "  424,\n",
       "  3,\n",
       "  50,\n",
       "  2671,\n",
       "  3,\n",
       "  318,\n",
       "  451,\n",
       "  484,\n",
       "  1137],\n",
       " [727, 921, 3, 663, 624, 1603],\n",
       " [101, 4, 66, 1, 132, 82],\n",
       " [53, 8, 1574, 4647, 4648, 4649, 221, 19, 213, 27, 83, 2916, 615],\n",
       " [1, 2777, 3, 569, 10, 2644, 3, 531, 1, 1816, 6, 42, 59, 79, 1159, 1, 57, 67],\n",
       " [1339, 1339, 3, 26, 2191, 1, 5, 1340, 1028, 916, 260, 1, 74],\n",
       " [2575,\n",
       "  95,\n",
       "  790,\n",
       "  2721,\n",
       "  4,\n",
       "  2117,\n",
       "  108,\n",
       "  342,\n",
       "  126,\n",
       "  282,\n",
       "  3466,\n",
       "  576,\n",
       "  1057,\n",
       "  126,\n",
       "  3,\n",
       "  16,\n",
       "  2478,\n",
       "  3596,\n",
       "  2460,\n",
       "  157,\n",
       "  343,\n",
       "  528,\n",
       "  1146,\n",
       "  2575,\n",
       "  95,\n",
       "  790,\n",
       "  2721,\n",
       "  4,\n",
       "  766,\n",
       "  348,\n",
       "  87],\n",
       " [94, 7, 356, 3, 270, 1925, 2, 3947, 9, 4, 15, 873],\n",
       " [602,\n",
       "  124,\n",
       "  675,\n",
       "  14,\n",
       "  124,\n",
       "  105,\n",
       "  3910,\n",
       "  7,\n",
       "  1461,\n",
       "  3,\n",
       "  875,\n",
       "  23,\n",
       "  1,\n",
       "  7,\n",
       "  679,\n",
       "  68,\n",
       "  246,\n",
       "  9,\n",
       "  1,\n",
       "  15,\n",
       "  5,\n",
       "  153],\n",
       " [807, 3, 65, 24, 2, 1849, 559, 99, 10, 1, 26, 161],\n",
       " [401,\n",
       "  136,\n",
       "  505,\n",
       "  2,\n",
       "  5,\n",
       "  12,\n",
       "  13,\n",
       "  1438,\n",
       "  4,\n",
       "  4114,\n",
       "  1969,\n",
       "  123,\n",
       "  38,\n",
       "  317,\n",
       "  6,\n",
       "  1,\n",
       "  26,\n",
       "  4115],\n",
       " [176, 10, 473, 1000, 4, 1484, 2, 5, 971, 6, 2723, 99, 4, 26, 161],\n",
       " [208, 3, 722, 119, 3, 2700, 4, 4274, 1, 12, 90, 17, 4, 5, 1004, 59],\n",
       " [506, 3, 8, 2809, 4374, 6, 2, 121, 617, 129, 341, 3, 96, 870, 1, 5, 34],\n",
       " [417, 608, 1543, 2861, 696, 23, 485, 55, 104],\n",
       " [122, 925, 200, 2097, 1, 541, 106, 179, 4755, 211, 2, 302, 525],\n",
       " [527, 31, 3, 3174, 119, 54, 11, 2, 815],\n",
       " [147, 97, 64, 4, 5, 762, 6, 14, 1377, 746, 1, 50, 331, 78, 3394],\n",
       " [257, 31, 3, 1872, 305, 2, 7, 50, 370, 1, 17, 8, 598, 689],\n",
       " [224, 173, 42, 25, 7, 3852, 1, 530, 2, 1531, 858, 127, 2, 266, 45],\n",
       " [180, 3330, 2544, 999, 10, 19, 195, 253, 195, 479, 4373, 21, 1864],\n",
       " [3941, 4, 5, 4150, 4151, 2203, 6, 4152, 3, 5, 9, 19, 1144, 2744, 404],\n",
       " [74, 2213, 3, 1, 555, 9, 4, 5, 1078, 2313, 1732, 1, 310, 37],\n",
       " [1400, 2, 5, 2464, 10, 2465, 118, 2, 422],\n",
       " [12, 8, 210, 163, 184, 2835, 2836, 1, 520, 802, 200, 2837],\n",
       " [433, 31, 3, 480, 753, 1217, 9, 1, 585, 344, 67, 9, 1, 57, 25, 61],\n",
       " [3189, 291, 115, 1, 3190, 435, 957, 1686, 743, 151, 3191, 1078, 1647, 839],\n",
       " [112, 322, 62, 2441, 20, 964, 88, 1681, 3558],\n",
       " [1002, 2, 7, 12, 1, 172, 752, 18, 2, 3840, 3841, 6, 2584, 1, 142, 2, 5, 36],\n",
       " [3364, 1745, 185, 88, 159],\n",
       " [3437, 612, 3, 2, 275, 2, 72, 63, 1104],\n",
       " [1494, 1390, 4, 1357, 117, 235, 10, 3624, 85, 3, 1, 22, 2446],\n",
       " [530, 2, 1701, 2127, 1, 1123, 2963, 19, 92, 44, 524],\n",
       " [518, 1597, 3, 4, 4943, 2, 5, 4944, 546, 1, 735, 40],\n",
       " [60, 14, 1325, 4370, 1, 2815, 3, 1, 566, 4001, 10, 242, 56, 266, 45],\n",
       " [598, 689, 10, 699, 1, 4338, 512, 502, 293, 22],\n",
       " [82, 215, 109, 601, 93, 43, 13, 1, 1396],\n",
       " [2995, 1, 145, 330, 2326, 1, 171],\n",
       " [12, 1213, 20, 474, 4, 295, 3, 203, 2, 61, 41, 123, 14, 47, 2, 2696, 1, 659],\n",
       " [110, 1213, 3, 127, 1, 531, 2, 42, 3, 575, 2, 15, 1512],\n",
       " [405, 8, 945, 158, 2, 45, 45, 1102, 255, 146, 260, 1, 332, 3100],\n",
       " [7, 53, 2354, 11, 3959, 1051, 2, 3840, 1, 649, 2, 12],\n",
       " [40, 78, 1306, 1, 80, 3008],\n",
       " [2230, 219, 3, 3153, 1, 1, 2231, 2, 2827, 800, 2232],\n",
       " [1764, 2, 160, 803, 304, 3327, 1, 1765, 364, 388, 199, 1766, 1, 39, 44, 1590],\n",
       " [2912, 62, 489, 2913, 8, 2054, 1271, 1, 310, 529],\n",
       " [111, 351, 11, 616, 4, 4720, 4721, 1, 1058],\n",
       " [55, 56, 130, 1, 145, 330, 1309, 3, 1, 3103, 1, 210],\n",
       " [442, 18, 1118, 3, 3724, 1, 1546, 14, 1376, 19, 315, 856, 171, 4284, 3],\n",
       " [2, 5, 1, 486, 687, 3379, 438, 233, 35, 7, 168],\n",
       " [374, 2, 2345, 2151, 920, 4, 39, 3, 2116, 1, 526, 2, 327],\n",
       " [3, 2, 74, 919],\n",
       " [897, 1527, 1, 4674, 225, 1280, 1, 382, 714, 2, 428, 89, 170, 3, 226],\n",
       " [595, 220, 1819, 3, 4, 3, 9, 440, 1, 5, 12, 13, 1, 2332],\n",
       " [103, 56, 12, 8, 2054, 1271, 471, 3],\n",
       " [2021, 4535, 4536, 41, 609, 149, 1249, 34, 4537, 1, 699],\n",
       " [1740, 2477, 2245, 8],\n",
       " [1491, 1516, 97, 64, 1985, 6, 85, 4, 180, 1750, 8, 195, 479],\n",
       " [359, 2246, 1, 3074, 2, 3176, 1, 1021],\n",
       " [569, 4, 32, 13, 1, 3404, 2, 344, 1394, 4272],\n",
       " [52, 130, 1, 1, 1758, 237, 1, 1116, 2349, 1645, 293, 80],\n",
       " [150, 908, 620, 1, 5, 130, 1, 720, 238, 4962, 91, 4963, 3, 2, 210],\n",
       " [1340, 378, 1391, 4, 3585, 2, 3490, 2, 62, 494, 1, 57, 37],\n",
       " [307, 2886, 1, 145, 2223, 1536, 3172, 3173, 2, 423, 379],\n",
       " [96, 1, 2510, 3, 2533, 2, 15, 5, 176, 328, 1, 2597, 2, 84],\n",
       " [1066, 10, 1730, 728, 88, 412],\n",
       " [898, 221, 1, 1810, 3, 1037, 2, 189, 1, 5, 118, 2, 915, 62, 3, 83, 828, 2154],\n",
       " [189, 378, 1391, 4, 3015, 414, 1, 3551, 2, 3633, 1, 5, 1162],\n",
       " [36, 310, 2905, 116, 2, 5, 109, 985, 81, 116, 2, 126],\n",
       " [2508, 3733, 4, 14, 503, 1468, 107, 1, 3815, 3816, 472, 1, 324, 1061],\n",
       " [7, 42, 2, 23, 1, 4079, 2, 2615, 645, 2, 5],\n",
       " [893, 313, 3, 1, 4, 2, 222, 3234, 1, 5, 647, 1700],\n",
       " [217, 239, 2, 5, 3067, 1, 4939, 1327, 6, 5, 633, 4940, 1, 4941, 365],\n",
       " [183, 846, 415, 820, 3518, 3, 115, 1, 72, 63],\n",
       " [540, 833, 1337, 1362, 2, 251, 2, 390, 1775, 800],\n",
       " [3675,\n",
       "  2,\n",
       "  7,\n",
       "  2521,\n",
       "  2757,\n",
       "  3,\n",
       "  596,\n",
       "  483,\n",
       "  2829,\n",
       "  721,\n",
       "  477,\n",
       "  124,\n",
       "  105,\n",
       "  81,\n",
       "  3998,\n",
       "  14,\n",
       "  175,\n",
       "  581,\n",
       "  116],\n",
       " [6, 1708, 1, 152],\n",
       " [1279, 3421, 4, 427, 427, 41, 38, 360, 8, 92],\n",
       " [362, 20, 2389, 4, 1394, 410, 9, 1, 5, 230, 2, 1330],\n",
       " [243, 227, 4740, 1596, 1, 37, 108, 14, 4741, 2, 493],\n",
       " [60, 14, 30, 478, 1, 119, 13, 1, 15, 995, 3751, 2, 331, 1],\n",
       " [5, 1705, 4, 592, 148, 1706],\n",
       " [7, 512, 1688, 4, 1901, 2, 3866, 13, 38, 7, 36, 24, 503, 77],\n",
       " [442, 18, 50, 701, 315, 27, 3297, 571, 258, 2693, 184, 2690, 1964],\n",
       " [485, 860, 1358, 35, 1801, 2, 2427],\n",
       " [993,\n",
       "  2558,\n",
       "  1118,\n",
       "  3,\n",
       "  14,\n",
       "  97,\n",
       "  233,\n",
       "  24,\n",
       "  3775,\n",
       "  2,\n",
       "  172,\n",
       "  16,\n",
       "  586,\n",
       "  81,\n",
       "  996,\n",
       "  1967,\n",
       "  21,\n",
       "  3932,\n",
       "  29,\n",
       "  18,\n",
       "  534,\n",
       "  151,\n",
       "  253,\n",
       "  3471],\n",
       " [6, 127, 4347, 4348, 786],\n",
       " [2, 48, 1049, 2, 1469, 4, 469, 6, 160, 4397, 3, 4, 310, 995, 217],\n",
       " [2807, 2808, 24, 79, 2794, 1, 1141, 2, 320, 2241, 2, 5, 34],\n",
       " [111, 1, 104, 3, 3093, 23, 1, 553, 3],\n",
       " [100, 787, 1010, 2, 32, 11, 14, 2, 469, 6, 2390, 4, 248, 399],\n",
       " [205, 3266, 1380, 3, 16, 166, 3267, 167, 3],\n",
       " [52, 30, 4, 1042, 166, 140, 3, 1758, 106, 11, 4, 68, 182],\n",
       " [723, 2360, 1267, 2150, 8, 158, 11, 2940, 16, 250],\n",
       " [7, 96, 45, 45, 3, 3507, 9, 2674, 4, 5, 2594, 2, 15, 5, 65],\n",
       " [867, 1169, 4, 7, 137, 3, 1510, 35, 7, 1],\n",
       " [2332, 2, 2006, 1, 1060, 1, 251],\n",
       " [1688, 4, 3475, 2, 1097, 6, 2, 104, 2284, 1783],\n",
       " [89, 45, 144, 222, 265, 801, 2063, 14, 17, 46, 4667],\n",
       " [464, 3165, 91, 2237, 932, 8, 241, 413, 250],\n",
       " [338, 875, 2, 1046, 125, 870, 1, 142, 2, 5, 34],\n",
       " [2494, 3, 2386, 1, 7, 1214, 2698, 4, 116, 2, 131, 1, 77, 59],\n",
       " [36, 461, 2, 69, 9, 1941, 4, 797, 717, 12, 3, 7, 986, 2, 621],\n",
       " [1822, 1251, 1, 2, 1029, 8, 27, 115, 19, 3626, 3627],\n",
       " [324, 1061, 80, 1261, 4, 115, 1, 5, 2494, 3, 2],\n",
       " [259, 2, 7, 401, 1888, 30, 2, 15, 84, 2776, 4, 142, 2, 5, 34],\n",
       " [31, 3, 42, 54, 1, 591, 2, 52, 369, 3322, 1, 3323],\n",
       " [2409, 455, 645, 1, 338, 45, 2, 2410, 1784],\n",
       " [3, 105, 575, 85, 9, 10, 2607, 105, 56, 1792, 2, 120, 219, 1195, 1],\n",
       " [4695, 1052, 2, 2938, 306, 810, 1, 190],\n",
       " [626, 2, 797, 2959, 406, 1, 1287],\n",
       " [688, 86, 851, 4157, 21, 18, 2686],\n",
       " [4874, 306, 2, 700, 190, 55, 933, 922, 3],\n",
       " [241, 2382, 264, 1312, 1, 116, 2, 2, 2006, 4],\n",
       " [2543, 3388, 987, 3, 561, 3, 3909, 4060, 13, 946, 4, 1932, 107, 1, 5, 153],\n",
       " [186, 3053, 1364, 1, 1575, 149, 3336, 2321, 349, 68, 185, 2911, 1, 280],\n",
       " [1583, 1, 1, 152],\n",
       " [1328, 4, 118, 2, 122, 303, 3, 2354, 1, 2355, 13, 1, 604, 191],\n",
       " [10, 4280, 61, 545, 3, 378, 4, 1006, 2, 559, 9, 1, 5, 12],\n",
       " [1880, 756, 4, 298, 861, 377, 203, 1, 2672, 126, 8, 2553, 2554],\n",
       " [50, 4166, 3, 840, 2, 5, 1835, 1, 1214, 101, 2, 36, 3, 671, 2, 1906],\n",
       " [1457, 6, 3768, 3769, 2, 904, 416, 211, 2, 1727, 402, 1388, 18, 1, 627],\n",
       " [907, 2210, 35, 2891, 16, 1574, 3128, 6, 299],\n",
       " [1754, 9, 1, 974, 496, 3392, 3, 88, 412],\n",
       " [1098, 1242, 2208, 13, 1, 2860, 1, 188, 19, 1664],\n",
       " [3353, 35, 3354, 2, 37],\n",
       " [194, 385, 4, 1495, 8, 234, 13, 1, 7, 1651],\n",
       " [70, 495, 70, 6, 2, 262, 10, 1183, 19, 3861, 395, 2714, 2715],\n",
       " [1338, 270, 4, 709, 108, 123, 97, 64, 587, 1785, 1, 5, 1209, 215, 2669],\n",
       " [102, 483, 1495, 47, 102, 4, 366, 177, 1, 32, 8, 33],\n",
       " [1057, 2, 55, 3, 130, 1, 1, 138, 749, 3],\n",
       " [241, 27, 2475, 75, 4, 203, 2, 1, 26, 3651, 2, 1097],\n",
       " [148,\n",
       "  335,\n",
       "  41,\n",
       "  10,\n",
       "  2898,\n",
       "  85,\n",
       "  3,\n",
       "  1965,\n",
       "  1,\n",
       "  5,\n",
       "  1316,\n",
       "  3,\n",
       "  1434,\n",
       "  2,\n",
       "  1931,\n",
       "  10,\n",
       "  697,\n",
       "  85,\n",
       "  3,\n",
       "  863,\n",
       "  919,\n",
       "  174,\n",
       "  283,\n",
       "  21,\n",
       "  1868,\n",
       "  3,\n",
       "  41,\n",
       "  85,\n",
       "  2,\n",
       "  1316,\n",
       "  1,\n",
       "  7,\n",
       "  133,\n",
       "  289,\n",
       "  3,\n",
       "  785,\n",
       "  41,\n",
       "  38,\n",
       "  339,\n",
       "  419,\n",
       "  4300,\n",
       "  3,\n",
       "  643,\n",
       "  3,\n",
       "  4427,\n",
       "  2,\n",
       "  339,\n",
       "  149,\n",
       "  4427,\n",
       "  2,\n",
       "  6,\n",
       "  233,\n",
       "  4,\n",
       "  1434,\n",
       "  157,\n",
       "  307,\n",
       "  29,\n",
       "  22,\n",
       "  309,\n",
       "  3939,\n",
       "  29,\n",
       "  307,\n",
       "  368,\n",
       "  1259,\n",
       "  1411,\n",
       "  1444,\n",
       "  2646,\n",
       "  879,\n",
       "  1170,\n",
       "  1451,\n",
       "  89,\n",
       "  87],\n",
       " [2224, 2225, 1243, 1, 51, 133, 1, 741, 1124, 2, 2487, 279],\n",
       " [48, 2681, 3, 3841, 1, 1948, 1949, 4043],\n",
       " [48, 807, 3, 79, 1159, 1, 1856, 2, 292, 1013, 1, 5, 34],\n",
       " [7, 252, 23, 1, 1348, 3, 757, 758, 1959, 2, 466, 4375, 1, 2785, 287, 17],\n",
       " [92, 1, 1247, 1, 245, 1641, 1134, 21, 3338, 2015, 1355, 21],\n",
       " [1644, 2, 7, 3228, 552, 4, 5, 2654, 930, 1, 2, 5, 79, 4, 759],\n",
       " [3727,\n",
       "  3748,\n",
       "  2,\n",
       "  520,\n",
       "  3481,\n",
       "  1,\n",
       "  33,\n",
       "  125,\n",
       "  3,\n",
       "  16,\n",
       "  2405,\n",
       "  3480,\n",
       "  6,\n",
       "  1,\n",
       "  334,\n",
       "  247,\n",
       "  16,\n",
       "  2403,\n",
       "  2404],\n",
       " [166, 631, 101, 41, 590, 590, 4, 15, 5, 66, 662, 1, 577],\n",
       " [3568, 87, 453, 3262, 29, 22, 224, 1, 332, 2447, 1426],\n",
       " [595, 220, 3462, 1, 374, 2, 359, 155, 105, 3578, 117, 3579],\n",
       " [2572, 6, 1836, 3729, 101, 4, 14, 503, 1468, 1, 3831, 2, 380, 1, 57, 450],\n",
       " [53, 8, 1188, 783, 352, 1, 2, 1859, 39, 87, 14, 784, 661, 41, 147, 4, 177],\n",
       " [195, 479, 3, 729, 14, 3, 107, 4, 609, 335, 2102, 58, 497, 209],\n",
       " [172, 668, 2, 2723, 3983, 1, 84, 6, 26, 161, 570, 3, 346, 1, 140, 3, 1803],\n",
       " [1216, 1005, 102, 1985, 16, 1770, 612, 762, 2, 1, 1948, 1949],\n",
       " [2710, 2711, 19, 598, 689, 1466, 31, 85, 3, 108, 164, 85, 17, 561],\n",
       " [893, 1588, 3, 567, 193, 17, 18, 4, 5, 222, 2068, 3, 293, 29, 735, 122],\n",
       " [3764, 14, 1, 24, 1631, 6, 1, 450],\n",
       " [885,\n",
       "  2,\n",
       "  7,\n",
       "  1209,\n",
       "  215,\n",
       "  14,\n",
       "  2636,\n",
       "  4,\n",
       "  2583,\n",
       "  2,\n",
       "  109,\n",
       "  93,\n",
       "  882,\n",
       "  3,\n",
       "  2674,\n",
       "  1975,\n",
       "  4,\n",
       "  314,\n",
       "  2,\n",
       "  162],\n",
       " [9, 1, 15, 2231, 1130, 4, 1926, 968, 8, 992, 3759, 6, 2, 15, 84],\n",
       " [940, 3102, 3, 2, 179, 1274, 554, 3, 5, 628, 2199, 88, 1573],\n",
       " [42, 878, 2, 503, 67, 1, 566, 793, 78, 673, 10, 17],\n",
       " [402, 1006, 2, 769, 6, 770, 2, 12, 3, 10, 371, 2682, 2, 740],\n",
       " [48, 4287, 923, 967, 2, 5, 3708, 24, 3096, 4368, 17, 1, 5, 864],\n",
       " [25, 172, 1873, 116, 2, 4372, 2, 240, 136, 2666, 2, 67, 6, 2756, 2, 392],\n",
       " [5, 62, 3, 10, 371, 1, 490, 260, 1],\n",
       " [1677, 2096, 2147, 4, 911, 115, 1, 530, 2, 2, 1529, 6, 458, 1264],\n",
       " [1442, 3239, 3679, 115, 1, 1367, 8, 27, 3, 1, 327],\n",
       " [326,\n",
       "  4532,\n",
       "  2014,\n",
       "  4,\n",
       "  2015,\n",
       "  2864,\n",
       "  35,\n",
       "  2865,\n",
       "  2,\n",
       "  1034,\n",
       "  1,\n",
       "  5,\n",
       "  94,\n",
       "  2016,\n",
       "  3,\n",
       "  1,\n",
       "  1544,\n",
       "  2017,\n",
       "  2,\n",
       "  212],\n",
       " [52, 461, 2, 56, 1818, 9, 1, 12, 1470, 20, 14, 1463, 2, 579],\n",
       " [951, 1236, 1, 1, 1682, 1100, 332, 2],\n",
       " [626, 2, 7, 1301, 246, 406, 1, 539],\n",
       " [28, 1050, 2, 647, 942, 2327],\n",
       " [350, 27, 2, 212, 3558],\n",
       " [246, 151, 256, 3917, 22, 29, 1205, 375, 779, 3992, 1937, 29, 151],\n",
       " [227, 1113, 952, 1359, 1, 37, 179, 1114, 820, 83, 537, 13, 1, 1676],\n",
       " [7, 480, 4, 135, 2490, 144, 167, 81, 1967, 21, 2890, 4147],\n",
       " [1511, 31, 3, 110, 2730, 1, 664, 2, 6, 4127, 9, 1, 15, 84],\n",
       " [1813, 242, 1, 3620, 2, 5, 462, 2, 7, 1821, 1, 256],\n",
       " [1, 4, 187, 71, 2, 499, 11, 2671, 1995, 2, 7, 448, 4, 1646, 3, 47, 71, 1, 2],\n",
       " [7, 2786, 277, 51, 129, 24, 6, 1014, 878, 3, 2, 15, 135, 67],\n",
       " [208, 3, 990, 86, 549, 38, 32, 79, 1838, 1, 15, 990],\n",
       " [3520, 476, 1417, 1, 1711, 236, 1313, 2, 37, 3521, 4, 3522, 2427],\n",
       " [52, 30, 1, 150, 2257, 2, 121, 12, 106, 1, 114],\n",
       " [217, 4, 32, 43, 2, 33, 2059, 4336, 81, 4143, 3, 16, 3780],\n",
       " [2282, 14, 2263, 1, 225, 1, 178, 223],\n",
       " [7, 1453, 1869, 10, 125, 6, 4211, 1, 1175, 1931],\n",
       " [1036, 68, 10, 353, 424, 1, 5, 4630, 1, 485, 104, 21, 257],\n",
       " [2443, 2, 2, 1056, 1056, 1421, 3, 1, 212],\n",
       " [22, 700, 980, 3887, 4, 997, 107, 82, 1],\n",
       " [795, 24, 2824, 1, 4441, 796, 482, 348, 133, 83, 594, 2, 349, 198, 40],\n",
       " [230, 3, 305, 2, 190, 1918, 2, 135, 717, 12],\n",
       " [362, 3075, 1330, 1570, 2, 3251, 831, 156, 1, 275, 356, 2],\n",
       " [52, 24, 2951, 54, 1, 2083, 1, 792],\n",
       " [528, 4418, 4228, 103, 1, 5, 203, 41, 123, 322, 1, 1769],\n",
       " [4016, 514, 862, 3, 3, 233, 2, 166, 4079, 20, 14, 24],\n",
       " [1043, 2, 1549, 1, 3120, 1133, 312, 3, 312, 3, 1, 485, 551, 3393],\n",
       " [1511,\n",
       "  31,\n",
       "  3,\n",
       "  110,\n",
       "  753,\n",
       "  1217,\n",
       "  1,\n",
       "  4356,\n",
       "  2,\n",
       "  990,\n",
       "  90,\n",
       "  4,\n",
       "  284,\n",
       "  742,\n",
       "  95,\n",
       "  675,\n",
       "  164,\n",
       "  1006,\n",
       "  2,\n",
       "  361],\n",
       " [1752, 2086, 350, 3388, 4, 946, 26, 3389, 2, 171, 1, 3390, 2, 1753],\n",
       " [287, 28, 2042, 2, 87, 421, 768, 1, 931, 2413],\n",
       " [644, 2292, 4, 1256, 1, 3268, 465, 2, 189, 115, 1, 685, 3, 517],\n",
       " [2033, 2, 1040, 1, 152, 4585, 13, 1, 2884, 4586, 1, 2885],\n",
       " [195, 479, 6, 342, 3615, 13, 1, 4304, 1, 132, 81, 658, 1180, 1205, 4304],\n",
       " [615,\n",
       "  3,\n",
       "  3599,\n",
       "  2,\n",
       "  5,\n",
       "  168,\n",
       "  71,\n",
       "  637,\n",
       "  4,\n",
       "  1764,\n",
       "  2,\n",
       "  3364,\n",
       "  1745,\n",
       "  772,\n",
       "  4,\n",
       "  5,\n",
       "  168,\n",
       "  41,\n",
       "  637,\n",
       "  126,\n",
       "  4,\n",
       "  7,\n",
       "  1126,\n",
       "  3,\n",
       "  2,\n",
       "  6,\n",
       "  3486,\n",
       "  1,\n",
       "  590,\n",
       "  4,\n",
       "  665,\n",
       "  2,\n",
       "  5,\n",
       "  2816,\n",
       "  409,\n",
       "  4,\n",
       "  5,\n",
       "  4341,\n",
       "  909,\n",
       "  3,\n",
       "  4,\n",
       "  1745,\n",
       "  950,\n",
       "  1437,\n",
       "  47],\n",
       " [33, 2548, 601, 681, 6, 3739, 670, 346, 6, 2713, 1, 4093, 1407, 207],\n",
       " [787, 2, 633, 3870, 101, 41, 419, 75, 858, 2, 160, 3871, 266, 356],\n",
       " [3178, 942, 2, 93, 3, 10, 94, 1, 77, 2, 109, 1629, 1668, 2, 357],\n",
       " [183, 33, 143, 158, 920, 4, 3, 1437, 16, 315, 27],\n",
       " [702, 481, 3, 3530],\n",
       " [7, 53, 291, 11, 4, 177, 1, 15, 12, 1, 2, 859],\n",
       " [98, 274, 1670, 2, 37, 13, 1, 1, 3577, 59, 6, 2, 15, 84],\n",
       " [438, 12, 4, 1420, 1, 387, 1, 401, 10, 1132, 1, 26, 1492],\n",
       " [33, 43, 71, 476, 261, 3, 4, 4234, 6, 9, 393, 978, 3, 1958],\n",
       " [155, 2034, 2, 7, 2035, 2886, 1, 1257, 2, 1043, 2, 907, 2887, 1258],\n",
       " [650, 4117, 206, 70, 3642, 1850],\n",
       " [205, 73, 11, 4, 179, 4260, 3, 478, 23, 1, 4389],\n",
       " [23, 1, 3, 3380, 41, 1506, 2, 5, 168, 4, 1711, 236, 371, 20, 38, 447],\n",
       " [1516,\n",
       "  1985,\n",
       "  16,\n",
       "  4379,\n",
       "  458,\n",
       "  419,\n",
       "  47,\n",
       "  1398,\n",
       "  2,\n",
       "  989,\n",
       "  29,\n",
       "  3655,\n",
       "  4309,\n",
       "  6,\n",
       "  123,\n",
       "  671,\n",
       "  3,\n",
       "  483,\n",
       "  3358,\n",
       "  82],\n",
       " [76, 1470, 11, 14, 1, 968, 3, 4034, 1, 132, 4, 5, 380],\n",
       " [1183, 2, 69, 9, 1, 120, 443, 1, 1924, 510, 2, 2155, 23, 1, 5, 34],\n",
       " [882, 3, 71, 4, 7, 583, 13, 1, 560, 3, 177, 1, 15, 2516],\n",
       " [3, 4315, 1, 7, 4, 2, 34, 100],\n",
       " [506, 3, 2570, 2, 7, 345, 1, 167, 3, 655, 501, 2584, 1, 142, 2, 5, 34],\n",
       " [176, 1417, 101, 4, 66, 1468, 1, 532],\n",
       " [169, 3506, 2417, 13, 1, 14, 901, 2, 1412, 79, 3507],\n",
       " [176, 4015, 4, 9, 1, 1488, 4223, 2, 153, 372, 3, 464, 271, 272],\n",
       " [179, 1114, 113, 1, 228, 138, 1, 50, 159, 5, 3689, 1689],\n",
       " [74,\n",
       "  3242,\n",
       "  3,\n",
       "  4,\n",
       "  122,\n",
       "  130,\n",
       "  1,\n",
       "  103,\n",
       "  56,\n",
       "  619,\n",
       "  3552,\n",
       "  3,\n",
       "  2,\n",
       "  7,\n",
       "  65,\n",
       "  2,\n",
       "  1344,\n",
       "  29,\n",
       "  256],\n",
       " [2679,\n",
       "  677,\n",
       "  4,\n",
       "  5,\n",
       "  34,\n",
       "  41,\n",
       "  590,\n",
       "  4,\n",
       "  112,\n",
       "  2721,\n",
       "  1,\n",
       "  659,\n",
       "  8,\n",
       "  2353,\n",
       "  1039,\n",
       "  4106,\n",
       "  4106],\n",
       " [2889, 1246, 3, 64, 41, 419, 4597, 4, 4598, 909, 3, 88, 798, 910],\n",
       " [332, 333, 634, 1690, 1373, 9, 1, 5, 2, 186, 1550, 765, 2, 34],\n",
       " [2011, 1, 979, 2, 2336, 88, 939, 1426],\n",
       " [970, 1920, 4, 436, 3, 953, 1, 132, 4184, 18, 615],\n",
       " [830, 914, 3, 2, 1761, 16, 2172, 2173],\n",
       " [632, 138, 553, 38, 407, 156, 639, 89, 44, 1303],\n",
       " [202, 1381, 2, 112, 503, 800, 2295, 1, 2296, 2, 496, 23, 1, 218],\n",
       " [170, 106, 1, 716, 3, 1050, 30, 2, 685, 3, 4688],\n",
       " [1075,\n",
       "  86,\n",
       "  2,\n",
       "  3049,\n",
       "  2156,\n",
       "  4897,\n",
       "  30,\n",
       "  1,\n",
       "  1321,\n",
       "  11,\n",
       "  1634,\n",
       "  1635,\n",
       "  1,\n",
       "  3050,\n",
       "  4,\n",
       "  484,\n",
       "  417,\n",
       "  24,\n",
       "  3051],\n",
       " [1884, 166, 3, 267, 196, 2, 7, 65, 9, 3904, 1635, 4, 15, 439],\n",
       " [614, 3209, 4, 2411, 3092, 1, 5, 3, 987, 71, 203, 9, 2, 1160],\n",
       " [191, 8, 1074, 4042, 1187, 1, 52, 1, 132, 6, 3874, 107, 1102, 255],\n",
       " [2, 3528, 20, 3, 4, 25, 3529, 107],\n",
       " [111, 3, 1140, 54, 11, 2, 1, 539],\n",
       " [1094, 3275, 1, 51, 133, 1303],\n",
       " [130, 1, 188, 1, 1266, 430, 324, 2074, 921],\n",
       " [36, 4, 767, 1450, 2, 417, 451, 484, 1, 321, 86, 3, 2],\n",
       " [1915, 2, 1, 57, 674, 2, 2769, 6],\n",
       " [205, 4238, 23, 1, 712, 396, 3, 11, 3980, 4, 32, 2, 28, 2695],\n",
       " [12,\n",
       "  519,\n",
       "  2830,\n",
       "  1522,\n",
       "  6,\n",
       "  4459,\n",
       "  4460,\n",
       "  3,\n",
       "  16,\n",
       "  1523,\n",
       "  4461,\n",
       "  2831,\n",
       "  3,\n",
       "  598,\n",
       "  689,\n",
       "  4462,\n",
       "  1524,\n",
       "  4463,\n",
       "  5,\n",
       "  1026],\n",
       " [1444, 1279, 374, 20, 1755, 1, 307, 3033, 2, 333, 711],\n",
       " [882, 3, 71, 66, 877, 79, 3, 54],\n",
       " [202, 38, 724, 3, 3535, 1, 622, 463, 2246, 2, 5, 3535, 1, 37],\n",
       " [92, 3, 144, 470, 4, 1738, 2, 202],\n",
       " [1072, 2055, 2, 257, 28, 247, 1742, 3, 3345, 88, 159],\n",
       " [3, 3937, 3937, 2, 7, 480, 3719, 4, 2644, 3, 66, 699, 59, 510, 2, 880],\n",
       " [413, 250, 187, 895, 4479, 303, 4480, 1233],\n",
       " [40, 118, 2, 72, 63, 1],\n",
       " [3, 16, 1411, 2643, 47, 102, 4, 203, 2, 15, 1218, 2570, 1, 140, 3, 3229],\n",
       " [183, 694, 634, 14, 90, 1, 5, 961, 687],\n",
       " [52, 86, 73, 11, 2, 93, 20, 13, 2517, 146, 75, 59],\n",
       " [2, 2209, 259, 22, 395],\n",
       " [1647, 29, 2171, 3, 4945, 1, 384, 8, 824, 4946, 720, 549, 54],\n",
       " [6, 1, 845, 3, 23, 1, 324, 2074, 2024, 3],\n",
       " [25, 491, 58, 809, 237, 20, 30, 4, 7, 1042, 166, 140, 3, 575, 1, 659, 2, 100],\n",
       " [50, 2671, 3, 318, 2, 447, 4, 995, 11, 746, 4, 3774, 2019],\n",
       " [557, 2207, 244, 2208, 3],\n",
       " [5, 859, 3538, 264, 2, 898, 3, 3539, 2, 9, 1, 5, 1417],\n",
       " [170, 1416, 1, 2067, 939, 364, 421, 768],\n",
       " [3331, 29, 2089, 291, 1, 5, 647, 1700, 2, 500],\n",
       " [33, 6, 943, 1082, 2, 447, 43, 160, 116, 2, 2320, 95, 3],\n",
       " [2314, 549, 1, 292, 1200, 6, 4, 116, 2, 4249, 467],\n",
       " [2790, 2, 69, 2, 84, 8, 4297, 2312, 3787, 2, 34],\n",
       " [775, 776, 21, 2187, 1, 1, 3043, 107, 82, 957, 24, 2773, 174],\n",
       " [1499,\n",
       "  1947,\n",
       "  49,\n",
       "  158,\n",
       "  386,\n",
       "  2843,\n",
       "  4025,\n",
       "  1408,\n",
       "  22,\n",
       "  327,\n",
       "  91,\n",
       "  3731,\n",
       "  2507,\n",
       "  3732,\n",
       "  58,\n",
       "  2295,\n",
       "  319,\n",
       "  22,\n",
       "  4032,\n",
       "  29,\n",
       "  441,\n",
       "  58,\n",
       "  778,\n",
       "  200,\n",
       "  418,\n",
       "  157,\n",
       "  2113,\n",
       "  1499,\n",
       "  1947,\n",
       "  21,\n",
       "  2623,\n",
       "  174,\n",
       "  218,\n",
       "  1180,\n",
       "  1150,\n",
       "  1403,\n",
       "  2497,\n",
       "  255,\n",
       "  735,\n",
       "  492,\n",
       "  154],\n",
       " [1891, 220, 21, 595, 589, 3, 589, 2, 208, 95, 4, 39, 589, 347, 4, 5, 261],\n",
       " [380, 9, 1, 5, 1624, 284, 4826, 2, 698, 597, 548, 2126],\n",
       " [2219, 1170, 4, 68, 836, 764, 28, 40],\n",
       " [28, 1086, 381, 20, 4883, 244, 693, 934, 1, 218, 2151, 548, 74],\n",
       " [25, 125, 23, 1, 256, 2, 150, 532, 1452, 4, 2527, 6],\n",
       " [7, 53, 3734, 2, 4, 60, 3888, 1, 26, 2, 12, 107],\n",
       " [2697,\n",
       "  2060,\n",
       "  197,\n",
       "  3,\n",
       "  436,\n",
       "  3,\n",
       "  16,\n",
       "  1978,\n",
       "  552,\n",
       "  41,\n",
       "  419,\n",
       "  75,\n",
       "  3,\n",
       "  432,\n",
       "  2,\n",
       "  103,\n",
       "  2739,\n",
       "  436],\n",
       " [25, 2301, 50, 367, 1, 109, 601, 196, 4, 1631, 2003],\n",
       " [239, 2, 973, 6, 971, 3500, 738, 4, 239, 88, 159],\n",
       " [3362, 2, 62, 2289, 1, 3, 901, 2, 201],\n",
       " [1467, 2619, 3, 16, 2187, 3679, 19, 2658, 85, 3, 290, 105],\n",
       " [189,\n",
       "  3395,\n",
       "  4,\n",
       "  653,\n",
       "  2,\n",
       "  2880,\n",
       "  1155,\n",
       "  3343,\n",
       "  2019,\n",
       "  3,\n",
       "  2398,\n",
       "  4,\n",
       "  375,\n",
       "  3471,\n",
       "  1,\n",
       "  3060],\n",
       " [557, 2207, 244, 180, 163, 2208, 811, 744, 981, 330, 3453, 88, 356],\n",
       " [3, 4, 939, 542, 85, 3, 4186, 1105, 149, 2356, 2],\n",
       " [1304, 184, 4, 118, 8, 98, 2492],\n",
       " [431, 1410, 3, 26, 1837, 4, 326, 2, 450, 1076, 2244, 1, 254, 178],\n",
       " [597, 1636, 4, 5, 2290, 2, 1443, 1, 1610, 2444, 2, 960, 1782],\n",
       " [5, 4915, 3, 83, 2163, 813, 229, 4916, 3058, 260, 19, 27],\n",
       " [2409, 1788, 365, 2, 1784, 2, 2410, 38, 2411, 1658, 13, 1, 100],\n",
       " [676, 3, 1184, 2724, 25, 1394, 82, 2700, 347, 6, 767],\n",
       " [1197,\n",
       "  232,\n",
       "  21,\n",
       "  22,\n",
       "  1731,\n",
       "  2311,\n",
       "  1219,\n",
       "  70,\n",
       "  29,\n",
       "  1150,\n",
       "  1403,\n",
       "  425,\n",
       "  232,\n",
       "  4091,\n",
       "  148,\n",
       "  134,\n",
       "  22,\n",
       "  324,\n",
       "  3011,\n",
       "  3883,\n",
       "  70,\n",
       "  324,\n",
       "  2425,\n",
       "  22,\n",
       "  368,\n",
       "  1197,\n",
       "  148,\n",
       "  3955,\n",
       "  21,\n",
       "  1150,\n",
       "  1403,\n",
       "  883,\n",
       "  157,\n",
       "  307,\n",
       "  29,\n",
       "  22,\n",
       "  309,\n",
       "  307,\n",
       "  368,\n",
       "  1259,\n",
       "  1411,\n",
       "  1444,\n",
       "  2646,\n",
       "  879,\n",
       "  1170,\n",
       "  1451,\n",
       "  89,\n",
       "  87,\n",
       "  183,\n",
       "  1433,\n",
       "  574,\n",
       "  21,\n",
       "  1433,\n",
       "  1025],\n",
       " [16, 11, 4, 1375, 6, 259, 59, 1],\n",
       " [7, 3, 137, 160, 20, 2, 3359, 4, 5, 655, 3922, 242, 347, 1, 32],\n",
       " [4, 1461, 3, 165, 1, 748, 2, 3777, 58, 3125],\n",
       " [1934, 4, 585, 3, 1108, 2, 322, 12, 108, 14, 107, 3, 4, 208, 2, 5, 47],\n",
       " [2632, 583, 1, 2684, 2632, 6, 3, 97, 10, 513, 77, 17],\n",
       " [35, 1313, 2, 1035, 80, 3034, 1627, 2, 3469, 557],\n",
       " [3208, 2, 5, 454, 3, 934, 1691, 3209, 1, 171],\n",
       " [74,\n",
       "  24,\n",
       "  1525,\n",
       "  2,\n",
       "  72,\n",
       "  63,\n",
       "  2090,\n",
       "  1632,\n",
       "  1,\n",
       "  5,\n",
       "  133,\n",
       "  3,\n",
       "  328,\n",
       "  2,\n",
       "  26,\n",
       "  2,\n",
       "  1231,\n",
       "  1997],\n",
       " [25, 1758, 3, 2368, 1, 802, 1275],\n",
       " [4767, 2978, 1, 2979, 4768, 2, 362],\n",
       " [1962, 1971, 13, 1, 473, 103, 1496, 2524, 246],\n",
       " [155, 1279, 14, 270, 4673, 41, 123, 264, 2930, 2, 212, 4, 427, 427],\n",
       " [254, 178, 350, 98, 2466, 2, 28, 1721, 1813, 1, 212],\n",
       " [4128, 16, 977, 42, 1, 451, 484, 3, 977, 347, 4, 10, 1321, 13, 38, 1412],\n",
       " [357, 1261, 4, 911, 115, 1, 2892, 1560],\n",
       " [1902, 4, 14, 2950, 642, 2, 33, 29, 364, 923, 3879],\n",
       " [1607, 163, 1715, 1, 1307],\n",
       " [60, 93, 3, 38, 1412, 38, 3895, 6, 38, 2743, 338, 237, 3, 699, 17],\n",
       " [278, 4444, 9, 4445, 2, 407, 1, 279, 2, 798, 4446],\n",
       " [212,\n",
       "  1591,\n",
       "  3,\n",
       "  1,\n",
       "  1055,\n",
       "  2075,\n",
       "  4,\n",
       "  4702,\n",
       "  1592,\n",
       "  2,\n",
       "  4703,\n",
       "  198,\n",
       "  55,\n",
       "  3,\n",
       "  2944,\n",
       "  2,\n",
       "  1056,\n",
       "  1056],\n",
       " [1880, 756, 471, 3, 1187, 1, 2552, 782, 75, 2, 33, 125, 3, 16, 2553, 2554],\n",
       " [734, 191, 2, 3800, 8, 1874, 1875, 144, 75, 25, 3801, 3, 203, 2, 121, 871],\n",
       " [29,\n",
       "  58,\n",
       "  1157,\n",
       "  658,\n",
       "  58,\n",
       "  22,\n",
       "  39,\n",
       "  148,\n",
       "  134,\n",
       "  253,\n",
       "  567,\n",
       "  441,\n",
       "  283,\n",
       "  1007,\n",
       "  49,\n",
       "  6,\n",
       "  151,\n",
       "  58,\n",
       "  553,\n",
       "  80,\n",
       "  1219,\n",
       "  4197],\n",
       " [158, 3719, 8, 166, 680, 1, 1, 3026, 2, 39],\n",
       " [68, 54, 1, 4613, 2, 704, 6, 815, 1, 1263],\n",
       " [1121, 2, 202, 753, 9, 1, 388, 543],\n",
       " [26, 487, 2, 2137, 3, 2138, 3023, 2, 5, 1079],\n",
       " [915, 168, 83, 828, 2154, 1317, 260, 1, 359],\n",
       " [2, 113, 1, 7, 60, 1, 1096, 1474, 1, 191, 5, 34, 753],\n",
       " [42, 1964, 11, 2, 135, 61, 4, 655, 4061],\n",
       " [246, 1445, 3808, 2, 3809, 4, 196, 3, 2, 407],\n",
       " [4, 33, 1091, 217, 4, 15, 32, 6, 1899, 1450, 1, 5, 1434],\n",
       " [176, 1, 207, 1010, 4, 96, 369, 2, 207, 282, 95, 290],\n",
       " [12, 8, 3879, 6, 2473, 3, 16, 4, 1848, 3, 853],\n",
       " [438, 12, 2, 943, 6, 445, 961, 2, 3896, 1067, 1, 563],\n",
       " [1831, 320, 4, 5, 3241, 1, 577, 13, 1, 140, 3, 1274, 71, 782, 17, 47],\n",
       " [436, 3, 4014, 8, 970, 337, 2, 777, 4384, 6, 3973],\n",
       " [5, 1887, 3943, 3, 772, 3944, 146, 4, 7, 94, 2091, 117, 41, 147, 4, 57, 930],\n",
       " [775, 10, 1, 51, 1406, 596, 3948, 1767, 1],\n",
       " [1728, 709, 1, 5, 3312, 896, 393, 1736, 41, 38, 1, 1737, 1, 1738],\n",
       " [3146,\n",
       "  206,\n",
       "  4032,\n",
       "  29,\n",
       "  441,\n",
       "  897,\n",
       "  283,\n",
       "  778,\n",
       "  495,\n",
       "  4336,\n",
       "  58,\n",
       "  70,\n",
       "  429,\n",
       "  49,\n",
       "  778,\n",
       "  225,\n",
       "  4263,\n",
       "  779,\n",
       "  3258,\n",
       "  22,\n",
       "  2566,\n",
       "  1020,\n",
       "  1007,\n",
       "  4021,\n",
       "  511,\n",
       "  22,\n",
       "  293,\n",
       "  1356,\n",
       "  49,\n",
       "  273,\n",
       "  91,\n",
       "  225],\n",
       " [186, 711, 3391, 3],\n",
       " [51,\n",
       "  155,\n",
       "  2218,\n",
       "  3,\n",
       "  3640,\n",
       "  4,\n",
       "  5,\n",
       "  65,\n",
       "  229,\n",
       "  3640,\n",
       "  23,\n",
       "  1,\n",
       "  1314,\n",
       "  2144,\n",
       "  198,\n",
       "  2145,\n",
       "  2425],\n",
       " [1151, 117, 2, 48, 47, 48, 2, 3744, 1, 849, 2, 142, 2, 34],\n",
       " [38, 1065, 199, 1, 600, 89, 926, 302, 4766, 1603],\n",
       " [271, 272, 4, 570, 1, 172, 573, 3, 2434],\n",
       " [28, 227, 937, 17, 46, 1, 37, 185, 1373, 44, 243],\n",
       " [25,\n",
       "  240,\n",
       "  3515,\n",
       "  1,\n",
       "  530,\n",
       "  2,\n",
       "  1981,\n",
       "  1981,\n",
       "  638,\n",
       "  317,\n",
       "  6,\n",
       "  2756,\n",
       "  2,\n",
       "  135,\n",
       "  789,\n",
       "  6,\n",
       "  392],\n",
       " [130, 1, 188, 1, 990, 86, 1, 865, 792, 455, 935],\n",
       " [120, 76, 1213, 3, 127, 11, 2733, 2, 1826, 4, 15, 5, 1512],\n",
       " [556, 4226, 196, 3, 196, 117, 46, 64, 4, 191, 80, 4099, 500, 117, 82],\n",
       " [533, 184, 376, 3, 38, 1, 526, 1, 19, 300, 145, 6, 170, 141, 17],\n",
       " [93, 3, 6, 2020, 1, 1096, 11, 4122, 1857, 2, 4123, 113],\n",
       " [60, 1095, 3, 2, 652, 4, 377, 131, 237, 1, 114],\n",
       " [35, 2, 62, 3, 289, 1, 72, 63, 83, 104, 3],\n",
       " [1889, 11, 2, 759, 665, 290, 1221, 1805, 2, 5, 1890, 59],\n",
       " [33, 1459, 1125, 980, 1510, 43, 35, 7],\n",
       " [2807,\n",
       "  2808,\n",
       "  2779,\n",
       "  30,\n",
       "  2,\n",
       "  353,\n",
       "  838,\n",
       "  1,\n",
       "  7,\n",
       "  2485,\n",
       "  11,\n",
       "  4169,\n",
       "  449,\n",
       "  449,\n",
       "  4,\n",
       "  5,\n",
       "  856,\n",
       "  1890],\n",
       " [518, 28, 10, 353, 424, 1, 766, 420, 851, 1, 960, 1782, 1331, 3, 1, 766, 958],\n",
       " [1764, 2, 1, 251, 241, 250],\n",
       " [4, 1181, 463, 1933, 147, 4, 177, 82, 19, 4239, 1871],\n",
       " [92, 50, 2, 1, 3433, 496, 2, 37],\n",
       " [33, 662, 101, 41, 1516, 3, 261, 16, 1192, 1, 2, 656],\n",
       " [310, 1373, 2, 2932, 80, 695, 8, 714, 2, 188, 19, 300, 145],\n",
       " [48, 79, 2780, 2, 325, 2, 7, 36],\n",
       " [197, 3, 2582, 270, 4, 239, 2, 1, 2416, 1],\n",
       " [27, 304, 726, 2101, 24, 867, 1],\n",
       " [383, 920, 4, 1041, 3, 1268, 2, 225, 4696, 4, 5, 2072, 429, 2939, 4697],\n",
       " [1349, 4, 911, 2, 724, 1037, 6, 3319, 1, 715],\n",
       " [122, 54, 1, 1284, 28, 106, 1, 1751, 1673],\n",
       " [614, 1587, 3, 4, 1588, 3, 802, 4685, 4686],\n",
       " [52, 4229, 2, 5, 3873, 2641, 2, 104, 739, 248, 4205, 43, 1, 32],\n",
       " [122, 31, 3, 94, 54, 11, 2, 1323, 1, 1035],\n",
       " [281, 1902, 195, 49, 609, 786, 4302, 4135, 1911, 1921, 4303, 2792, 2792],\n",
       " [89, 1648, 11, 1, 2319, 2079, 60, 30, 106],\n",
       " [1533, 353, 2920, 353, 1577, 2921, 3, 1, 186, 711],\n",
       " [3534, 2034, 2, 390, 356, 99, 3031, 4, 1335, 1280, 1, 636, 223],\n",
       " [1942,\n",
       "  52,\n",
       "  24,\n",
       "  314,\n",
       "  2,\n",
       "  7,\n",
       "  821,\n",
       "  6,\n",
       "  407,\n",
       "  1,\n",
       "  7,\n",
       "  1209,\n",
       "  215,\n",
       "  2669,\n",
       "  1013,\n",
       "  1,\n",
       "  142,\n",
       "  2,\n",
       "  34],\n",
       " [5, 374, 141, 141, 4, 927, 1297, 1, 327, 282, 368],\n",
       " [65, 1, 256, 305, 2, 566, 415, 11, 575, 1, 7, 2557, 2669],\n",
       " [5, 155, 4733, 1, 7, 1532, 3, 4734, 4735, 1, 2092, 19, 300, 4736],\n",
       " [317, 1908, 2, 7, 84, 28, 4, 160, 1, 248, 3821, 131],\n",
       " [181, 1390, 1, 1787, 193, 4, 3, 2399, 764, 72, 63],\n",
       " [205,\n",
       "  1800,\n",
       "  2436,\n",
       "  3543,\n",
       "  13,\n",
       "  1,\n",
       "  15,\n",
       "  954,\n",
       "  855,\n",
       "  760,\n",
       "  627,\n",
       "  10,\n",
       "  285,\n",
       "  335,\n",
       "  70,\n",
       "  2379,\n",
       "  425,\n",
       "  91,\n",
       "  502,\n",
       "  49,\n",
       "  363,\n",
       "  2437,\n",
       "  148,\n",
       "  134,\n",
       "  70,\n",
       "  1582],\n",
       " [2624, 441, 386, 273, 58, 425, 285, 58, 375, 233, 4, 5, 1, 32],\n",
       " [5, 1477, 5, 196, 3, 2743, 4, 513],\n",
       " [4008, 444, 60, 1, 4009, 3, 4010, 3807, 1, 141],\n",
       " [52, 1057, 1, 2083, 1, 491, 58, 809, 1, 2948, 4717, 106, 1, 114],\n",
       " [36, 671, 20, 1906, 2, 334, 367, 2, 647, 109, 601],\n",
       " [644, 1652, 396, 2, 1029, 8, 332, 333, 3, 2253, 1],\n",
       " [3643, 31, 3, 137, 983, 90, 3950, 2, 2303, 78, 266, 182, 4, 12, 3, 83, 296],\n",
       " [25, 61, 106, 20, 1517, 2, 179, 331, 193, 211, 2, 302, 30, 1, 114],\n",
       " [3411, 85, 46, 64, 4233, 1536, 3, 2304, 82, 1, 5, 94, 2653, 2, 322, 2598],\n",
       " [2009, 2855, 2856, 4522, 1, 141, 236, 133, 1, 202],\n",
       " [336, 387, 1067, 823, 20, 2982, 2, 4784, 201, 21, 201, 902],\n",
       " [195,\n",
       "  1,\n",
       "  686,\n",
       "  81,\n",
       "  4203,\n",
       "  881,\n",
       "  1139,\n",
       "  81,\n",
       "  1967,\n",
       "  21,\n",
       "  4246,\n",
       "  605,\n",
       "  81,\n",
       "  881,\n",
       "  134,\n",
       "  1260,\n",
       "  285,\n",
       "  21,\n",
       "  4240,\n",
       "  199,\n",
       "  4247],\n",
       " [228, 138, 111, 3, 1032, 2164, 1],\n",
       " [1019, 3, 215, 109, 93, 606, 2, 1, 731, 13, 1, 888, 3, 873, 6],\n",
       " [26, 3775, 2, 7, 136, 6, 2, 15, 345, 967, 6, 1695, 2, 5, 34],\n",
       " [2235, 221, 1, 359, 3, 393, 1, 50, 2440, 1, 187],\n",
       " [123, 112, 2459, 3, 4201, 772, 10, 125, 149, 4202, 3, 5, 848, 2, 36],\n",
       " [183, 42, 4001, 383, 11, 4, 60, 782],\n",
       " [1038, 305, 2, 179, 1814, 193, 306, 1, 190, 55, 1374],\n",
       " [241,\n",
       "  2683,\n",
       "  1951,\n",
       "  6,\n",
       "  1212,\n",
       "  2766,\n",
       "  2474,\n",
       "  3,\n",
       "  1212,\n",
       "  14,\n",
       "  3,\n",
       "  270,\n",
       "  1490,\n",
       "  4,\n",
       "  788,\n",
       "  561],\n",
       " [1703, 8, 145, 352, 19, 241],\n",
       " [901, 2, 201, 1535, 14, 3, 4516, 1, 152, 4517, 1, 5, 682, 4518],\n",
       " [36, 4012, 6, 765, 2, 13, 1, 15, 66, 1002, 1, 120, 1, 132],\n",
       " [2946, 3, 2079, 2080, 1, 4707, 2947, 2, 4708, 44, 614],\n",
       " [249, 3135, 593, 841, 3523, 1, 5, 1033],\n",
       " [417, 1668, 4, 1043, 2, 608, 1543, 2861, 1, 228, 138, 1410, 13, 1, 453, 725],\n",
       " [194, 3, 10, 55, 3, 12, 24, 136, 13, 507, 6, 2652, 1, 141, 2, 234],\n",
       " [2710, 2711, 1747, 16, 3, 3, 18, 882, 3, 4, 5, 678, 1143, 59],\n",
       " [1793, 1334, 4, 1820, 1431, 1601, 3606, 1, 260, 1, 3607],\n",
       " [1277, 56, 133, 1, 2927, 289, 813, 3, 46],\n",
       " [12, 2, 2530, 372, 35, 271, 272, 1, 1488, 4033],\n",
       " [2681,\n",
       "  4107,\n",
       "  1842,\n",
       "  1471,\n",
       "  10,\n",
       "  804,\n",
       "  3,\n",
       "  268,\n",
       "  9,\n",
       "  1,\n",
       "  5,\n",
       "  4108,\n",
       "  344,\n",
       "  38,\n",
       "  399,\n",
       "  3,\n",
       "  1019],\n",
       " [742, 2, 2462, 6, 1, 1818, 112, 6, 4, 2, 131, 1, 988],\n",
       " [147, 4, 295, 3, 177, 6, 123, 1, 140, 3, 71, 4037, 3, 47],\n",
       " [3596, 2460, 1, 2117, 2461, 56, 498, 46],\n",
       " [214, 4, 5, 60, 66, 297, 2, 32, 8, 1770, 612, 23, 82, 156, 43],\n",
       " [731, 1621, 845, 30, 2, 2373, 1, 2188, 2189],\n",
       " [23, 1, 89, 37, 1, 1101, 1342, 20, 944, 1, 262],\n",
       " [165, 2, 7, 3, 2616, 3904, 317, 686, 11, 2733, 2, 339, 4, 1182, 216],\n",
       " [195, 479, 1137, 11, 1, 7, 2, 1903, 1980],\n",
       " [368, 213, 27, 312, 4, 3468, 2395],\n",
       " [36, 6, 874, 1, 211, 2, 1914, 3, 1177, 23, 1, 2684, 1193, 1193],\n",
       " [452, 2, 50, 367, 2, 522, 2, 5, 1835, 3118, 6, 835, 291, 1, 245],\n",
       " [186, 1989, 1224, 56, 2825, 349, 198, 40, 799, 1, 297, 2, 1225, 280],\n",
       " [3347, 2643, 471, 3, 1187, 1, 2552, 2952, 30, 16, 595, 220, 2, 141],\n",
       " [155,\n",
       "  221,\n",
       "  1,\n",
       "  707,\n",
       "  3,\n",
       "  1268,\n",
       "  2,\n",
       "  1565,\n",
       "  4631,\n",
       "  4,\n",
       "  5,\n",
       "  303,\n",
       "  1,\n",
       "  2052,\n",
       "  1,\n",
       "  57,\n",
       "  4632,\n",
       "  4633],\n",
       " [900, 1379, 496, 489, 8, 220, 772, 4, 427, 427],\n",
       " [807, 1, 7, 42, 1825, 4310, 589, 95, 233],\n",
       " [698, 553, 1690, 1373, 9, 1, 553, 960, 653, 1128],\n",
       " [179, 1571, 222, 3, 1103, 1, 840, 3158, 6, 3],\n",
       " [433, 452, 8, 3078, 1, 2392, 2960, 17, 46, 185, 288, 3, 3466],\n",
       " [3177, 682, 207, 9, 1, 5, 1079, 3255, 3, 357],\n",
       " [98, 323, 2, 69, 19, 92, 1, 1027, 4464, 2, 51, 374],\n",
       " [51, 1337, 1, 3447, 4, 493, 6, 4401, 99, 4406, 4, 2594, 2, 57, 5, 65],\n",
       " [312, 105, 2, 2663, 16, 3626, 3627, 79, 1, 199, 1250],\n",
       " [4095,\n",
       "  1380,\n",
       "  281,\n",
       "  2093,\n",
       "  11,\n",
       "  2581,\n",
       "  944,\n",
       "  4,\n",
       "  7,\n",
       "  480,\n",
       "  1,\n",
       "  859,\n",
       "  108,\n",
       "  14,\n",
       "  1917,\n",
       "  2591],\n",
       " [1188, 1882, 783, 4, 819, 1426, 1052, 17, 35, 1845, 199, 1, 2606, 39],\n",
       " [1129, 3293, 2, 2303, 122, 449, 9, 1724, 4, 104, 78, 303, 3, 14, 3294],\n",
       " [2332, 2, 72, 63, 1, 39, 83, 1257, 3, 260, 1, 181],\n",
       " [104, 129, 341, 3, 48, 38, 949, 6, 1004, 99, 1382, 1, 84],\n",
       " [20, 13, 1, 7, 94, 1376, 1, 2],\n",
       " [4, 175, 4, 1962, 1327, 1, 39],\n",
       " [7, 1883, 2666, 2, 135, 67, 1, 566, 966, 476, 276],\n",
       " [991, 1, 4012, 3, 294, 10, 2788, 1476, 6, 4121, 16, 1015, 75, 17, 4, 3751],\n",
       " [702, 481, 1, 37, 460, 3500, 738],\n",
       " [1201, 1982, 7, 679, 104, 10, 398, 3, 2, 135, 842],\n",
       " [50, 367, 2, 5, 740, 1851, 2, 7, 36, 6, 41, 419, 47, 930],\n",
       " [5,\n",
       "  825,\n",
       "  2140,\n",
       "  3,\n",
       "  14,\n",
       "  4922,\n",
       "  1,\n",
       "  5,\n",
       "  620,\n",
       "  1,\n",
       "  77,\n",
       "  2,\n",
       "  390,\n",
       "  45,\n",
       "  44,\n",
       "  3061,\n",
       "  2,\n",
       "  4923,\n",
       "  1,\n",
       "  4924],\n",
       " [277, 2746, 2, 627, 3, 10, 127, 4072, 554, 3, 3595],\n",
       " [12, 8, 210, 163, 184, 2177, 2, 2835, 2836, 1, 520, 200, 2837],\n",
       " [468, 672, 547, 1, 2, 231, 1, 659, 126, 8, 1198, 1952, 1109],\n",
       " [450, 3632, 1, 152, 54, 11, 1232, 2, 3455],\n",
       " ...]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2761, 100)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_model = Word2Vec.load('word2vec/word2vec_300dim_20epochs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33542043, -1.6471791 ,  0.82437915,  0.34260795,  0.5697868 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv['lalaki'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(model, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, index in word_index.items():\n",
    "        if word in model.wv.key_to_index:\n",
    "            embedding_matrix[index] = model.wv[word][:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    word2vec_model,\n",
    "    tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10714, 300)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8388090349075975"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
    "nonzero_elements / vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 300)          3214200   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 94, 128)           268928    \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,486,249\n",
      "Trainable params: 3,486,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=True))\n",
    "model.add(layers.Conv1D(128, 7, activation='tanh'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(24, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "173/173 [==============================] - 3s 16ms/step - loss: 0.3659 - accuracy: 0.8345 - val_loss: 0.2530 - val_accuracy: 0.9001\n",
      "Epoch 2/50\n",
      "173/173 [==============================] - 2s 14ms/step - loss: 0.1154 - accuracy: 0.9573 - val_loss: 0.2566 - val_accuracy: 0.9016\n",
      "Epoch 3/50\n",
      "173/173 [==============================] - 2s 14ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.2683 - val_accuracy: 0.9175\n",
      "Epoch 4/50\n",
      "173/173 [==============================] - 2s 14ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.3397 - val_accuracy: 0.9088\n",
      "Epoch 5/50\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 8.0659e-04 - accuracy: 0.9996 - val_loss: 0.4061 - val_accuracy: 0.9146\n",
      "Epoch 6/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 1.1954e-05 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.9146\n",
      "Epoch 7/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 4.0739e-07 - accuracy: 1.0000 - val_loss: 0.7366 - val_accuracy: 0.9132\n",
      "Epoch 8/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 4.9629e-08 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.9117\n",
      "Epoch 9/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 2.1579e-08 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.9117\n",
      "Epoch 10/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 1.4538e-08 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.9074\n",
      "Epoch 11/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 1.1129e-08 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.9074\n",
      "Epoch 12/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 9.0477e-09 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 7.6557e-09 - accuracy: 1.0000 - val_loss: 0.8594 - val_accuracy: 0.9059\n",
      "Epoch 14/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 6.6594e-09 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.9059\n",
      "Epoch 15/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 5.8993e-09 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.9074\n",
      "Epoch 16/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 5.3147e-09 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.9074\n",
      "Epoch 17/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 4.8344e-09 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.9059\n",
      "Epoch 18/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 4.4374e-09 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.9088\n",
      "Epoch 19/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 4.1102e-09 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.9088\n",
      "Epoch 20/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 3.8257e-09 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.9088\n",
      "Epoch 21/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 3.5776e-09 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.9088\n",
      "Epoch 22/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 3.3665e-09 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.9088\n",
      "Epoch 23/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 3.1812e-09 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9088\n",
      "Epoch 24/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 3.0146e-09 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.9088\n",
      "Epoch 25/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.8686e-09 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.9088\n",
      "Epoch 26/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.7355e-09 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.9074\n",
      "Epoch 27/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.6138e-09 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.9074\n",
      "Epoch 28/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.5006e-09 - accuracy: 1.0000 - val_loss: 0.9194 - val_accuracy: 0.9074\n",
      "Epoch 29/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.4000e-09 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.9074\n",
      "Epoch 30/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.3038e-09 - accuracy: 1.0000 - val_loss: 0.9240 - val_accuracy: 0.9074\n",
      "Epoch 31/50\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 2.2191e-09 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.9074\n",
      "Epoch 32/50\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 2.1411e-09 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.9074\n",
      "Epoch 33/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 2.0721e-09 - accuracy: 1.0000 - val_loss: 0.9308 - val_accuracy: 0.9074\n",
      "Epoch 34/50\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 2.0081e-09 - accuracy: 1.0000 - val_loss: 0.9331 - val_accuracy: 0.9088\n",
      "Epoch 35/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.9485e-09 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.9088\n",
      "Epoch 36/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.8931e-09 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.9088\n",
      "Epoch 37/50\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 1.8408e-09 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.9088\n",
      "Epoch 38/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.7922e-09 - accuracy: 1.0000 - val_loss: 0.9417 - val_accuracy: 0.9103\n",
      "Epoch 39/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.7460e-09 - accuracy: 1.0000 - val_loss: 0.9437 - val_accuracy: 0.9103\n",
      "Epoch 40/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.7021e-09 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.9103\n",
      "Epoch 41/50\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 1.6612e-09 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.9103\n",
      "Epoch 42/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.6219e-09 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.5853e-09 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.9088\n",
      "Epoch 44/50\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 1.5501e-09 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.9088\n",
      "Epoch 45/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.5167e-09 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.9088\n",
      "Epoch 46/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.4852e-09 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.9088\n",
      "Epoch 47/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.4551e-09 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9088\n",
      "Epoch 48/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.4263e-09 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9074\n",
      "Epoch 49/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.3992e-09 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.9074\n",
      "Epoch 50/50\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 1.3725e-09 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.9074\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9074\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# STAMP = f'CNN_Glove_Vectors'\n",
    "# early_stopping =EarlyStopping(monitor='val_loss', patience=5)\n",
    "# bst_model_path = STAMP + '.h5'\n",
    "# model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "#, callbacks=[early_stopping, model_checkpoint]\n",
    "\n",
    "#model.load_weights(bst_model_path)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 300)          3214200   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,404,201\n",
      "Trainable params: 3,404,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_model = Sequential()\n",
    "RNN_model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "RNN_model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "RNN_model.add(layers.Dense(24, activation='relu'))\n",
    "RNN_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "RNN_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "RNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "87/87 [==============================] - 6s 30ms/step - loss: 0.3845 - accuracy: 0.8156 - val_loss: 0.2659 - val_accuracy: 0.8871\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.1245 - accuracy: 0.9565 - val_loss: 0.2286 - val_accuracy: 0.9190\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.2258 - val_accuracy: 0.9190\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.0360 - accuracy: 0.9899 - val_loss: 0.4316 - val_accuracy: 0.8857\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.3311 - val_accuracy: 0.9161\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.3773 - val_accuracy: 0.91320096 - \n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.4113 - val_accuracy: 0.9247\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4951 - val_accuracy: 0.9161\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 8.5394e-04 - accuracy: 0.9996 - val_loss: 0.6092 - val_accuracy: 0.9117\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.1918e-05 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.9146\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.7868e-04 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.9161\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.5574e-07 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.9132\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.8854 - val_accuracy: 0.9103\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 9.8411e-08 - accuracy: 1.0000 - val_loss: 0.8877 - val_accuracy: 0.9103\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 5.4797e-08 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.9103\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.5955e-08 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.9161\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.9447e-09 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.9175\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.6734e-09 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.9161\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.7245e-09 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.9146\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.3055e-09 - accuracy: 1.0000 - val_loss: 1.0351 - val_accuracy: 0.9161\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.0363e-09 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.9161\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 8.7398e-10 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.9161\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 7.4296e-10 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.9161\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 6.3552e-10 - accuracy: 1.0000 - val_loss: 1.0775 - val_accuracy: 0.9146\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.9361e-10 - accuracy: 1.0000 - val_loss: 1.0710 - val_accuracy: 0.9146\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 5.2610e-10 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9146\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 4.7863e-10 - accuracy: 1.0000 - val_loss: 1.0866 - val_accuracy: 0.9146\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 4.4560e-10 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.9132\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 4.1310e-10 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.9146\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 2s 24ms/step - loss: 3.8877e-10 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9132\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 3.6516e-10 - accuracy: 1.0000 - val_loss: 1.0961 - val_accuracy: 0.9132\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.4691e-10 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.9117\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.2686e-10 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.9117\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 3.1054e-10 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.9117\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.9970e-10 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.9117\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.8241e-10 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.9132\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.6828e-10 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.9117\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.5586e-10 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.9117\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.4897e-10 - accuracy: 1.0000 - val_loss: 1.1107 - val_accuracy: 0.9117\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.4160e-10 - accuracy: 1.0000 - val_loss: 1.1122 - val_accuracy: 0.9117\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.3337e-10 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.9117\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.2511e-10 - accuracy: 1.0000 - val_loss: 1.1105 - val_accuracy: 0.9117\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.1873e-10 - accuracy: 1.0000 - val_loss: 1.1202 - val_accuracy: 0.9132\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.1646e-10 - accuracy: 1.0000 - val_loss: 1.1231 - val_accuracy: 0.9146\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.1546e-10 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.9146\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.0910e-10 - accuracy: 1.0000 - val_loss: 1.1223 - val_accuracy: 0.9132\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 2.0340e-10 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9146\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 2.0559e-10 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.9132\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 2s 18ms/step - loss: 1.9551e-10 - accuracy: 1.0000 - val_loss: 1.1240 - val_accuracy: 0.9132\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 2s 19ms/step - loss: 1.9184e-10 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.9132\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9132\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = RNN_model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32)\n",
    "\n",
    "\n",
    "loss, accuracy = RNN_model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = RNN_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_CNNModel(hl, ol, act, num_filter, kernel_size):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "    model.add(layers.Conv1D(num_filter, kernel_size, activation=hl))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(24, activation=hl))\n",
    "    model.add(layers.Dense(1, activation=ol))\n",
    "    model.compile(optimizer=act,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.502170741558075\n",
      "model 2/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.502170741558075\n",
      "model 3/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.5166425704956055\n",
      "model 4/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 5/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.502170741558075\n",
      "model 6/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.6685962080955505\n",
      "model 7/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 8/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 9/1125 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 10/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 11/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 12/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 13/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 14/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 15/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 16/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.8929088115692139\n",
      "model 17/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 18/1125 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 19/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 20/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 21/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.916063666343689\n",
      "model 22/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 23/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 24/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 25/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 26/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 27/1125 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 28/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 29/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 30/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.49927639961242676\n",
      "model 31/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 32/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 33/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 34/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 35/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.4920405149459839\n",
      "model 36/1125 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 37/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.8784370422363281\n",
      "model 38/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 39/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 40/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 41/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9146165251731873\n",
      "model 42/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 43/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 44/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 45/1125 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 46/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 47/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 48/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.502170741558075\n",
      "model 49/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 50/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 51/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.502170741558075\n",
      "model 52/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 53/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 54/1125 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 55/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.8755427002906799\n",
      "model 56/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 57/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 58/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 59/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 60/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.8523878455162048\n",
      "model 61/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.8494935035705566\n",
      "model 62/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 63/1125 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.8480463027954102\n",
      "model 64/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 65/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 66/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 67/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.8740954995155334\n",
      "model 68/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 69/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.8726483583450317\n",
      "model 70/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 71/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 72/1125 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.8784370422363281\n",
      "model 73/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.5123010277748108\n",
      "model 74/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 75/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.5007236003875732\n",
      "model 76/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.5325614809989929\n",
      "model 77/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 78/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 79/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 80/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.5007236003875732\n",
      "model 81/1125 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 82/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8813313841819763\n",
      "model 83/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 84/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 85/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 86/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 87/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 88/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8827785849571228\n",
      "model 89/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 90/1125 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 91/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 92/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 93/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 94/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 95/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 96/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 97/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 98/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 99/1125 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 100/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 101/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 102/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 103/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 104/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 105/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 106/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 107/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 108/1125 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 109/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 110/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 111/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 112/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.502170741558075\n",
      "model 113/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 114/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 115/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 116/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 117/1125 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 118/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 119/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 120/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.555716335773468\n",
      "model 121/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.5036179423332214\n",
      "model 122/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 123/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 124/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.558610737323761\n",
      "model 125/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 126/1125 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.5571635365486145\n",
      "model 127/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 128/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 129/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 130/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.8827785849571228\n",
      "model 131/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 132/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 133/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 134/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 135/1125 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 136/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 137/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 138/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 139/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 140/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 141/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 142/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 143/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 144/1125 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.5383502244949341\n",
      "model 145/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 146/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 147/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 148/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 149/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 150/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.502170741558075\n",
      "model 151/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 152/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 153/1125 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 154/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 155/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 156/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 157/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 158/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 159/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 160/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 161/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 162/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 163/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.5354558825492859\n",
      "model 164/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 165/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.6468885540962219\n",
      "model 166/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 167/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 168/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.589001476764679\n",
      "model 169/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 170/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 171/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.6005788445472717\n",
      "model 172/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 173/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 174/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.502170741558075\n",
      "model 175/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 176/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 177/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.9146165251731873\n",
      "model 178/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 179/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 180/1125 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.502170741558075\n",
      "model 181/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 182/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 183/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 184/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 185/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 186/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 187/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 188/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 189/1125 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 190/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.8900144696235657\n",
      "model 191/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 192/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 193/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 194/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 195/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 196/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 197/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 198/1125 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 199/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 200/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 201/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 202/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 203/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 204/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 205/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 206/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 207/1125 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 208/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 209/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.5759768486022949\n",
      "model 210/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.5036179423332214\n",
      "model 211/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 212/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 213/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 214/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 215/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 216/1125 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 217/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 218/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 219/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 220/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 221/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 222/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 223/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 224/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 225/1125 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 226/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7018813490867615\n",
      "model 227/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.740955114364624\n",
      "model 228/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7424023151397705\n",
      "model 229/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7525325417518616\n",
      "model 230/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7626628279685974\n",
      "model 231/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7626628279685974\n",
      "model 232/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7452966570854187\n",
      "model 233/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7698987126350403\n",
      "model 234/1125 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7655571699142456\n",
      "model 235/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9131693243980408\n",
      "model 236/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 237/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9146165251731873\n",
      "model 238/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 239/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 240/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9175108671188354\n",
      "model 241/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 242/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9146165251731873\n",
      "model 243/1125 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 244/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 245/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 246/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 247/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 248/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 249/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 250/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 251/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9146165251731873\n",
      "model 252/1125 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 253/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7221418023109436\n",
      "model 254/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7149059176445007\n",
      "model 255/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7163531184196472\n",
      "model 256/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7192474603652954\n",
      "model 257/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7206946611404419\n",
      "model 258/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7293776869773865\n",
      "model 259/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.710564374923706\n",
      "model 260/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 261/1125 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.730824887752533\n",
      "model 262/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9102749824523926\n",
      "model 263/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 264/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 265/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 266/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 267/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9117221236228943\n",
      "model 268/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 269/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 270/1125 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 271/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.6772792935371399\n",
      "model 272/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.7973950505256653\n",
      "model 273/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8335745334625244\n",
      "model 274/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8523878455162048\n",
      "model 275/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8364688754081726\n",
      "model 276/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8567293882369995\n",
      "model 277/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8364688754081726\n",
      "model 278/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.8422576189041138\n",
      "model 279/1125 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.855282187461853\n",
      "model 280/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.7872648239135742\n",
      "model 281/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.7771345973014832\n",
      "model 282/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.8248914480209351\n",
      "model 283/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.8031837940216064\n",
      "model 284/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.7756873965263367\n",
      "model 285/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.8089724779129028\n",
      "model 286/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.784370481967926\n",
      "model 287/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.7800289392471313\n",
      "model 288/1125 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.7973950505256653\n",
      "model 289/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.8654124736785889\n",
      "model 290/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 291/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.8712011575698853\n",
      "model 292/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.8581765294075012\n",
      "model 293/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 294/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 295/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 296/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.8842257857322693\n",
      "model 297/1125 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 298/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7047756910324097\n",
      "model 299/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7192474603652954\n",
      "model 300/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 301/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7481909990310669\n",
      "model 302/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7366136312484741\n",
      "model 303/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7510854005813599\n",
      "model 304/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7612156271934509\n",
      "model 305/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7337192296981812\n",
      "model 306/1125 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 307/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8610709309577942\n",
      "model 308/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8654124736785889\n",
      "model 309/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 310/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8769898414611816\n",
      "model 311/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.855282187461853\n",
      "model 312/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8639652729034424\n",
      "model 313/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8668596148490906\n",
      "model 314/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8639652729034424\n",
      "model 315/1125 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 316/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 317/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 318/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 319/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 320/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.8494935035705566\n",
      "model 321/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 322/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 323/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 324/1125 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.8596237301826477\n",
      "model 325/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8885672688484192\n",
      "model 326/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 327/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 328/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8900144696235657\n",
      "model 329/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 330/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8929088115692139\n",
      "model 331/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 332/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 333/1125 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 334/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 335/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.898697555065155\n",
      "model 336/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 337/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 338/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 339/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 340/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 341/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 342/1125 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 343/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.6801736354827881\n",
      "model 344/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7641099691390991\n",
      "model 345/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.6758321523666382\n",
      "model 346/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7568740844726562\n",
      "model 347/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 348/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7525325417518616\n",
      "model 349/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7785817384719849\n",
      "model 350/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 351/1125 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7756873965263367\n",
      "model 352/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 353/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 354/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 355/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.885672926902771\n",
      "model 356/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 357/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 358/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 359/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 360/1125 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 361/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 362/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.8422576189041138\n",
      "model 363/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 364/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 365/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 366/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 367/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 368/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.8567293882369995\n",
      "model 369/1125 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.8480463027954102\n",
      "model 370/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 371/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 372/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 373/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 374/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.8929088115692139\n",
      "model 375/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 376/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.8900144696235657\n",
      "model 377/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 378/1125 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 379/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 380/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 381/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 382/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 383/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 384/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 385/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 386/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 387/1125 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 388/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7293776869773865\n",
      "model 389/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.774240255355835\n",
      "model 390/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 391/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7583212852478027\n",
      "model 392/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7916063666343689\n",
      "model 393/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7684515118598938\n",
      "model 394/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.8046309947967529\n",
      "model 395/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7626628279685974\n",
      "model 396/1125 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7641099691390991\n",
      "model 397/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 398/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.885672926902771\n",
      "model 399/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 400/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.8842257857322693\n",
      "model 401/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 402/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 403/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 404/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 405/1125 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 406/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 407/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.8408104181289673\n",
      "model 408/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 409/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 410/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 411/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.8379160761833191\n",
      "model 412/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.8509406447410583\n",
      "model 413/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 414/1125 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 415/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 416/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 417/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 418/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 419/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 420/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 421/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 422/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 423/1125 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 424/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 425/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 426/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 427/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 428/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 429/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 430/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 431/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 432/1125 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 433/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7510854005813599\n",
      "model 434/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7597684264183044\n",
      "model 435/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7626628279685974\n",
      "model 436/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7887120246887207\n",
      "model 437/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 438/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7597684264183044\n",
      "model 439/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7901591658592224\n",
      "model 440/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7684515118598938\n",
      "model 441/1125 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7698987126350403\n",
      "model 442/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 443/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 444/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.8842257857322693\n",
      "model 445/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.8827785849571228\n",
      "model 446/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 447/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 448/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 449/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 450/1125 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 451/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.743849515914917\n",
      "model 452/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7264833450317383\n",
      "model 453/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7395079731941223\n",
      "model 454/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7337192296981812\n",
      "model 455/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.740955114364624\n",
      "model 456/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7467438578605652\n",
      "model 457/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7525325417518616\n",
      "model 458/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.7510854005813599\n",
      "model 459/1125 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.743849515914917\n",
      "model 460/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.8900144696235657\n",
      "model 461/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 462/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 463/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 464/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 465/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 466/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 467/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 468/1125 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 469/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 470/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9204052090644836\n",
      "model 471/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.916063666343689\n",
      "model 472/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 473/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9175108671188354\n",
      "model 474/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 475/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 476/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 477/1125 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 478/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6266281008720398\n",
      "model 479/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.670043408870697\n",
      "model 480/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6671490669250488\n",
      "model 481/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 482/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6888567209243774\n",
      "model 483/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6251809000968933\n",
      "model 484/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.7293776869773865\n",
      "model 485/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.700434148311615\n",
      "model 486/1125 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6439942121505737\n",
      "model 487/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 488/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 489/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 490/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 491/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 492/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 493/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 494/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 495/1125 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 496/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 497/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 498/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 499/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.8321273326873779\n",
      "model 500/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.8104196786880493\n",
      "model 501/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.7916063666343689\n",
      "model 502/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.8364688754081726\n",
      "model 503/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.784370481967926\n",
      "model 504/1125 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.8263386487960815\n",
      "model 505/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.7785817384719849\n",
      "model 506/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.7988422513008118\n",
      "model 507/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8277857899665833\n",
      "model 508/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8089724779129028\n",
      "model 509/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 510/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.6859623789787292\n",
      "model 511/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.7988422513008118\n",
      "model 512/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 513/1125 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8277857899665833\n",
      "model 514/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.845151960849762\n",
      "model 515/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8697539567947388\n",
      "model 516/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8784370422363281\n",
      "model 517/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 518/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.885672926902771\n",
      "model 519/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 520/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 521/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 522/1125 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.8798842430114746\n",
      "model 523/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.6280752420425415\n",
      "model 524/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 525/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7178003191947937\n",
      "model 526/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.700434148311615\n",
      "model 527/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7337192296981812\n",
      "model 528/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7192474603652954\n",
      "model 529/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.740955114364624\n",
      "model 530/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7120115756988525\n",
      "model 531/1125 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7366136312484741\n",
      "model 532/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8610709309577942\n",
      "model 533/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8697539567947388\n",
      "model 534/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8784370422363281\n",
      "model 535/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8567293882369995\n",
      "model 536/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8581765294075012\n",
      "model 537/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8827785849571228\n",
      "model 538/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8726483583450317\n",
      "model 539/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8538350462913513\n",
      "model 540/1125 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8740954995155334\n",
      "model 541/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.8596237301826477\n",
      "model 542/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 543/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.8567293882369995\n",
      "model 544/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 545/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 546/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.8581765294075012\n",
      "model 547/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.8465991020202637\n",
      "model 548/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 549/1125 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 550/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 551/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 552/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 553/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 554/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 555/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 556/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 557/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 558/1125 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 559/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.898697555065155\n",
      "model 560/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 561/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 562/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 563/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 564/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.8813313841819763\n",
      "model 565/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 566/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 567/1125 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 568/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7626628279685974\n",
      "model 569/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 570/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7525325417518616\n",
      "model 571/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 572/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7583212852478027\n",
      "model 573/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7670043706893921\n",
      "model 574/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.784370481967926\n",
      "model 575/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7698987126350403\n",
      "model 576/1125 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7337192296981812\n",
      "model 577/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 578/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 579/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 580/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 581/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 582/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 583/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 584/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 585/1125 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.9102749824523926\n",
      "model 586/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.8625180721282959\n",
      "model 587/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 588/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 589/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.8509406447410583\n",
      "model 590/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 591/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 592/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 593/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 594/1125 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 595/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.885672926902771\n",
      "model 596/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.8755427002906799\n",
      "model 597/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 598/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 599/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 600/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 601/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 602/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 603/1125 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 604/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 605/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 606/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 607/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 608/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 609/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 610/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 611/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 612/1125 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 613/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.629522442817688\n",
      "model 614/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 615/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 616/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 617/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.784370481967926\n",
      "model 618/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7496381998062134\n",
      "model 619/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 620/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7612156271934509\n",
      "model 621/1125 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 622/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 623/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 624/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 625/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 626/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 627/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 628/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 629/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 630/1125 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 631/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 632/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 633/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 634/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 635/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 636/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.8625180721282959\n",
      "model 637/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.8596237301826477\n",
      "model 638/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 639/1125 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.7771345973014832\n",
      "model 640/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 641/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 642/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 643/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 644/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 645/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.8929088115692139\n",
      "model 646/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 647/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 648/1125 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 649/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.8784370422363281\n",
      "model 650/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 651/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 652/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 653/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 654/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 655/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 656/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 657/1125 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 658/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7018813490867615\n",
      "model 659/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 660/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7481909990310669\n",
      "model 661/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 662/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7091172337532043\n",
      "model 663/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 664/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7829232811927795\n",
      "model 665/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7785817384719849\n",
      "model 666/1125 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 667/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 668/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 669/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 670/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 671/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.8740954995155334\n",
      "model 672/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 673/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.885672926902771\n",
      "model 674/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 675/1125 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 676/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7525325417518616\n",
      "model 677/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.730824887752533\n",
      "model 678/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7684515118598938\n",
      "model 679/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7366136312484741\n",
      "model 680/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.743849515914917\n",
      "model 681/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.730824887752533\n",
      "model 682/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7583212852478027\n",
      "model 683/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7554269433021545\n",
      "model 684/1125 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.7366136312484741\n",
      "model 685/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 686/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 687/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 688/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 689/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 690/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 691/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 692/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 693/1125 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 694/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 695/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 696/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 697/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 698/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 699/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 700/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 701/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 702/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 703/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 704/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6584659814834595\n",
      "model 705/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7018813490867615\n",
      "model 706/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 707/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6541244387626648\n",
      "model 708/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6685962080955505\n",
      "model 709/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.740955114364624\n",
      "model 710/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 711/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 712/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 713/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 714/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 715/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 716/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 717/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 718/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 719/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 720/1125 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 721/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8089724779129028\n",
      "model 722/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8162084221839905\n",
      "model 723/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8263386487960815\n",
      "model 724/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8465991020202637\n",
      "model 725/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8437047600746155\n",
      "model 726/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8162084221839905\n",
      "model 727/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.7756873965263367\n",
      "model 728/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8219971060752869\n",
      "model 729/1125 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.8263386487960815\n",
      "model 730/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 731/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.7510854005813599\n",
      "model 732/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.8133140206336975\n",
      "model 733/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.7785817384719849\n",
      "model 734/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.7670043706893921\n",
      "model 735/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.7612156271934509\n",
      "model 736/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.7814761400222778\n",
      "model 737/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 738/1125 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.784370481967926\n",
      "model 739/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8625180721282959\n",
      "model 740/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8842257857322693\n",
      "model 741/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 742/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8740954995155334\n",
      "model 743/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 744/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8697539567947388\n",
      "model 745/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 746/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 747/1125 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 748/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 749/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7091172337532043\n",
      "model 750/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7337192296981812\n",
      "model 751/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7221418023109436\n",
      "model 752/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 753/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.730824887752533\n",
      "model 754/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7670043706893921\n",
      "model 755/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7293776869773865\n",
      "model 756/1125 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7322720885276794\n",
      "model 757/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8755427002906799\n",
      "model 758/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8480463027954102\n",
      "model 759/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8654124736785889\n",
      "model 760/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8712011575698853\n",
      "model 761/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8654124736785889\n",
      "model 762/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8697539567947388\n",
      "model 763/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8567293882369995\n",
      "model 764/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 765/1125 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8683068156242371\n",
      "model 766/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.8668596148490906\n",
      "model 767/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 768/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 769/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 770/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.855282187461853\n",
      "model 771/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 772/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.8668596148490906\n",
      "model 773/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 774/1125 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 775/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 776/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 777/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 778/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.8798842430114746\n",
      "model 779/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 780/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 781/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 782/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 783/1125 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 784/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 785/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 786/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 787/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.8784370422363281\n",
      "model 788/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 789/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.898697555065155\n",
      "model 790/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 791/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 792/1125 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 793/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 794/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 795/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7120115756988525\n",
      "model 796/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7612156271934509\n",
      "model 797/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7496381998062134\n",
      "model 798/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7626628279685974\n",
      "model 799/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7510854005813599\n",
      "model 800/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 801/1125 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 802/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.8871201276779175\n",
      "model 803/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.8842257857322693\n",
      "model 804/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 805/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.7945007085800171\n",
      "model 806/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 807/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 808/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 809/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 810/1125 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 811/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8364688754081726\n",
      "model 812/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 813/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 814/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 815/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 816/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 817/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8668596148490906\n",
      "model 818/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 819/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 820/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 821/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 822/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 823/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 824/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9131693243980408\n",
      "model 825/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8871201276779175\n",
      "model 826/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 827/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 828/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8900144696235657\n",
      "model 829/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 830/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 831/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 832/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 833/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 834/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 835/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 836/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 837/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 838/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7163531184196472\n",
      "model 839/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7452966570854187\n",
      "model 840/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 841/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.774240255355835\n",
      "model 842/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7380607724189758\n",
      "model 843/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 844/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7872648239135742\n",
      "model 845/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7727930545806885\n",
      "model 846/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7452966570854187\n",
      "model 847/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 848/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 849/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 850/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 851/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 852/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 853/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 854/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 855/1125 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 856/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.8581765294075012\n",
      "model 857/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 858/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 859/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 860/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 861/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.8437047600746155\n",
      "model 862/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 863/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 864/1125 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 865/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 866/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 867/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 868/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 869/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 870/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 871/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 872/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 873/1125 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 874/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 875/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 876/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 877/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 878/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 879/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 880/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 881/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 882/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 883/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.616497814655304\n",
      "model 884/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 885/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7163531184196472\n",
      "model 886/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 887/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7496381998062134\n",
      "model 888/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.743849515914917\n",
      "model 889/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 890/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7771345973014832\n",
      "model 891/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7597684264183044\n",
      "model 892/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 893/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 894/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 895/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.8827785849571228\n",
      "model 896/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 897/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 898/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 899/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 900/1125 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 901/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7554269433021545\n",
      "model 902/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7337192296981812\n",
      "model 903/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7351664304733276\n",
      "model 904/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7424023151397705\n",
      "model 905/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7554269433021545\n",
      "model 906/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7510854005813599\n",
      "model 907/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7525325417518616\n",
      "model 908/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7525325417518616\n",
      "model 909/1125 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7351664304733276\n",
      "model 910/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 911/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 912/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 913/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 914/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9146165251731873\n",
      "model 915/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 916/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 917/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 918/1125 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 919/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 920/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.916063666343689\n",
      "model 921/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 922/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 923/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 924/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 925/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 926/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 927/1125 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9146165251731873\n",
      "model 928/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.639652669429779\n",
      "model 929/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.683068037033081\n",
      "model 930/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.5166425704956055\n",
      "model 931/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6917510628700256\n",
      "model 932/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.589001476764679\n",
      "model 933/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7120115756988525\n",
      "model 934/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6570188403129578\n",
      "model 935/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.7091172337532043\n",
      "model 936/1125 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6917510628700256\n",
      "model 937/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 938/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 939/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 940/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 941/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 942/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 943/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 944/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9131693243980408\n",
      "model 945/1125 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 946/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 947/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8393632173538208\n",
      "model 948/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 949/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8379160761833191\n",
      "model 950/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8306801915168762\n",
      "model 951/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8089724779129028\n",
      "model 952/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8408104181289673\n",
      "model 953/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.8437047600746155\n",
      "model 954/1125 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 955/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 956/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8031837940216064\n",
      "model 957/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 958/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.7539797425270081\n",
      "model 959/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 960/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8162084221839905\n",
      "model 961/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.771345853805542\n",
      "model 962/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8162084221839905\n",
      "model 963/1125 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8306801915168762\n",
      "model 964/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8639652729034424\n",
      "model 965/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8523878455162048\n",
      "model 966/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 967/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 968/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 969/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8813313841819763\n",
      "model 970/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 971/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8798842430114746\n",
      "model 972/1125 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.885672926902771\n",
      "model 973/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 974/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7149059176445007\n",
      "model 975/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 976/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 977/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 978/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 979/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7163531184196472\n",
      "model 980/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 981/1125 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 982/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8639652729034424\n",
      "model 983/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8668596148490906\n",
      "model 984/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.855282187461853\n",
      "model 985/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8523878455162048\n",
      "model 986/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8697539567947388\n",
      "model 987/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8784370422363281\n",
      "model 988/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.885672926902771\n",
      "model 989/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 990/1125 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 991/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 992/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.8596237301826477\n",
      "model 993/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.8306801915168762\n",
      "model 994/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 995/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 996/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 997/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 998/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 999/1125 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1000/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.8885672688484192\n",
      "model 1001/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1002/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 1003/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 1004/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 1005/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 1006/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 1007/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.8871201276779175\n",
      "model 1008/1125 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 1009/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.885672926902771\n",
      "model 1010/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 1011/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 1012/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 1013/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 1014/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 1015/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 1016/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 1017/1125 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 1018/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 1019/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 1020/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 1021/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 1022/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 1023/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7612156271934509\n",
      "model 1024/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7583212852478027\n",
      "model 1025/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 1026/1125 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7698987126350403\n",
      "model 1027/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.8798842430114746\n",
      "model 1028/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 1029/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 1030/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 1031/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 1032/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 1033/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 1034/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 1035/1125 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 1036/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8292329907417297\n",
      "model 1037/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8408104181289673\n",
      "model 1038/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 1039/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 1040/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1041/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1042/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8567293882369995\n",
      "model 1043/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.8191027641296387\n",
      "model 1044/1125 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1045/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 1046/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 1047/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 1048/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8958032131195068\n",
      "model 1049/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1050/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1051/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8914616703987122\n",
      "model 1052/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 1053/1125 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 1054/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.885672926902771\n",
      "model 1055/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 1056/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 1057/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 1058/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.8914616703987122\n",
      "model 1059/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 1060/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 1061/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 1062/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 1063/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7670043706893921\n",
      "model 1064/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7033284902572632\n",
      "model 1065/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7366136312484741\n",
      "model 1066/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.774240255355835\n",
      "model 1067/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.774240255355835\n",
      "model 1068/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 1069/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7756873965263367\n",
      "model 1070/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7380607724189758\n",
      "model 1071/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7655571699142456\n",
      "model 1072/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 1073/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 1074/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8813313841819763\n",
      "model 1075/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 1076/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 1077/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 1078/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 1079/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 1080/1125 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.8900144696235657\n",
      "model 1081/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.8523878455162048\n",
      "model 1082/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.8509406447410583\n",
      "model 1083/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.8437047600746155\n",
      "model 1084/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1085/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 1086/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 1087/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 1088/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.8191027641296387\n",
      "model 1089/1125 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 1090/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.8871201276779175\n",
      "model 1091/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 1092/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 1093/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 1094/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1095/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1096/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 1097/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 1098/1125 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 1099/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 1100/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.8871201276779175\n",
      "model 1101/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 1102/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 1103/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 1104/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 1105/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.8827785849571228\n",
      "model 1106/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 1107/1125 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 1108/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.683068037033081\n",
      "model 1109/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7467438578605652\n",
      "model 1110/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7583212852478027\n",
      "model 1111/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7597684264183044\n",
      "model 1112/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 1113/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 1114/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7626628279685974\n",
      "model 1115/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7554269433021545\n",
      "model 1116/1125 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7481909990310669\n",
      "model 1117/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.885672926902771\n",
      "model 1118/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 1119/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 1120/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 1121/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 1122/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 1123/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 1124/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 1125/1125 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.9001446962356567\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hl_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "ol_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "act = ['SGD', 'RMSprop','Adam','Adagrad','Adamax']\n",
    "num_filters = [32, 64, 128]\n",
    "kernel_size = [3, 5, 7]\n",
    "table = defaultdict(list)\n",
    "count = 0\n",
    "for i in hl_f:\n",
    "    for j in ol_f:\n",
    "        for k in act:\n",
    "            for l in num_filters:\n",
    "                for m in kernel_size:\n",
    "\n",
    "                    table['hl_f'].append(i)\n",
    "                    table['ol_f'].append(j)\n",
    "                    table['k_f'].append(k)\n",
    "                    table['n_filters'].append(l)\n",
    "                    table['kernel_size'].append(m)\n",
    "\n",
    "                    \n",
    "\n",
    "                    model = create_CNNModel(i, j, k, l, m)\n",
    "\n",
    "                    history = model.fit(X_train, y_train,\n",
    "                        epochs=20,\n",
    "                        verbose=False,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=32)\n",
    "                    loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "                    table['accuracy'].append(accuracy)\n",
    "                    table['loss'].append(loss)\n",
    "                    count = count + 1\n",
    "                    print(f'model {count}/1125 done, hidden = {i}, output = {j}, optim = {k} || accuracy: {accuracy}')\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    with open('accuracies.txt', 'a') as f:\n",
    "                        f.write('\\n'+str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNNModel(hl, ol, act, lstm_size):\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "    RNN_model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "    RNN_model.add(layers.Dense(lstm_size, activation=hl))\n",
    "    RNN_model.add(layers.Dense(1, activation=ol))\n",
    "    RNN_model.compile(optimizer=act,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return RNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "hl_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "ol_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "act = ['SGD', 'RMSprop','Adam','Adagrad','Adamax']\n",
    "lstm_size = [32, 64, 128]\n",
    "count = 0\n",
    "for i in hl_f:\n",
    "    for j in ol_f:\n",
    "        for k in act:\n",
    "            for l in lstm_size:\n",
    "                count = count+1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1/375 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.5195369124412537\n",
      "model 2/375 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.502170741558075\n",
      "model 3/375 done, hidden = sigmoid, output = sigmoid, optim = SGD || accuracy: 0.502170741558075\n",
      "model 4/375 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 5/375 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.916063666343689\n",
      "model 6/375 done, hidden = sigmoid, output = sigmoid, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 7/375 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 8/375 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 9/375 done, hidden = sigmoid, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 10/375 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.5094066858291626\n",
      "model 11/375 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.502170741558075\n",
      "model 12/375 done, hidden = sigmoid, output = sigmoid, optim = Adagrad || accuracy: 0.49927639961242676\n",
      "model 13/375 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 14/375 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 15/375 done, hidden = sigmoid, output = sigmoid, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 16/375 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 17/375 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.5108538269996643\n",
      "model 18/375 done, hidden = sigmoid, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 19/375 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 20/375 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 21/375 done, hidden = sigmoid, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 22/375 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.8900144696235657\n",
      "model 23/375 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 24/375 done, hidden = sigmoid, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 25/375 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.6816208362579346\n",
      "model 26/375 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.6975398063659668\n",
      "model 27/375 done, hidden = sigmoid, output = tanh, optim = Adagrad || accuracy: 0.6714906096458435\n",
      "model 28/375 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 29/375 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 30/375 done, hidden = sigmoid, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 31/375 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 32/375 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 33/375 done, hidden = sigmoid, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 34/375 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 35/375 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 36/375 done, hidden = sigmoid, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 37/375 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 38/375 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 39/375 done, hidden = sigmoid, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 40/375 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.6685962080955505\n",
      "model 41/375 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.670043408870697\n",
      "model 42/375 done, hidden = sigmoid, output = relu, optim = Adagrad || accuracy: 0.6338639855384827\n",
      "model 43/375 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 44/375 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 45/375 done, hidden = sigmoid, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 46/375 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 47/375 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 48/375 done, hidden = sigmoid, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 49/375 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 50/375 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 51/375 done, hidden = sigmoid, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 52/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 53/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 54/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 55/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 56/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.659913182258606\n",
      "model 57/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adagrad || accuracy: 0.730824887752533\n",
      "model 58/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 59/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 60/375 done, hidden = sigmoid, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 61/375 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 62/375 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 63/375 done, hidden = sigmoid, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 64/375 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 65/375 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.502170741558075\n",
      "model 66/375 done, hidden = sigmoid, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 67/375 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 68/375 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 69/375 done, hidden = sigmoid, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 70/375 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 71/375 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.6989869475364685\n",
      "model 72/375 done, hidden = sigmoid, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 73/375 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 74/375 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 75/375 done, hidden = sigmoid, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 76/375 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.6989869475364685\n",
      "model 77/375 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.7047756910324097\n",
      "model 78/375 done, hidden = tanh, output = sigmoid, optim = SGD || accuracy: 0.6903039216995239\n",
      "model 79/375 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 80/375 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.916063666343689\n",
      "model 81/375 done, hidden = tanh, output = sigmoid, optim = RMSprop || accuracy: 0.9131693243980408\n",
      "model 82/375 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 83/375 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 84/375 done, hidden = tanh, output = sigmoid, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 85/375 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.6917510628700256\n",
      "model 86/375 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.6107091307640076\n",
      "model 87/375 done, hidden = tanh, output = sigmoid, optim = Adagrad || accuracy: 0.5976845026016235\n",
      "model 88/375 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 89/375 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9117221236228943\n",
      "model 90/375 done, hidden = tanh, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 91/375 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 92/375 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.6353111267089844\n",
      "model 93/375 done, hidden = tanh, output = tanh, optim = SGD || accuracy: 0.6613603234291077\n",
      "model 94/375 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.8089724779129028\n",
      "model 95/375 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 96/375 done, hidden = tanh, output = tanh, optim = RMSprop || accuracy: 0.8523878455162048\n",
      "model 97/375 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.9102749824523926\n",
      "model 98/375 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 99/375 done, hidden = tanh, output = tanh, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 100/375 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.740955114364624\n",
      "model 101/375 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7467438578605652\n",
      "model 102/375 done, hidden = tanh, output = tanh, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 103/375 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 104/375 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 105/375 done, hidden = tanh, output = tanh, optim = Adamax || accuracy: 0.8929088115692139\n",
      "model 106/375 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 107/375 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 108/375 done, hidden = tanh, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 109/375 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 110/375 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 111/375 done, hidden = tanh, output = relu, optim = RMSprop || accuracy: 0.8943560123443604\n",
      "model 112/375 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 113/375 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 114/375 done, hidden = tanh, output = relu, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 115/375 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.740955114364624\n",
      "model 116/375 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7322720885276794\n",
      "model 117/375 done, hidden = tanh, output = relu, optim = Adagrad || accuracy: 0.7293776869773865\n",
      "model 118/375 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 119/375 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 120/375 done, hidden = tanh, output = relu, optim = Adamax || accuracy: 0.9117221236228943\n",
      "model 121/375 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 122/375 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 123/375 done, hidden = tanh, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 124/375 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.9131693243980408\n",
      "model 125/375 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 126/375 done, hidden = tanh, output = LeakyReLU, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 127/375 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 128/375 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 129/375 done, hidden = tanh, output = LeakyReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 130/375 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7467438578605652\n",
      "model 131/375 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.7612156271934509\n",
      "model 132/375 done, hidden = tanh, output = LeakyReLU, optim = Adagrad || accuracy: 0.5007236003875732\n",
      "model 133/375 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 134/375 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 135/375 done, hidden = tanh, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 136/375 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 137/375 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 138/375 done, hidden = tanh, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 139/375 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 140/375 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 141/375 done, hidden = tanh, output = PReLU, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 142/375 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 143/375 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 144/375 done, hidden = tanh, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 145/375 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7264833450317383\n",
      "model 146/375 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 147/375 done, hidden = tanh, output = PReLU, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 148/375 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 149/375 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 150/375 done, hidden = tanh, output = PReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 151/375 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.6874095797538757\n",
      "model 152/375 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.6960926055908203\n",
      "model 153/375 done, hidden = relu, output = sigmoid, optim = SGD || accuracy: 0.6960926055908203\n",
      "model 154/375 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9146165251731873\n",
      "model 155/375 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 156/375 done, hidden = relu, output = sigmoid, optim = RMSprop || accuracy: 0.9088277816772461\n",
      "model 157/375 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9175108671188354\n",
      "model 158/375 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 159/375 done, hidden = relu, output = sigmoid, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 160/375 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.616497814655304\n",
      "model 161/375 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.6570188403129578\n",
      "model 162/375 done, hidden = relu, output = sigmoid, optim = Adagrad || accuracy: 0.5933429598808289\n",
      "model 163/375 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 164/375 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 165/375 done, hidden = relu, output = sigmoid, optim = Adamax || accuracy: 0.9131693243980408\n",
      "model 166/375 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.8089724779129028\n",
      "model 167/375 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 168/375 done, hidden = relu, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 169/375 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8465991020202637\n",
      "model 170/375 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8581765294075012\n",
      "model 171/375 done, hidden = relu, output = tanh, optim = RMSprop || accuracy: 0.8437047600746155\n",
      "model 172/375 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 173/375 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 174/375 done, hidden = relu, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 175/375 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.639652669429779\n",
      "model 176/375 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7047756910324097\n",
      "model 177/375 done, hidden = relu, output = tanh, optim = Adagrad || accuracy: 0.7192474603652954\n",
      "model 178/375 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 179/375 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.8914616703987122\n",
      "model 180/375 done, hidden = relu, output = tanh, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 181/375 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 182/375 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 183/375 done, hidden = relu, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 184/375 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 185/375 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 186/375 done, hidden = relu, output = relu, optim = RMSprop || accuracy: 0.9102749824523926\n",
      "model 187/375 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 188/375 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.885672926902771\n",
      "model 189/375 done, hidden = relu, output = relu, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 190/375 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 191/375 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 192/375 done, hidden = relu, output = relu, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 193/375 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.9088277816772461\n",
      "model 194/375 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 195/375 done, hidden = relu, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 196/375 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 197/375 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 198/375 done, hidden = relu, output = LeakyReLU, optim = SGD || accuracy: 0.7814761400222778\n",
      "model 199/375 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 200/375 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 201/375 done, hidden = relu, output = LeakyReLU, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 202/375 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 203/375 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 204/375 done, hidden = relu, output = LeakyReLU, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 205/375 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 206/375 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7206946611404419\n",
      "model 207/375 done, hidden = relu, output = LeakyReLU, optim = Adagrad || accuracy: 0.7539797425270081\n",
      "model 208/375 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 209/375 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 210/375 done, hidden = relu, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 211/375 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 212/375 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 213/375 done, hidden = relu, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 214/375 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 215/375 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 216/375 done, hidden = relu, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 217/375 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 218/375 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.8943560123443604\n",
      "model 219/375 done, hidden = relu, output = PReLU, optim = Adam || accuracy: 0.898697555065155\n",
      "model 220/375 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7221418023109436\n",
      "model 221/375 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 222/375 done, hidden = relu, output = PReLU, optim = Adagrad || accuracy: 0.7279305458068848\n",
      "model 223/375 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.898697555065155\n",
      "model 224/375 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 225/375 done, hidden = relu, output = PReLU, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 226/375 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.6888567209243774\n",
      "model 227/375 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.6903039216995239\n",
      "model 228/375 done, hidden = LeakyReLU, output = sigmoid, optim = SGD || accuracy: 0.6975398063659668\n",
      "model 229/375 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9131693243980408\n",
      "model 230/375 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 231/375 done, hidden = LeakyReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9015918970108032\n",
      "model 232/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.898697555065155\n",
      "model 233/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 234/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 235/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6960926055908203\n",
      "model 236/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.5672937631607056\n",
      "model 237/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6845151782035828\n",
      "model 238/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 239/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 240/375 done, hidden = LeakyReLU, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 241/375 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.7583212852478027\n",
      "model 242/375 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.502170741558075\n",
      "model 243/375 done, hidden = LeakyReLU, output = tanh, optim = SGD || accuracy: 0.502170741558075\n",
      "model 244/375 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 245/375 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 246/375 done, hidden = LeakyReLU, output = tanh, optim = RMSprop || accuracy: 0.8437047600746155\n",
      "model 247/375 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 248/375 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 249/375 done, hidden = LeakyReLU, output = tanh, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 250/375 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 251/375 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7178003191947937\n",
      "model 252/375 done, hidden = LeakyReLU, output = tanh, optim = Adagrad || accuracy: 0.7076700329780579\n",
      "model 253/375 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 254/375 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8958032131195068\n",
      "model 255/375 done, hidden = LeakyReLU, output = tanh, optim = Adamax || accuracy: 0.8972503542900085\n",
      "model 256/375 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 257/375 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 258/375 done, hidden = LeakyReLU, output = relu, optim = SGD || accuracy: 0.502170741558075\n",
      "model 259/375 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 260/375 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 261/375 done, hidden = LeakyReLU, output = relu, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 262/375 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 263/375 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 264/375 done, hidden = LeakyReLU, output = relu, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 265/375 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 266/375 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7424023151397705\n",
      "model 267/375 done, hidden = LeakyReLU, output = relu, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 268/375 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9015918970108032\n",
      "model 269/375 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9102749824523926\n",
      "model 270/375 done, hidden = LeakyReLU, output = relu, optim = Adamax || accuracy: 0.9059334397315979\n",
      "model 271/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 272/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 273/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 274/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 275/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 276/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9044862389564514\n",
      "model 277/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9059334397315979\n",
      "model 278/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 279/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9146165251731873\n",
      "model 280/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7264833450317383\n",
      "model 281/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7149059176445007\n",
      "model 282/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7351664304733276\n",
      "model 283/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 284/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 285/375 done, hidden = LeakyReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 286/375 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 287/375 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.49927639961242676\n",
      "model 288/375 done, hidden = LeakyReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 289/375 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 290/375 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 291/375 done, hidden = LeakyReLU, output = PReLU, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 292/375 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.502170741558075\n",
      "model 293/375 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.9117221236228943\n",
      "model 294/375 done, hidden = LeakyReLU, output = PReLU, optim = Adam || accuracy: 0.9015918970108032\n",
      "model 295/375 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7235890030860901\n",
      "model 296/375 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7206946611404419\n",
      "model 297/375 done, hidden = LeakyReLU, output = PReLU, optim = Adagrad || accuracy: 0.7178003191947937\n",
      "model 298/375 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.9131693243980408\n",
      "model 299/375 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 300/375 done, hidden = LeakyReLU, output = PReLU, optim = Adamax || accuracy: 0.8943560123443604\n",
      "model 301/375 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.6917510628700256\n",
      "model 302/375 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.7178003191947937\n",
      "model 303/375 done, hidden = PReLU, output = sigmoid, optim = SGD || accuracy: 0.6874095797538757\n",
      "model 304/375 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9073805809020996\n",
      "model 305/375 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9175108671188354\n",
      "model 306/375 done, hidden = PReLU, output = sigmoid, optim = RMSprop || accuracy: 0.9117221236228943\n",
      "model 307/375 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 308/375 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 309/375 done, hidden = PReLU, output = sigmoid, optim = Adam || accuracy: 0.9088277816772461\n",
      "model 310/375 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6888567209243774\n",
      "model 311/375 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6382055282592773\n",
      "model 312/375 done, hidden = PReLU, output = sigmoid, optim = Adagrad || accuracy: 0.6497828960418701\n",
      "model 313/375 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 314/375 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 315/375 done, hidden = PReLU, output = sigmoid, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 316/375 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 317/375 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.7916063666343689\n",
      "model 318/375 done, hidden = PReLU, output = tanh, optim = SGD || accuracy: 0.7727930545806885\n",
      "model 319/375 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.80173659324646\n",
      "model 320/375 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8567293882369995\n",
      "model 321/375 done, hidden = PReLU, output = tanh, optim = RMSprop || accuracy: 0.8350217342376709\n",
      "model 322/375 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8885672688484192\n",
      "model 323/375 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 324/375 done, hidden = PReLU, output = tanh, optim = Adam || accuracy: 0.8958032131195068\n",
      "model 325/375 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.713458776473999\n",
      "model 326/375 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.730824887752533\n",
      "model 327/375 done, hidden = PReLU, output = tanh, optim = Adagrad || accuracy: 0.7192474603652954\n",
      "model 328/375 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.8885672688484192\n",
      "model 329/375 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.9001446962356567\n",
      "model 330/375 done, hidden = PReLU, output = tanh, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 331/375 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 332/375 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 333/375 done, hidden = PReLU, output = relu, optim = SGD || accuracy: 0.6975398063659668\n",
      "model 334/375 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9059334397315979\n",
      "model 335/375 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 336/375 done, hidden = PReLU, output = relu, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 337/375 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.9073805809020996\n",
      "model 338/375 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.9044862389564514\n",
      "model 339/375 done, hidden = PReLU, output = relu, optim = Adam || accuracy: 0.9131693243980408\n",
      "model 340/375 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 341/375 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7395079731941223\n",
      "model 342/375 done, hidden = PReLU, output = relu, optim = Adagrad || accuracy: 0.7264833450317383\n",
      "model 343/375 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.49782922863960266\n",
      "model 344/375 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.9102749824523926\n",
      "model 345/375 done, hidden = PReLU, output = relu, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 346/375 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 347/375 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 348/375 done, hidden = PReLU, output = LeakyReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 349/375 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.9001446962356567\n",
      "model 350/375 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8972503542900085\n",
      "model 351/375 done, hidden = PReLU, output = LeakyReLU, optim = RMSprop || accuracy: 0.8871201276779175\n",
      "model 352/375 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.8972503542900085\n",
      "model 353/375 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.8929088115692139\n",
      "model 354/375 done, hidden = PReLU, output = LeakyReLU, optim = Adam || accuracy: 0.9146165251731873\n",
      "model 355/375 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 356/375 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.7206946611404419\n",
      "model 357/375 done, hidden = PReLU, output = LeakyReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 358/375 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 359/375 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9117221236228943\n",
      "model 360/375 done, hidden = PReLU, output = LeakyReLU, optim = Adamax || accuracy: 0.9044862389564514\n",
      "model 361/375 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.49782922863960266\n",
      "model 362/375 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 363/375 done, hidden = PReLU, output = PReLU, optim = SGD || accuracy: 0.502170741558075\n",
      "model 364/375 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.49782922863960266\n",
      "model 365/375 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.898697555065155\n",
      "model 366/375 done, hidden = PReLU, output = PReLU, optim = RMSprop || accuracy: 0.9030390977859497\n",
      "model 367/375 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.9001446962356567\n",
      "model 368/375 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.9030390977859497\n",
      "model 369/375 done, hidden = PReLU, output = PReLU, optim = Adam || accuracy: 0.49782922863960266\n",
      "model 370/375 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.7221418023109436\n",
      "model 371/375 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.49782922863960266\n",
      "model 372/375 done, hidden = PReLU, output = PReLU, optim = Adagrad || accuracy: 0.710564374923706\n",
      "model 373/375 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.9030390977859497\n",
      "model 374/375 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.9073805809020996\n",
      "model 375/375 done, hidden = PReLU, output = PReLU, optim = Adamax || accuracy: 0.9088277816772461\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hl_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "ol_f = ['sigmoid','tanh','relu','LeakyReLU','PReLU']\n",
    "act = ['SGD', 'RMSprop','Adam','Adagrad','Adamax']\n",
    "lstm_size = [32, 64, 128]\n",
    "\n",
    "\n",
    "RNN_table = defaultdict(list)\n",
    "count = 0\n",
    "for i in hl_f:\n",
    "    for j in ol_f:\n",
    "        for k in act:\n",
    "            for l in lstm_size:\n",
    "                RNN_table['hl_f'].append(i)\n",
    "                RNN_table['ol_f'].append(j)\n",
    "                RNN_table['k_f'].append(k)\n",
    "                RNN_table['lstm_size'].append(l)          \n",
    "\n",
    "                model = create_RNNModel(i, j, k, l)\n",
    "\n",
    "                history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32)\n",
    "                loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "                RNN_table['accuracy'].append(accuracy)\n",
    "                RNN_table['loss'].append(loss)\n",
    "                count = count + 1\n",
    "                print(f'model {count}/375 done, hidden = {i}, output = {j}, optim = {k} || accuracy: {accuracy}')\n",
    "                tf.keras.backend.clear_session()\n",
    "                with open('RNN_accuracies.txt', 'a') as f:\n",
    "                    f.write('\\n'+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hl_f</th>\n",
       "      <th>ol_f</th>\n",
       "      <th>k_f</th>\n",
       "      <th>n_filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.693044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.692790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>0.692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>0.693040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.692909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.308327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888567</td>\n",
       "      <td>0.420891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.895803</td>\n",
       "      <td>0.278415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>0.900145</td>\n",
       "      <td>0.372530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hl_f     ol_f     k_f  n_filters  kernel_size  accuracy      loss\n",
       "0     sigmoid  sigmoid     SGD         32            3  0.502171  0.693044\n",
       "1     sigmoid  sigmoid     SGD         32            5  0.502171  0.692790\n",
       "2     sigmoid  sigmoid     SGD         32            7  0.516643  0.692992\n",
       "3     sigmoid  sigmoid     SGD         64            3  0.497829  0.693040\n",
       "4     sigmoid  sigmoid     SGD         64            5  0.502171  0.692909\n",
       "...       ...      ...     ...        ...          ...       ...       ...\n",
       "1120    PReLU    PReLU  Adamax         64            5  0.905933  0.308327\n",
       "1121    PReLU    PReLU  Adamax         64            7  0.888567  0.420891\n",
       "1122    PReLU    PReLU  Adamax        128            3  0.895803  0.278415\n",
       "1123    PReLU    PReLU  Adamax        128            5  0.497829  7.745959\n",
       "1124    PReLU    PReLU  Adamax        128            7  0.900145  0.372530\n",
       "\n",
       "[1125 rows x 7 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CNN_res = pd.DataFrame(table)\n",
    "df_CNN_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hl_f</th>\n",
       "      <th>ol_f</th>\n",
       "      <th>k_f</th>\n",
       "      <th>n_filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920405</td>\n",
       "      <td>0.377860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tanh</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.862805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.360863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>0.322013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>0.362213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>relu</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>relu</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.693483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hl_f       ol_f      k_f  n_filters  kernel_size  accuracy      loss\n",
       "469     relu    sigmoid     Adam         32            5  0.920405  0.377860\n",
       "239     tanh    sigmoid  RMSprop         64            7  0.917511  0.862805\n",
       "472     relu    sigmoid     Adam         64            5  0.917511  0.360863\n",
       "20   sigmoid    sigmoid     Adam         32            7  0.916064  0.322013\n",
       "470     relu    sigmoid     Adam         32            7  0.916064  0.362213\n",
       "..       ...        ...      ...        ...          ...       ...       ...\n",
       "614     relu  LeakyReLU  Adagrad         32            7  0.497829  7.745959\n",
       "113  sigmoid       relu     Adam         64            7  0.497829  7.745959\n",
       "620     relu  LeakyReLU  Adagrad        128            7  0.497829  7.745959\n",
       "80   sigmoid       tanh  Adagrad        128            7  0.497829  7.745959\n",
       "34   sigmoid    sigmoid  Adagrad        128            5  0.492041  0.693483\n",
       "\n",
       "[1125 rows x 7 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CNN_res.sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hl_f</th>\n",
       "      <th>ol_f</th>\n",
       "      <th>k_f</th>\n",
       "      <th>lstm_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.519537</td>\n",
       "      <td>0.691516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>64</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.692205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>SGD</td>\n",
       "      <td>128</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.693376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.907381</td>\n",
       "      <td>1.237076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>1.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>64</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>128</td>\n",
       "      <td>0.710564</td>\n",
       "      <td>0.602195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>32</td>\n",
       "      <td>0.903039</td>\n",
       "      <td>0.561781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>64</td>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.484241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>128</td>\n",
       "      <td>0.908828</td>\n",
       "      <td>0.601306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hl_f     ol_f      k_f  lstm_size  accuracy      loss\n",
       "0    sigmoid  sigmoid      SGD         32  0.519537  0.691516\n",
       "1    sigmoid  sigmoid      SGD         64  0.502171  0.692205\n",
       "2    sigmoid  sigmoid      SGD        128  0.502171  0.693376\n",
       "3    sigmoid  sigmoid  RMSprop         32  0.907381  1.237076\n",
       "4    sigmoid  sigmoid  RMSprop         64  0.916064  1.190194\n",
       "..       ...      ...      ...        ...       ...       ...\n",
       "370    PReLU    PReLU  Adagrad         64  0.497829  7.745959\n",
       "371    PReLU    PReLU  Adagrad        128  0.710564  0.602195\n",
       "372    PReLU    PReLU   Adamax         32  0.903039  0.561781\n",
       "373    PReLU    PReLU   Adamax         64  0.907381  0.484241\n",
       "374    PReLU    PReLU   Adamax        128  0.908828  0.601306\n",
       "\n",
       "[375 rows x 6 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RNN_res = pd.DataFrame(RNN_table)\n",
    "df_RNN_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hl_f</th>\n",
       "      <th>ol_f</th>\n",
       "      <th>k_f</th>\n",
       "      <th>lstm_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>0.551390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.917511</td>\n",
       "      <td>1.183042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>1.190194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tanh</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.916064</td>\n",
       "      <td>1.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>PReLU</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>Adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.914617</td>\n",
       "      <td>0.627071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>PReLU</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>64</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>7.745959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hl_f       ol_f      k_f  lstm_size  accuracy      loss\n",
       "156       relu    sigmoid     Adam         32  0.917511  0.551390\n",
       "304      PReLU    sigmoid  RMSprop         64  0.917511  1.183042\n",
       "4      sigmoid    sigmoid  RMSprop         64  0.916064  1.190194\n",
       "79        tanh    sigmoid  RMSprop         64  0.916064  1.042169\n",
       "353      PReLU  LeakyReLU     Adam        128  0.914617  0.627071\n",
       "..         ...        ...      ...        ...       ...       ...\n",
       "65     sigmoid      PReLU  RMSprop        128  0.497829  7.745959\n",
       "67     sigmoid      PReLU     Adam         64  0.497829  7.745959\n",
       "68     sigmoid      PReLU     Adam        128  0.497829  7.745959\n",
       "69     sigmoid      PReLU  Adagrad         32  0.497829  7.745959\n",
       "298  LeakyReLU      PReLU   Adamax         64  0.497829  7.745959\n",
       "\n",
       "[375 rows x 6 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RNN_res.sort_values('accuracy', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RNN_res.to_csv('RNN_Experimentation_ENGLISH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 300)          3214200   \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 96, 32)            48032     \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,263,049\n",
      "Trainable params: 3,263,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 2s 11ms/step - loss: 0.5755 - accuracy: 0.7269 - val_loss: 0.3381 - val_accuracy: 0.8654\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.1675 - accuracy: 0.9515 - val_loss: 0.2410 - val_accuracy: 0.9103\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 0.0394 - accuracy: 0.9909 - val_loss: 0.2329 - val_accuracy: 0.9074\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.2567 - val_accuracy: 0.9030\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.2691 - val_accuracy: 0.9016\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9088\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 9.2093e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9074\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 6.2975e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9074\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 4.6485e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 3.5785e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9074\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 2.8436e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.9074\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 2.3213e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9074\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 1.9228e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9059\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 1.6188e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9059\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 1.3789e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9059\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 1.1893e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 1.0303e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9059\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 9.0240e-05 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9059\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 7.9585e-05 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9059\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 1s 10ms/step - loss: 7.0641e-05 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9059\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 6.2992e-05 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 5.6464e-05 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9059\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 1s 9ms/step - loss: 5.0806e-05 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9059\n",
      "Training Accuracy: 0.9978\n",
      "Testing Accuracy:  0.9074\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, trainable=True))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(24, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "STAMP = f'Tagalog_CNN_Vectors'\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=20)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32, shuffle=True, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "\n",
    "#, \n",
    "\n",
    "model.load_weights(bst_model_path)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 300)          3214200   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,404,201\n",
      "Trainable params: 3,404,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11712/1820913775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      9\u001b[0m \u001b[0mRNN_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = RNN_model.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cvaal\\anaconda3\\envs\\tf_gpu_2.7\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_model = Sequential()\n",
    "RNN_model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "RNN_model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "RNN_model.add(layers.Dense(24, activation='relu'))\n",
    "RNN_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "RNN_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "RNN_model.summary()\n",
    "history = RNN_model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32)\n",
    "\n",
    "\n",
    "loss, accuracy = RNN_model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = RNN_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=5000, char_level=True)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=49)\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "X_train.shape\n",
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    'glove/glove.6B.100d.txt',\n",
    "    tokenizer.word_index, embedding_dim)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# model = Sequential()\n",
    "# model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "# model.add(layers.Conv1D(128, 5, activation='tanh'))\n",
    "# model.add(layers.GlobalMaxPooling1D())\n",
    "# model.add(layers.Dense(10, activation='tanh'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='RMSProp',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          8200      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 200)         160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               59648     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235,249\n",
      "Trainable params: 235,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 11s 33ms/step - loss: 0.6956 - accuracy: 0.6121 - val_loss: 0.5907 - val_accuracy: 0.6099\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6417 - accuracy: 0.6963 - val_loss: 0.4911 - val_accuracy: 0.7511\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 1.1212 - accuracy: 0.6758 - val_loss: 0.5808 - val_accuracy: 0.6427\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.7456 - accuracy: 0.7125 - val_loss: 0.6594 - val_accuracy: 0.7351\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 1.4210 - accuracy: 0.7003 - val_loss: 0.4938 - val_accuracy: 0.7641\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6147 - accuracy: 0.7579 - val_loss: 0.4672 - val_accuracy: 0.7641\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.8021 - accuracy: 0.7510 - val_loss: 0.9463 - val_accuracy: 0.7359\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6923 - accuracy: 0.7442 - val_loss: 0.4440 - val_accuracy: 0.7817\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5613 - accuracy: 0.7707 - val_loss: 0.4605 - val_accuracy: 0.7565\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.6938 - accuracy: 0.7497 - val_loss: 0.4625 - val_accuracy: 0.7481\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5897 - accuracy: 0.7587 - val_loss: 0.4719 - val_accuracy: 0.7855\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.6117 - accuracy: 0.7890 - val_loss: 0.5014 - val_accuracy: 0.7924\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5542 - accuracy: 0.7784 - val_loss: 0.5644 - val_accuracy: 0.7924\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5431 - accuracy: 0.7753 - val_loss: 0.4619 - val_accuracy: 0.7931\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.7028 - accuracy: 0.7789 - val_loss: 0.5451 - val_accuracy: 0.7588\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6697 - accuracy: 0.7715 - val_loss: 0.5218 - val_accuracy: 0.7649\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.8033 - accuracy: 0.7658 - val_loss: 0.5497 - val_accuracy: 0.7565\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6135 - accuracy: 0.7793 - val_loss: 0.6175 - val_accuracy: 0.7809\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6452 - accuracy: 0.7764 - val_loss: 0.6797 - val_accuracy: 0.7649\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5943 - accuracy: 0.7904 - val_loss: 0.5891 - val_accuracy: 0.7924\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5984 - accuracy: 0.7625 - val_loss: 0.6037 - val_accuracy: 0.7412\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.7063 - accuracy: 0.7808 - val_loss: 0.9111 - val_accuracy: 0.7908\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.7088 - accuracy: 0.8005 - val_loss: 0.6742 - val_accuracy: 0.7878\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.6604 - accuracy: 0.7995 - val_loss: 0.8303 - val_accuracy: 0.8038\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5519 - accuracy: 0.7963 - val_loss: 0.8487 - val_accuracy: 0.7947\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.5896 - accuracy: 0.8041 - val_loss: 0.6208 - val_accuracy: 0.7977\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.7522 - accuracy: 0.8131 - val_loss: 1.2336 - val_accuracy: 0.7863\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.5965 - accuracy: 0.8142 - val_loss: 0.5286 - val_accuracy: 0.7878\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.6463 - accuracy: 0.8186 - val_loss: 0.8566 - val_accuracy: 0.8015\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.5148 - accuracy: 0.8110 - val_loss: 0.6090 - val_accuracy: 0.7924\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5845 - accuracy: 0.8211 - val_loss: 0.8198 - val_accuracy: 0.8061\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5730 - accuracy: 0.8207 - val_loss: 0.7255 - val_accuracy: 0.7893\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.7003 - accuracy: 0.8234 - val_loss: 0.9032 - val_accuracy: 0.8031\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.8217 - accuracy: 0.8139 - val_loss: 0.6062 - val_accuracy: 0.7679\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.5800 - accuracy: 0.8314 - val_loss: 0.6455 - val_accuracy: 0.8046\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5786 - accuracy: 0.8127 - val_loss: 0.6084 - val_accuracy: 0.7817\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5628 - accuracy: 0.8309 - val_loss: 0.9187 - val_accuracy: 0.8015\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.6818 - accuracy: 0.8219 - val_loss: 0.8756 - val_accuracy: 0.7916\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6519 - accuracy: 0.8278 - val_loss: 0.9250 - val_accuracy: 0.7969\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5068 - accuracy: 0.8381 - val_loss: 0.6225 - val_accuracy: 0.8023\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5251 - accuracy: 0.8314 - val_loss: 0.6282 - val_accuracy: 0.8076\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5264 - accuracy: 0.8368 - val_loss: 0.9392 - val_accuracy: 0.7885\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5173 - accuracy: 0.8423 - val_loss: 0.9144 - val_accuracy: 0.7947\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5657 - accuracy: 0.8381 - val_loss: 1.6383 - val_accuracy: 0.7573\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5309 - accuracy: 0.8477 - val_loss: 0.7335 - val_accuracy: 0.8031\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.4712 - accuracy: 0.8530 - val_loss: 0.9787 - val_accuracy: 0.8023\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5302 - accuracy: 0.8540 - val_loss: 1.0296 - val_accuracy: 0.7924\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5672 - accuracy: 0.8520 - val_loss: 1.0917 - val_accuracy: 0.8015\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5818 - accuracy: 0.8540 - val_loss: 0.9704 - val_accuracy: 0.8168\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5271 - accuracy: 0.8597 - val_loss: 0.9353 - val_accuracy: 0.7824\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5520 - accuracy: 0.8625 - val_loss: 0.9386 - val_accuracy: 0.7939\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5818 - accuracy: 0.8580 - val_loss: 0.9085 - val_accuracy: 0.7855\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5866 - accuracy: 0.8614 - val_loss: 0.9279 - val_accuracy: 0.7878\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5369 - accuracy: 0.8660 - val_loss: 1.1116 - val_accuracy: 0.8084\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.6012 - accuracy: 0.8744 - val_loss: 0.9949 - val_accuracy: 0.7931\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5115 - accuracy: 0.8740 - val_loss: 1.4148 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5184 - accuracy: 0.8771 - val_loss: 1.2929 - val_accuracy: 0.7954\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.6270 - accuracy: 0.8751 - val_loss: 1.1730 - val_accuracy: 0.7962\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4619 - accuracy: 0.8795 - val_loss: 1.1122 - val_accuracy: 0.7924\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5295 - accuracy: 0.8879 - val_loss: 1.4929 - val_accuracy: 0.8115\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5103 - accuracy: 0.8914 - val_loss: 1.2067 - val_accuracy: 0.7878\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4949 - accuracy: 0.8967 - val_loss: 1.6030 - val_accuracy: 0.7985\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.5681 - accuracy: 0.8925 - val_loss: 1.6178 - val_accuracy: 0.7885\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.4449 - accuracy: 0.8986 - val_loss: 1.5925 - val_accuracy: 0.8053\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4419 - accuracy: 0.9076 - val_loss: 1.4998 - val_accuracy: 0.8015\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.4204 - accuracy: 0.9112 - val_loss: 2.0054 - val_accuracy: 0.7870\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4626 - accuracy: 0.9116 - val_loss: 1.8455 - val_accuracy: 0.7947\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4636 - accuracy: 0.9091 - val_loss: 1.8512 - val_accuracy: 0.7924\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5380 - accuracy: 0.9082 - val_loss: 1.9911 - val_accuracy: 0.7893\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5172 - accuracy: 0.9139 - val_loss: 1.9079 - val_accuracy: 0.7679\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5514 - accuracy: 0.9156 - val_loss: 2.0645 - val_accuracy: 0.7908\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.4843 - accuracy: 0.9191 - val_loss: 2.0206 - val_accuracy: 0.7855\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.4816 - accuracy: 0.9248 - val_loss: 2.4496 - val_accuracy: 0.7947\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5144 - accuracy: 0.9252 - val_loss: 2.1191 - val_accuracy: 0.7824\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.4468 - accuracy: 0.9336 - val_loss: 2.1201 - val_accuracy: 0.7954\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.5293 - accuracy: 0.9320 - val_loss: 2.1303 - val_accuracy: 0.7939\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4344 - accuracy: 0.9336 - val_loss: 2.0493 - val_accuracy: 0.7817\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4588 - accuracy: 0.9278 - val_loss: 2.0991 - val_accuracy: 0.7824\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4123 - accuracy: 0.9423 - val_loss: 2.3593 - val_accuracy: 0.7847\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.4100 - accuracy: 0.9317 - val_loss: 1.9041 - val_accuracy: 0.7863\n",
      "Epoch 81/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3633 - accuracy: 0.9427 - val_loss: 2.1745 - val_accuracy: 0.7740\n",
      "Epoch 82/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3961 - accuracy: 0.9441 - val_loss: 2.3500 - val_accuracy: 0.7855\n",
      "Epoch 83/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3685 - accuracy: 0.9471 - val_loss: 2.1354 - val_accuracy: 0.7962\n",
      "Epoch 84/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.4645 - accuracy: 0.9389 - val_loss: 2.3758 - val_accuracy: 0.7779\n",
      "Epoch 85/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3680 - accuracy: 0.9509 - val_loss: 2.2434 - val_accuracy: 0.7969\n",
      "Epoch 86/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.4311 - accuracy: 0.9496 - val_loss: 2.2741 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3858 - accuracy: 0.9523 - val_loss: 2.4192 - val_accuracy: 0.7931\n",
      "Epoch 88/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3510 - accuracy: 0.9557 - val_loss: 2.4314 - val_accuracy: 0.7924\n",
      "Epoch 89/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3380 - accuracy: 0.9580 - val_loss: 2.4037 - val_accuracy: 0.789330 - accuracy: 0.\n",
      "Epoch 90/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3085 - accuracy: 0.9591 - val_loss: 2.4278 - val_accuracy: 0.7931\n",
      "Epoch 91/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3511 - accuracy: 0.9626 - val_loss: 2.7456 - val_accuracy: 0.7840\n",
      "Epoch 92/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3498 - accuracy: 0.9593 - val_loss: 2.5267 - val_accuracy: 0.7947\n",
      "Epoch 93/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3359 - accuracy: 0.9635 - val_loss: 2.6558 - val_accuracy: 0.7740\n",
      "Epoch 94/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3233 - accuracy: 0.9639 - val_loss: 2.6203 - val_accuracy: 0.7954\n",
      "Epoch 95/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3130 - accuracy: 0.9664 - val_loss: 2.4210 - val_accuracy: 0.7969\n",
      "Epoch 96/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2914 - accuracy: 0.9698 - val_loss: 2.7666 - val_accuracy: 0.7786\n",
      "Epoch 97/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4158 - accuracy: 0.9595 - val_loss: 2.6604 - val_accuracy: 0.7901\n",
      "Epoch 98/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3578 - accuracy: 0.9681 - val_loss: 2.7033 - val_accuracy: 0.7977\n",
      "Epoch 99/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3206 - accuracy: 0.9708 - val_loss: 2.8393 - val_accuracy: 0.7779\n",
      "Epoch 100/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.4146 - accuracy: 0.9622 - val_loss: 2.8399 - val_accuracy: 0.7924\n",
      "Epoch 101/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3514 - accuracy: 0.9658 - val_loss: 2.6440 - val_accuracy: 0.7962\n",
      "Epoch 102/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3167 - accuracy: 0.9693 - val_loss: 2.8319 - val_accuracy: 0.7847\n",
      "Epoch 103/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.2965 - accuracy: 0.9744 - val_loss: 2.6788 - val_accuracy: 0.7962\n",
      "Epoch 104/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2900 - accuracy: 0.9740 - val_loss: 2.6648 - val_accuracy: 0.7878\n",
      "Epoch 105/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3045 - accuracy: 0.9752 - val_loss: 2.6321 - val_accuracy: 0.7924\n",
      "Epoch 106/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2788 - accuracy: 0.9752 - val_loss: 2.9045 - val_accuracy: 0.7947\n",
      "Epoch 107/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3969 - accuracy: 0.9643 - val_loss: 2.8047 - val_accuracy: 0.7924\n",
      "Epoch 108/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3579 - accuracy: 0.9702 - val_loss: 2.7085 - val_accuracy: 0.7985\n",
      "Epoch 109/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3544 - accuracy: 0.9693 - val_loss: 2.8212 - val_accuracy: 0.7901\n",
      "Epoch 110/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3288 - accuracy: 0.9721 - val_loss: 2.8947 - val_accuracy: 0.7832\n",
      "Epoch 111/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3160 - accuracy: 0.9738 - val_loss: 2.7432 - val_accuracy: 0.7977\n",
      "Epoch 112/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.3665 - accuracy: 0.9693 - val_loss: 2.7139 - val_accuracy: 0.7977\n",
      "Epoch 113/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3194 - accuracy: 0.9733 - val_loss: 2.9337 - val_accuracy: 0.7878\n",
      "Epoch 114/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.3176 - accuracy: 0.9737 - val_loss: 3.0230 - val_accuracy: 0.7802\n",
      "Epoch 115/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3284 - accuracy: 0.9725 - val_loss: 2.7246 - val_accuracy: 0.7947\n",
      "Epoch 116/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3224 - accuracy: 0.9716 - val_loss: 2.8154 - val_accuracy: 0.7939\n",
      "Epoch 117/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3196 - accuracy: 0.9717 - val_loss: 2.9438 - val_accuracy: 0.7824\n",
      "Epoch 118/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2761 - accuracy: 0.9763 - val_loss: 2.9398 - val_accuracy: 0.7863\n",
      "Epoch 119/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2854 - accuracy: 0.9740 - val_loss: 2.8217 - val_accuracy: 0.7954\n",
      "Epoch 120/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3249 - accuracy: 0.9733 - val_loss: 2.9960 - val_accuracy: 0.7817\n",
      "Epoch 121/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3057 - accuracy: 0.9752 - val_loss: 2.7356 - val_accuracy: 0.7977\n",
      "Epoch 122/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.3475 - accuracy: 0.9689 - val_loss: 2.8419 - val_accuracy: 0.7969\n",
      "Epoch 123/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.2860 - accuracy: 0.9763 - val_loss: 2.8212 - val_accuracy: 0.7870\n",
      "Epoch 124/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2935 - accuracy: 0.9773 - val_loss: 2.8283 - val_accuracy: 0.7924\n",
      "Epoch 125/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3011 - accuracy: 0.9773 - val_loss: 2.8741 - val_accuracy: 0.7954\n",
      "Epoch 126/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.2653 - accuracy: 0.9800 - val_loss: 3.0477 - val_accuracy: 0.7802\n",
      "Epoch 127/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2880 - accuracy: 0.9767 - val_loss: 2.8620 - val_accuracy: 0.7893\n",
      "Epoch 128/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.3397 - accuracy: 0.9733 - val_loss: 2.7960 - val_accuracy: 0.7977\n",
      "Epoch 129/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.2756 - accuracy: 0.9782 - val_loss: 2.8611 - val_accuracy: 0.7939\n",
      "Epoch 130/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.2923 - accuracy: 0.9756 - val_loss: 2.9607 - val_accuracy: 0.7908\n",
      "Epoch 131/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.2836 - accuracy: 0.9773 - val_loss: 2.8355 - val_accuracy: 0.8015\n",
      "Epoch 132/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2418 - accuracy: 0.9807 - val_loss: 2.8967 - val_accuracy: 0.7977\n",
      "Epoch 133/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.2977 - accuracy: 0.9763 - val_loss: 2.9906 - val_accuracy: 0.7870\n",
      "Epoch 134/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2721 - accuracy: 0.9771 - val_loss: 2.7025 - val_accuracy: 0.7977\n",
      "Epoch 135/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2983 - accuracy: 0.9761 - val_loss: 2.9529 - val_accuracy: 0.7939\n",
      "Epoch 136/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.2331 - accuracy: 0.9815 - val_loss: 2.7942 - val_accuracy: 0.7992\n",
      "Epoch 137/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2485 - accuracy: 0.9813 - val_loss: 2.7824 - val_accuracy: 0.7992\n",
      "Epoch 138/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2948 - accuracy: 0.9771 - val_loss: 2.7653 - val_accuracy: 0.8046\n",
      "Epoch 139/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2389 - accuracy: 0.9807 - val_loss: 2.8384 - val_accuracy: 0.7969\n",
      "Epoch 140/200\n",
      "164/164 [==============================] - 4s 26ms/step - loss: 0.2539 - accuracy: 0.9786 - val_loss: 2.7775 - val_accuracy: 0.7977\n",
      "Epoch 141/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2531 - accuracy: 0.9800 - val_loss: 2.9813 - val_accuracy: 0.7863\n",
      "Epoch 142/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2358 - accuracy: 0.9811 - val_loss: 2.8812 - val_accuracy: 0.7924\n",
      "Epoch 143/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.2531 - accuracy: 0.9790 - val_loss: 3.0699 - val_accuracy: 0.7802\n",
      "Epoch 144/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2448 - accuracy: 0.9811 - val_loss: 2.8643 - val_accuracy: 0.7924\n",
      "Epoch 145/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2122 - accuracy: 0.9845 - val_loss: 3.0580 - val_accuracy: 0.7893\n",
      "Epoch 146/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2223 - accuracy: 0.9832 - val_loss: 2.9218 - val_accuracy: 0.7985\n",
      "Epoch 147/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2233 - accuracy: 0.9822 - val_loss: 2.9331 - val_accuracy: 0.7893\n",
      "Epoch 148/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2497 - accuracy: 0.9813 - val_loss: 2.9040 - val_accuracy: 0.7985\n",
      "Epoch 149/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2245 - accuracy: 0.9832 - val_loss: 2.8860 - val_accuracy: 0.7916\n",
      "Epoch 150/200\n",
      "164/164 [==============================] - 4s 24ms/step - loss: 0.2294 - accuracy: 0.9832 - val_loss: 2.8344 - val_accuracy: 0.7947\n",
      "Epoch 151/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1863 - accuracy: 0.9855 - val_loss: 2.8451 - val_accuracy: 0.7985\n",
      "Epoch 152/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1866 - accuracy: 0.9851 - val_loss: 2.8781 - val_accuracy: 0.7977\n",
      "Epoch 153/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2226 - accuracy: 0.9824 - val_loss: 2.9190 - val_accuracy: 0.7939\n",
      "Epoch 154/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2226 - accuracy: 0.9824 - val_loss: 2.9617 - val_accuracy: 0.7916\n",
      "Epoch 155/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2991 - accuracy: 0.9752 - val_loss: 2.9303 - val_accuracy: 0.7901\n",
      "Epoch 156/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.3461 - accuracy: 0.9754 - val_loss: 2.8531 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2442 - accuracy: 0.9807 - val_loss: 2.9192 - val_accuracy: 0.7855\n",
      "Epoch 158/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2451 - accuracy: 0.9817 - val_loss: 2.9037 - val_accuracy: 0.7947\n",
      "Epoch 159/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2150 - accuracy: 0.9822 - val_loss: 2.9526 - val_accuracy: 0.7885\n",
      "Epoch 160/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2659 - accuracy: 0.9788 - val_loss: 2.9277 - val_accuracy: 0.7947\n",
      "Epoch 161/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2768 - accuracy: 0.9792 - val_loss: 2.8880 - val_accuracy: 0.7901\n",
      "Epoch 162/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2381 - accuracy: 0.9813 - val_loss: 2.9866 - val_accuracy: 0.7840\n",
      "Epoch 163/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1997 - accuracy: 0.9845 - val_loss: 2.7995 - val_accuracy: 0.8031\n",
      "Epoch 164/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1906 - accuracy: 0.9849 - val_loss: 2.8501 - val_accuracy: 0.8015\n",
      "Epoch 165/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1816 - accuracy: 0.9861 - val_loss: 2.9183 - val_accuracy: 0.7947\n",
      "Epoch 166/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2139 - accuracy: 0.9843 - val_loss: 3.2141 - val_accuracy: 0.7779\n",
      "Epoch 167/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2646 - accuracy: 0.9813 - val_loss: 2.9385 - val_accuracy: 0.7885\n",
      "Epoch 168/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2137 - accuracy: 0.9840 - val_loss: 2.8331 - val_accuracy: 0.7954\n",
      "Epoch 169/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1510 - accuracy: 0.9882 - val_loss: 2.8535 - val_accuracy: 0.7962\n",
      "Epoch 170/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2254 - accuracy: 0.9834 - val_loss: 2.8562 - val_accuracy: 0.8015\n",
      "Epoch 171/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2050 - accuracy: 0.9853 - val_loss: 2.8640 - val_accuracy: 0.7992\n",
      "Epoch 172/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2040 - accuracy: 0.9845 - val_loss: 2.7590 - val_accuracy: 0.8069\n",
      "Epoch 173/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2677 - accuracy: 0.9805 - val_loss: 2.8601 - val_accuracy: 0.8008\n",
      "Epoch 174/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2078 - accuracy: 0.9847 - val_loss: 3.0159 - val_accuracy: 0.7947\n",
      "Epoch 175/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2594 - accuracy: 0.9801 - val_loss: 2.7462 - val_accuracy: 0.8084\n",
      "Epoch 176/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2364 - accuracy: 0.9819 - val_loss: 2.7234 - val_accuracy: 0.8015\n",
      "Epoch 177/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2029 - accuracy: 0.9845 - val_loss: 2.8260 - val_accuracy: 0.7962\n",
      "Epoch 178/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2346 - accuracy: 0.9822 - val_loss: 2.8604 - val_accuracy: 0.8031\n",
      "Epoch 179/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1851 - accuracy: 0.9859 - val_loss: 2.8428 - val_accuracy: 0.8038\n",
      "Epoch 180/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2018 - accuracy: 0.9849 - val_loss: 2.9733 - val_accuracy: 0.7939\n",
      "Epoch 181/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2242 - accuracy: 0.9832 - val_loss: 2.8493 - val_accuracy: 0.8015\n",
      "Epoch 182/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2066 - accuracy: 0.9845 - val_loss: 2.8472 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1965 - accuracy: 0.9855 - val_loss: 2.8918 - val_accuracy: 0.7985\n",
      "Epoch 184/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2298 - accuracy: 0.9828 - val_loss: 2.8966 - val_accuracy: 0.7954\n",
      "Epoch 185/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2082 - accuracy: 0.9834 - val_loss: 2.7274 - val_accuracy: 0.8099\n",
      "Epoch 186/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2007 - accuracy: 0.9851 - val_loss: 2.8422 - val_accuracy: 0.8008\n",
      "Epoch 187/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2225 - accuracy: 0.9840 - val_loss: 2.6637 - val_accuracy: 0.8122\n",
      "Epoch 188/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2078 - accuracy: 0.9849 - val_loss: 2.8996 - val_accuracy: 0.7985\n",
      "Epoch 189/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2647 - accuracy: 0.9800 - val_loss: 2.7924 - val_accuracy: 0.8038\n",
      "Epoch 190/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2520 - accuracy: 0.9801 - val_loss: 2.9569 - val_accuracy: 0.7893\n",
      "Epoch 191/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2196 - accuracy: 0.9840 - val_loss: 2.7097 - val_accuracy: 0.8084\n",
      "Epoch 192/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1891 - accuracy: 0.9851 - val_loss: 2.8761 - val_accuracy: 0.7977\n",
      "Epoch 193/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2034 - accuracy: 0.9845 - val_loss: 2.7582 - val_accuracy: 0.8046\n",
      "Epoch 194/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2230 - accuracy: 0.9843 - val_loss: 2.6033 - val_accuracy: 0.8168\n",
      "Epoch 195/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1991 - accuracy: 0.9863 - val_loss: 2.7246 - val_accuracy: 0.8023\n",
      "Epoch 196/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1855 - accuracy: 0.9861 - val_loss: 2.8928 - val_accuracy: 0.7962\n",
      "Epoch 197/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.2020 - accuracy: 0.9840 - val_loss: 2.7639 - val_accuracy: 0.8061\n",
      "Epoch 198/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1893 - accuracy: 0.9870 - val_loss: 2.7662 - val_accuracy: 0.8023\n",
      "Epoch 199/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1852 - accuracy: 0.9863 - val_loss: 2.9053 - val_accuracy: 0.7992\n",
      "Epoch 200/200\n",
      "164/164 [==============================] - 4s 25ms/step - loss: 0.1901 - accuracy: 0.9864 - val_loss: 2.7875 - val_accuracy: 0.8038\n",
      "Training Accuracy: 0.9897\n",
      "Testing Accuracy:  0.8038\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "RNN_model = Sequential()\n",
    "RNN_model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "RNN_model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n",
    "RNN_model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "RNN_model.add(layers.Dense(64, activation='relu'))\n",
    "RNN_model.add(layers.Dropout(0.5))\n",
    "RNN_model.add(layers.Dense(1))\n",
    "opt = optimizers.rmsprop_v2.RMSProp(learning_rate=0.001)\n",
    "RNN_model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "RNN_model.summary()\n",
    "history = RNN_model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32)\n",
    "\n",
    "\n",
    "loss, accuracy = RNN_model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = RNN_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 100, 100)          8200      \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 512)              731136    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,129\n",
      "Trainable params: 805,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "328/328 [==============================] - 11s 23ms/step - loss: 3.1660 - accuracy: 0.5827 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 2/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 3/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 4/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 5/200\n",
      "328/328 [==============================] - 7s 22ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 6/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 7/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 8/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 9/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 10/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 11/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 12/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 13/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 14/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 15/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 16/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 17/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 18/200\n",
      "328/328 [==============================] - 7s 23ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 19/200\n",
      "328/328 [==============================] - 7s 22ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 20/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 21/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 22/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 23/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 24/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 25/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 26/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 27/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 28/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 29/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 30/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 31/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 32/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 33/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 34/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 35/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 36/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 37/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 38/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 39/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 40/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 41/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 42/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 43/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 44/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 45/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 46/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 47/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 48/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 49/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 50/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 51/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 52/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 53/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 54/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 55/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 56/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 57/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 58/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 59/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 60/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 61/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 62/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 63/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 64/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 65/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 66/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 67/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 68/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 69/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 70/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 71/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 72/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 73/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 74/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 75/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 76/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 77/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 78/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 79/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 80/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 81/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 82/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 83/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 84/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 85/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 86/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 87/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 88/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 89/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 90/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 91/200\n",
      "328/328 [==============================] - 7s 21ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 92/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 93/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 94/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 95/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 96/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 97/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 98/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 99/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 100/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 101/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 102/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 103/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 104/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 105/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 106/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 107/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 108/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 109/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 110/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 111/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 112/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 113/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 114/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 115/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 116/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 117/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 118/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 119/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 120/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 121/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 122/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 123/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 124/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 125/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 126/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 127/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 128/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 129/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 130/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 131/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 132/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 133/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 134/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 135/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 136/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 137/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 138/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 139/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 140/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 141/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 142/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 143/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 144/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 145/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 146/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 147/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 148/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 149/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 150/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 151/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 152/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 153/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 154/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 155/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 156/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 157/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 158/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 159/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 160/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 161/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 162/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 163/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 164/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 165/200\n",
      "328/328 [==============================] - 6s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 166/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 167/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 168/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 169/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 170/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 171/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 172/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 173/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 174/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 175/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 176/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 177/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 178/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 179/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 180/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 181/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 182/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 183/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 184/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 185/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 186/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 187/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 188/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 189/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 190/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 191/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 192/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 193/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 194/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 195/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 196/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 197/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 198/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 199/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Epoch 200/200\n",
      "328/328 [==============================] - 7s 20ms/step - loss: 7.7007 - accuracy: 0.5008 - val_loss: 7.7596 - val_accuracy: 0.4969\n",
      "Training Accuracy: 0.5008\n",
      "Testing Accuracy:  0.4969\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_model = Sequential()\n",
    "RNN_model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "RNN_model.add(layers.Bidirectional(layers.LSTM(256)))\n",
    "RNN_model.add(layers.Dense(128, activation='relu'))\n",
    "RNN_model.add(layers.Dense(1, activation='tanh'))\n",
    "opt = optimizers.rmsprop_v2.RMSProp(learning_rate=0.001)\n",
    "RNN_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "RNN_model.summary()\n",
    "history = RNN_model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=16)\n",
    "\n",
    "\n",
    "loss, accuracy = RNN_model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = RNN_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
