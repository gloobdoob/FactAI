{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Page rank integer</th>\n",
       "      <th>Page rank decimal</th>\n",
       "      <th>Site Rank</th>\n",
       "      <th>Domain registrar</th>\n",
       "      <th>Postal code</th>\n",
       "      <th>Country of origin</th>\n",
       "      <th>Harmless</th>\n",
       "      <th>Malicious</th>\n",
       "      <th>Suspicious</th>\n",
       "      <th>Undetected</th>\n",
       "      <th>Timeout</th>\n",
       "      <th>No. of Local links</th>\n",
       "      <th>No. of Outbound links</th>\n",
       "      <th>Total links</th>\n",
       "      <th>Links to fake news site?</th>\n",
       "      <th>Wordpress?</th>\n",
       "      <th>Site Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actionnews3.com</td>\n",
       "      <td>3</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7390112.0</td>\n",
       "      <td>GoDaddy.com, LLC</td>\n",
       "      <td>85284</td>\n",
       "      <td>US</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcnews-us.com</td>\n",
       "      <td>3</td>\n",
       "      <td>2.89</td>\n",
       "      <td>6579810.0</td>\n",
       "      <td>NamePal.com #8009 Inc.</td>\n",
       "      <td>32256</td>\n",
       "      <td>US</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21stcenturywire.com</td>\n",
       "      <td>5</td>\n",
       "      <td>4.57</td>\n",
       "      <td>66742.0</td>\n",
       "      <td>GoDaddy.com, LLC</td>\n",
       "      <td>85284</td>\n",
       "      <td>US</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>36</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>4</td>\n",
       "      <td>4.15</td>\n",
       "      <td>778723.0</td>\n",
       "      <td>GoDaddy.com, LLC</td>\n",
       "      <td>85284</td>\n",
       "      <td>US</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcnews.com</td>\n",
       "      <td>5</td>\n",
       "      <td>4.78</td>\n",
       "      <td>32787.0</td>\n",
       "      <td>CSC CORPORATE DOMAINS, INC.</td>\n",
       "      <td>10023-6298</td>\n",
       "      <td>US</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Domain  Page rank integer  Page rank decimal  Site Rank   \n",
       "0      actionnews3.com                  3               2.82  7390112.0  \\\n",
       "1       abcnews-us.com                  3               2.89  6579810.0   \n",
       "2  21stcenturywire.com                  5               4.57    66742.0   \n",
       "3  100percentfedup.com                  4               4.15   778723.0   \n",
       "4          abcnews.com                  5               4.78    32787.0   \n",
       "\n",
       "              Domain registrar Postal code Country of origin  Harmless   \n",
       "0             GoDaddy.com, LLC       85284                US        86  \\\n",
       "1       NamePal.com #8009 Inc.       32256                US        86   \n",
       "2             GoDaddy.com, LLC       85284                US        83   \n",
       "3             GoDaddy.com, LLC       85284                US        84   \n",
       "4  CSC CORPORATE DOMAINS, INC.  10023-6298                US        83   \n",
       "\n",
       "   Malicious  Suspicious  Undetected  Timeout  No. of Local links   \n",
       "0          0           0          10        0                  16  \\\n",
       "1          0           0          10        0                   0   \n",
       "2          0           0          13        0                 183   \n",
       "3          1           0          11        0                  49   \n",
       "4          0           0          13        0                   0   \n",
       "\n",
       "   No. of Outbound links  Total links  Links to fake news site?  Wordpress?   \n",
       "0                      1           17                     False        True  \\\n",
       "1                      1            1                     False       False   \n",
       "2                     36          219                     False        True   \n",
       "3                      8           57                     False        True   \n",
       "4                    144          144                     False       False   \n",
       "\n",
       "  Site Rating  \n",
       "0        Fake  \n",
       "1        Fake  \n",
       "2        Fake  \n",
       "3        Fake  \n",
       "4        Fake  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df = pd.read_csv('FakeReal_News_Sites.csv', index_col=[0])\n",
    "fn_df.head()\n",
    "# fn_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# fn_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain                      False\n",
       "Page rank integer           False\n",
       "Page rank decimal           False\n",
       "Site Rank                    True\n",
       "Domain registrar             True\n",
       "Postal code                  True\n",
       "Country of origin            True\n",
       "Harmless                    False\n",
       "Malicious                   False\n",
       "Suspicious                  False\n",
       "Undetected                  False\n",
       "Timeout                     False\n",
       "No. of Local links          False\n",
       "No. of Outbound links       False\n",
       "Total links                 False\n",
       "Links to fake news site?    False\n",
       "Wordpress?                  False\n",
       "Site Rating                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_df.fillna({'Site Rank':0, 'Domain registrar':'None', 'Postal code':'None', 'Country of origin':'None'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain                      False\n",
       "Page rank integer           False\n",
       "Page rank decimal           False\n",
       "Site Rank                   False\n",
       "Domain registrar            False\n",
       "Postal code                 False\n",
       "Country of origin           False\n",
       "Harmless                    False\n",
       "Malicious                   False\n",
       "Suspicious                  False\n",
       "Undetected                  False\n",
       "Timeout                     False\n",
       "No. of Local links          False\n",
       "No. of Outbound links       False\n",
       "Total links                 False\n",
       "Links to fake news site?    False\n",
       "Wordpress?                  False\n",
       "Site Rating                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df[(fn_df['Site Rating'] == 'Fake')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_df.loc[fn_df['Malicious'] > 0, 'Malicious'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnecessary columns = Links to fake news site?, Suspicious, and No. of Outbound links\n",
    "X = fn_df[['Domain registrar', 'Postal code',\n",
    "       'Wordpress?', 'Page rank decimal', 'Site Rank', 'Country of origin', 'No. of Local links', 'Total links']]\n",
    "\n",
    "y = fn_df['Site Rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "cat_cols = ['Postal code', 'Country of origin']\n",
    "bin_cols = ['Wordpress?']\n",
    "num_cols = ['Page rank decimal','Site Rank', 'Total links']\n",
    "\n",
    "ct = ColumnTransformer([('standard_scaler', StandardScaler(), num_cols),\n",
    "                        ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown= \"ignore\"), cat_cols),\n",
    "                        ('label_encoder', OrdinalEncoder(handle_unknown= \"use_encoded_value\", unknown_value=np.nan), bin_cols)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# params={\n",
    "#  \"learning_rate\"    : [0.01, 0.05, 0.10, 0.15, 0.20, 0.25] ,\n",
    "#  \"max_depth\"        : [ 3, 4, 5, 6, 9, 12],\n",
    "#  \"min_child_weight\" : [ 1, 3, 5, 7, 9, 11 ],\n",
    "#  \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4, 0.5],\n",
    "#  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7, 0.9, 0.11 ]\n",
    "    \n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=params,\n",
    "#     scoring = 'roc_auc',\n",
    "#     n_jobs = 5,\n",
    "#     cv = 5,\n",
    "#     verbose=True,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "# clfXGB_gs = Pipeline(steps = [('preprocessor', ct), ('XGBoost', grid_search)])\n",
    "# clfXGB_gs.fit(X_train, y_train)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# def plot_search_results(grid):\n",
    "#     \"\"\"\n",
    "#     Params: \n",
    "#         grid: A trained GridSearchCV object.\n",
    "#     \"\"\"\n",
    "#     ## Results from grid search\n",
    "#     results = grid.cv_results_\n",
    "#     means_test = results['mean_test_score']\n",
    "#     stds_test = results['std_test_score']\n",
    "#     means_train = results['mean_train_score']\n",
    "#     stds_train = results['std_train_score']\n",
    "\n",
    "#     ## Getting indexes of values per hyper-parameter\n",
    "#     masks=[]\n",
    "#     masks_names= list(grid.best_params_.keys())\n",
    "#     for p_k, p_v in grid.best_params_.items():\n",
    "#         masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "#     params=grid.param_grid\n",
    "\n",
    "#     ## Ploting results\n",
    "#     fig, ax = plt.subplots(1,len(params),sharex='none', sharey='none',figsize=(30,6))\n",
    "#     fig.suptitle('Score per parameter')\n",
    "#     fig.text(0.04, 0.5, 'MEAN SCORE', va='center', rotation='vertical')\n",
    "#     pram_preformace_in_best = {}\n",
    "#     for i, p in enumerate(masks_names):\n",
    "#         m = np.stack(masks[:i] + masks[i+1:])\n",
    "#         pram_preformace_in_best\n",
    "#         best_parms_mask = m.all(axis=0)\n",
    "#         best_index = np.where(best_parms_mask)[0]\n",
    "#         x = np.array(params[p])\n",
    "#         y_1 = np.array(means_test[best_index])\n",
    "#         e_1 = np.array(stds_test[best_index])\n",
    "#         y_2 = np.array(means_train[best_index])\n",
    "#         e_2 = np.array(stds_train[best_index])\n",
    "#         ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
    "#         ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "#         ax[i].set_xlabel(p.upper())\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "# plot_search_results(grid_search)\n",
    "# grid_search.best_params_\n",
    "# grid_search.best_score_\n",
    "# cv_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# cv_df= cv_df.drop('params', axis=1)\n",
    "# cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "\n",
    "clfXGB_nocv = Pipeline(steps = [('preprocessor', ct), ('XGBoost', XGBClassifier())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "models = [clfXGB_nocv]\n",
    "model_scores={}\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    name = list(model.named_steps)[1]\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    model_scores[name] = score, mae, mse, f1\n",
    "    \n",
    "\n",
    "    joblib.dump(model, f'{name}Classifier.joblib')\n",
    "    print(f'model {idx+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBoost': (0.9148936170212766,\n",
       "  0.0851063829787234,\n",
       "  0.0851063829787234,\n",
       "  0.909090909090909)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores\n",
    "#accuracy, mean absolute error, mean squared error, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SitePreprocessor.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "clfSVM = Pipeline(steps = [('preprocessor', ct), ('SVM', SVC())])\n",
    "#logistic regression\n",
    "clfLOGREG = Pipeline(steps = [('preprocessor', ct), ('Logistic Regression', LogisticRegression())])\n",
    "#XGBoost\n",
    "clfXGB = Pipeline(steps = [('preprocessor', ct), ('XGBoost', XGBClassifier(colsample_bytree= 0.4, gamma= 0.3, learning_rate= 0.01,max_depth= 3, min_child_weigh = 3))])\n",
    "#Naive Bayes\n",
    "clfNB = Pipeline(steps = [('preprocessor', ct), ('Naive Bayes', GaussianNB())])\n",
    "#Random forest\n",
    "clfRFC = Pipeline(steps = [('preprocessor', ct), ('RFC', RandomForestClassifier())])\n",
    "#neural netTODO\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(ct, \"SitePreprocessor.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 done\n",
      "model 2 done\n",
      "[11:13:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_child_weigh\" } are not used.\n",
      "\n",
      "model 3 done\n",
      "model 4 done\n",
      "model 5 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "models = [clfSVM, clfLOGREG, clfXGB, clfNB, clfRFC]\n",
    "\n",
    "model_scores={}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "for idx, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    name = list(model.named_steps)[1]\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    model_scores[name] = score, mae, mse, f1\n",
    "    \n",
    "\n",
    "    joblib.dump(model, f'{name}Classifier2.joblib')\n",
    "    print(f'model {idx+1} done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "# models = [clfSVM, clfLOGREG, clfXGB, clfNB, clfRFC]\n",
    "\n",
    "# model_scores={}\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "# for idx, model in enumerate(models):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     name = list(model.named_steps)[1]\n",
    "    \n",
    "#     score = model.score(X_test, y_test)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "#     model_scores[name] = score, mae, mse, f1\n",
    "    \n",
    "\n",
    "#     joblib.dump(model, f'{name}Classifier.joblib')\n",
    "#     print(f'model {idx+1} done')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': (0.9148936170212766,\n",
       "  0.0851063829787234,\n",
       "  0.0851063829787234,\n",
       "  0.9047619047619048),\n",
       " 'Logistic Regression': (0.9361702127659575,\n",
       "  0.06382978723404255,\n",
       "  0.06382978723404255,\n",
       "  0.9302325581395349),\n",
       " 'XGBoost': (0.9574468085106383,\n",
       "  0.0425531914893617,\n",
       "  0.0425531914893617,\n",
       "  0.9523809523809523),\n",
       " 'Naive Bayes': (0.46808510638297873,\n",
       "  0.5319148936170213,\n",
       "  0.5319148936170213,\n",
       "  0.626865671641791),\n",
       " 'RFC': (0.9574468085106383,\n",
       "  0.0425531914893617,\n",
       "  0.0425531914893617,\n",
       "  0.9523809523809523)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores\n",
    "#scores in order: accuracy, mean absolute error, mean squared error, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_child_weigh\" } are not used.\n",
      "\n",
      "Score:  0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "clfXGB.fit(X_train, y_train)\n",
    "print('Score: ',clfXGB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfXGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 1 1]\n",
      "[1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  1]\n",
      " [ 1 25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6ec5c042ddf83e1a0c3f39fbc3e80edf14e579d2f804f9b839dc9985dcd105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
